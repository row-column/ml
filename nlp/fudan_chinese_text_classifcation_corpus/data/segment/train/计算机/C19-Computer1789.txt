软件 学报 
 JOURN   AL   OF   SOFTWARE 
 1999 年 　 第 10 卷 　 第 10 期 　 Vol.10 　 No.10 　 1999 
 
 
 
 基于 多层 油藏 问题 负载 均衡 的 并行任务 划分 
 舒 继武   赵 金熙   周维四   张德富 
 摘要 　 该文 基于 分布式 并行 计算机系统 , 对 一类 多层 二维 二相流 油藏 数值 模拟 问题 给出 了 3 种 任务 划分 策略 — “ 卷帘 ” 方式 、 区域 分解 方式 和 “ 卷帘 ” 与 区域 分解 结合 的 方式 , 对 它们 进行 了 比较 , 提出 了 减少 求解 时间 、 利于 负载 均衡 和 提高 并行 性能 的 任务 划分 方法 , 并 实际 应用 于 有 多达 72 万个 网格 节点 的 大规模 油藏 模拟 问题 . 实算 结果表明 , 该 策略 划分 产生 的 并行 求解 任务 均衡 , 有利于 加速 比 的 提高 . 该 方法 也 适用 于 区域 或 数据 并行 的 任务 划分 问题 . 
 关键词   并行计算 , 负载 均衡 , 任务 划分 , 油藏 数值 模拟 . 
 中图法 分类号 　 TP319 
 
 Parallel   Tasks   Partitioning   of   Load - balancing   for   a   Multiple   Layers 
 Numerical   Simulation   of   Reservoir 
 SHU   Ji - wu1 , 2   ZHAO   Jin - xi1 , 2   ZHOU   Wei - si3   ZHANG   De - fu1 , 2 
 1 ( State   Key   Laboratory   for   Novel   Software   Technology   Nanjing   University   Nanjing   210093 ) 
 2 ( Department   of   Computer   Science   and   Technology   Nanjing   University   Nanjing   210093 ) 
 3 ( The   Academy   of   Geological   Sciences   Shengli   Oil - Field   Dongying   257000 ) 
 Abstract   In   this   paper ,   three   tasks   division   strategies   of   load - balancing   are   given ,   which   include   a   round - robin   fashion ,   a   domain   partitioning   fashion   and   a   fashion   of   round - robin   combining   with   domain   partitioning ,   and   a   comparison   is   made .   Then   tasks   division   methods   are   proposed   which   can   reduce   solving   times   and   benefit   load - balancing   and   increases   parallel   efficiency   for   a   simulation   of   reservoir   of   multiple   layers   two - dimension   two - phase   flow   numerical   problems   on   distributed   memory   parallel   systems .   This   approach   is   applied   to   a   large   scale   reservoir   simulation   which   has   over   720   000   grid   points .   The   practical   results   show   that   the   tasks   generated   by   the   strategy   are   well - balanced   and   benefit   to   improve   speedup .   This   approach   is   apt   to   the   problems   for   domain   parallel   or   data   parallel . 
 Key   words   Parallel   computing ,   load - balancing ,   task   dividing ,   numerical   simulation   of   reservoir . 
 　 　 油藏 模拟 需要 大量 的 计算 时间 , 并行 计算机 的 使用 对 其 产生 了 强有力 的 推动 作用 [ 1 ] . 国外 的 许多 石油 公司 用 并行处理 来 降低生产 成本 , 提高 生产率 . 国内 的 一些 石油 公司 也 正在 投资 使用 并行 计算机 进行 油藏 模拟 , 以 提高 处理速度 , 缩短 处理 时间 . 国内外 已有 相关 的 工作 报道 . 文献 [ 2 ] 利用 分布式 并行 计算机 ( ipcs / 860 ) 求解 了 一个 两种 组分 的 油藏 模拟 问题 . 文献 [ 3 ] 给出 了 将 区域 分解 法 和 多重 网格 技术相结合 来 解决 油藏 模拟计算 问题 的 一种 方法 . 文献 [ 4 ] 基于 Transputer 并行 系统 实现 了 多层 二维 二相 油藏 模拟 的 并行 试验 . 在 油藏 数值 模拟 中 , 多层 二维 二相流 油藏 数值 模拟 应用 非常 广泛 . 本文 以 此类 问题 的 并行计算 作为 讨论 背景 . 它 具有 在 不同 时间 步 任务 大小 不同 的 特殊性 . 图 1 表示 它 在 一个 时间 步 的 串行 计算 流程 ( KC 表示 需 计算 的 油层 数 ) . 流程 中 的 主要 计算 时间 是 花 在 解 压力 方程组 上 . 在 每 一时间 步 一般 有 1 个 或 多个 油层 需要 计算 ; 在 不同 的 时间 步 , 需 计算 的 油层 数 KC 有时 是 变化 的 , 有时 甚至 相差 较大 . 目前 , 此类 问题 的 并行处理 一般 都 采用 这种 按 油层 并行 的 策略 , 也 有 的 按 拟 三维 问题 采用 区域 分解 方法 . 文献 [ 4 ] 利用 每个 油层 压力 方程组 求解 的 相互 独立性 , 按 “ 卷帘 ” 方式 将 油层 映射 到 多处理机 并行 环境 中 并行 求解 , 但是 由于 在 不同 的 时间 步 , 层数 是 变化 的 , 有时 层数 小于 或远 小于 处理机 数时 , 处理机 负载 很 不 均衡 , 处理机 得不到 充分利用 , 也 未能 充分 挖掘 问题 的 并行性 , 其 加速 比不高 ; 另外 , 在 每 一时间 步解 饱和度 方程组 需各层 压力 值 , 问题 求解 的 完成 是 等待 最慢 结点 机上 的 压力 数据 , 这 就 导致 整体 并行 性能 退化 到 与 最慢 结点 机 相同 . 本文 通过 比较 几种 任务 划分 策略 , 提出 了 一种 减少 求解 时间 、 有利于 负载 均衡 和 提高 处理机 性能 的 任务 划分 策略 ( 并行 方案 3 ) . 该 策略 划分 的 并行任务 比 文献 [ 3 , 4 ] 的 两种 并行 方案 负载 均衡 , 并行 加速 比高 , 并且 在 大规模 油藏 模拟 实际 生产 应用 中 取得 了 良好 的 效果 . 
 
 图 1 　 压力 串行 计算 过程 
 1 　 任务 划分 对 并行 性能 的 影响 
 　 　 在 并行计算 中 , 任务 的 划分 应 与 求解 问题 的 规模 和 处理机 的 结构 密切相关 , 它 极大 地 影响 到 能否 有效 地 发挥 并行机 的 性能 和 减少 求解 时间 , 尤其 是 对 求解 任务 大小 发生变化 的 问题 . 对于 一个 给定 的 并行 环境 , 其 并行 计算机 结构 类型 和 处理机 数是 确定 的 , 加速 比 将 取决于 : ①   任务 的 均衡 ; ②   各 处理机 之间 的 同步 和 通信 耗费 ; ③   任务 的 执行 速度 . 这 3 点 是 相互 关联 的 . 
 　 　 减少 通信 时间 有 两 方面 的 途径 : 一方面 是 提高 通信 速率 , 减少 通信 延迟 ; 另一方面 是 减少 通信 数据量 . 前者 与 系统 的 硬件 结构 、 性能 及 操作系统 有关 , 后者 与 并行 粒度 有关 . 并行 粒度 也 是 影响 负载 均衡 的 一个 因素 , 选择 合适 的 并行 粒度 是 设计 并行处理 程序 、 改善 并行处理 性能 的 重要途径 , 它 可以 大大减少 问题 的 求解 时间 . 
 　 　 根据 Amdahl 定理 可知 , 高 并行度 可以 提高 并行 性能 . 在 决定 并行 加速 实际 可 达到 的 并行度 的 诸多 因素 中 , 数据 规模 和 数据 本身 取决于 具体 的 问题 , 是 我们 所 不能 控制 的 . 从 改进 代码 结构 这一 角度 来讲 , 细化 计算 粒度 可以 做到 提高 算法 的 并行度 , 从而 提高 并行 系统 的 性能 . 
 　 　 细化 计算 粒度 使得 系统 中 实际 参与 分配 的 任务 数变 多 , 易使 负载 均衡 . 但 在 细化 计算 粒度 的 同时 , 将 引起 通信量 的 增加 . 通信 对 并行计算 来说 是 一种 额外 开销 , 对 性能 将 产生 负面 的 影响 . 在 大规模 并行 系统 中 , 当 采用 细化 计算 粒度 的 并行 时 , 系统 性能 有时 会 因为 计算 粒度 细化 而 受益 , 同时 又 因为 通信 开销 随之 增大 而 被 部分 或 全部 抵销 , 甚至 反而 会 导致 性能 下降 , 因此 必须 在 并行度 与 粒度 间 充分 地 进行 折衷 并 尽可能 地使 负载平衡 . 
 　 　 并行 求解 时间 一般 为 参与 并行计算 的 处理机 中 运行 时间 的 最大值 . 这里 定义 该 问题 的 一个 时间 步 并行 求解 的 加速 比 Sp 为 
 . 　 　 　 　 　 　 　 　 　 　 　 　   ( 1 ) 
 其中 Tp 表示 所 讨论 的 并行算法 使用 p 台 处理机 的 运行 时间 , T1 表示 该 算法 在 单 处理机 上 的 运行 时间 , td 表示 分配 数据 给 结点 机和 从 结点 机 接收 结果 数据 所 需 的 时间 , tcomm 表示 处理机 之间 通信 和 同步 所 需 时间 , tcalc 表示 在 一个 时间 步 最慢 结点 机 的 计算 时间 . 
 2 　 划分 策略 
 2.1 　 并行 方案 1 及其 实现 
 　 　 利用 该 问题 “ 每 一时间 步解 每层 压力 方程组 是 相互 独立 的 ” 这一 特性 , 按层 “ 卷帘 ” 方式 分配 层 数据 到 各 处理机 . 设有 p 个 处理机 , 在 某一时间 步内 , 有 k 层 需要 计算 , 那么 在 第 i 个 处理机 上 分配 的 层 集为 Ri ＝ { k | ( k   mod   p ) ＝ i } ( i ＝ 0 , … , p -   1 ) . 如图 2 所示 为 p 个 处理机 上 的 并行 求解 过程 . 
 
 图 2 　 P 个 处理机 并行计算 过程 
 　 　 在 这种 并行 方案 中 , 是 以 油层 为 并行计算 粒度 , 是 粗粒度 并行 . 其 主要 优点 是 每 一时间 步解 压力 方程组 没有 处理机 之间 的 通信 和 同步 开销 , 只有 分配 数据 给 结点 机和 从 结点 机 接收 结果 数据 所 需 的 时间 . 其 主要 不足 是 : 在 每 一时间 步 , 需 计算 的 层数 不 一定 相同 , 容易 使 处理机 的 负载 不 均衡 , 并且 在 每 一次 时间 步 , 饱和度 的 求解 需要 等待 最慢 结点 机上 的 压力 数据 , 这样 可 导致 整体 并行 性能 退化 到 与 最慢 结点 机 相同 , 从而 使 加速 比 下降 . 尤其 是 在 某些 时间 步 , 当 计算 层数 为 1 时 退化 为 串行 处理 . 对 该 并行 方案 , 式 ( 1 ) 可 变为 
 , 　 　 　 　 　 　 　 　 　 　 　 　 　   ( 2 ) 
 其中 tj 为 第 j 层 的 计算 时间 . 在 确定 的 时间 步 , 分配 数据 给 结点 机和 从 结点 机 接收 结果 数据 所 需 的 时间 td 是 一定 的 , 因此 要 使 其 Sp 最大 , 必须 有 
 . 　 　 　 　 　 　 　 　 　 　 　 　 　 　   ( 3 ) 
 　 　 对于 这种 粒度 划分 方法 , 并行 粒度 大 , 对于 在 不同 时间 步 计算 层数 变化 或 在 某些 时间 步 计算 层数 小于 处理机 数 的 问题 , 任务 分布 难以 均匀 , 处理机 也 未 得到 充分利用 , 加速 比不高 , 并行 效率 低 . 对 有些 模型 , 加速 比 甚至 很 低 . 目前 采用 的 多 是 这种 以层 为 并行 粒度 [ 4 ] 的 方法 . 
 2 　 并行 方案 2 及其 实现 
 　 　 设有 p 个 处理机 , 在 某一时间 步 , 有 k 层 需 计算 , 每 一层 采用 区域 分解 法 , 将 每 一层 对应 的 计算 区域 分为 p 个子 区域 ( 任务 ) , 仍 按 “ 卷帘 ” 方式 分配 子 区域 数据 到 各 处理机 , 则 在 第 i 个 处理机 上 分配 的 子 区域 集 为 所有 k 层 的 第 i 个子 区域 组成 的 集合 , 即 Qi = { q | ( q   mod   p ) = i } , 其中 i = 0 , … , p -   1 , q = 1 , … , k × p . 
 　 　 该 方法 细化 了 方法 1 的 并行 粒度 , 它 是 以 油层 的 子 区域 为 并行计算 粒度 , 有利于 处理机 负载平衡 , 特别 是 当 每层 划分 的 子 区域 数 与 处理机 数 相等 时 , 每一 处理机 分配 的 子 区域 数 相等 , 负载 易于 均衡 . 对于 实际 的 油藏 模拟 问题 , 由于 计算 的 区域 一般 都 是 大 范围 的 , 以子 区域 作为 并行计算 粒度 仍 是 粗粒度 并行 , 可以 认为 是 方案 1 的 粒度 的 细化 . 图 3 表示 , 在 某一时间 步 , 每 一层 计算 区域 划分 为 p 个子 区域 , 在 p 个 处理机 上 并行 求解 的 过程 . 
 
 图 3 　 P 个 处理机 并行计算 过程 
 　 　 对于 实际 问题 , 区域 分解 法 的 通信 主要 是 相邻 边界 数据交换 , 其 通信量 不大 . 特别 是 对 大规模 问题 , 细化 并行 粒度 改善 负载 均衡 时 缩短 的 时间 大于 通信 增加 的 时间 . 对于 某一时间 步 , 当 计算 层数 k <   处理机 数 p 时 , 尤其 是 k < < p 时 , 该 方法 与 第 1 种 方法 比较 , tcomm 的 开销 一般 要 小于 由于 负载 不 平衡 所 引起 的 同步 等待 开销 时间 , 此时 细化 第 1 种 方法 的 并行 粒度 可以 获得 更 高 的 加速 比 . 但 在 k > > p 时 , tcomm 随着 计算 层数 的 增大 而 增大 , 会 成为 影响 加速 比 的 重要 因素 , 此时 可能 没有 第 1 种 方法 的 加速 比高 . 对于 该 并行 方案 , 式 ( 1 ) 可 变为 
 , 　 　 　 　 　 　 　 　 　 　 　 　 　 　   ( 4 ) 
 其中 tq 为子 区域 q 的 计算 时间 , tis 为 第 i 层 区域 间通信 同步 时间 . 要 使式 ( 4 ) 中 的 Sp 最大 , 需 有 
 .   　 　 　 　 　 　 　 　 　 　 　 　 　 ( 5 ) 
 2.3   并行 方案 3 及其 实现 
 　 　 令 , 第 1 层 ～ 第 k -   p * n 层 , 采用 方法 2 划分 任务 , 每层 划分 为 p 个子 区域 ( 任务 ) , 共有 p * ( k -   p * n ) 个 任务 , 有 k -   p * n 次机 间通信 同步 . 按子 区域 “ 卷帘 ” 方式 分配 数据 块 到 p 个 处理机 , 即 Qi = { q | ( q   mod   p ) = i } , i = 0 , … , p -   1 , q = 1 , … , ( k -   p × n ) × p , 这是 以子 区域 为 并行 粒度 . 第 k -   p * n + 1 层 ~ 第 k 层 , 采用 方法 1 来 划分 任务 , 即 以层 为 粒度 的 共有 p * n 个 任务 , 按层 “ 卷帘 ” 方式 分配 层 数据 到 p 个 处理机 , 即 Ri = { j | ( j   mod   p ) = i } , i = 0 , … , p -   1 , j = k -   p × n + 1 , … , k . 如图 4 所示 为 在 p 个 处理机 上 的 并行 实现 过程 . 该 方法 综合 了 方法 1 和 方法 2 , 同时 采用 了 两种 不同 的 并行计算 粒度   油层 和 油层 的 子 区域 , 既 易于 负载平衡 , 又 减少 了 通信 同步 , 它 克服 了 上述 两种 方法 的 不足 , 而 保留 了 它们 的 优点 . 
 
 图 4 　 p 个 处理 并行计算 过程 
 　 　 当 k < < p 时 , 方法 3 是 采用 区域 分解 方法 来 分割 区域 并 均匀 地 映射 到 处理机 上 , 各 处理机 的 负载 也 基本 平衡 . 由于 k 很小 , 通信 同步 也 开销 不大 . 方法 2 可 看成 是 此种 情况 的 特例 . 当 k > > p 时 , 方法 3 综合 了 方法 1 与 方法 2 , 各 处理机 的 负载 基本 平衡 . 
 　 　 这种 方法 也 存在 通信 开销 的 问题 , 只是 它 比 方法 2 的 通信 开销 要 小 , 有时 甚至 小 很多 , 因此 与 方法 2 相比 有 较 高 的 加速 比 . 对 该 并行 方案 , 式 ( 1 ) 可 变为 
 .   　 　 　 　 　 　 　 　 　 ( 6 ) 
 　 　 对于 在 不同 的 时间 步 计算 层数 变化 的 问题 , 该 方法 总能 使 各 处理机 的 负载 基本 平衡 , 因此 比 方法 1 和 方法 2 更 有效 . 要 使式 ( 6 ) 中 Sp 最大 , 必须 有 
 .   　 　 　 　 　 　 　 　 　 ( 7 ) 
 　 　 比较 式 ( 2 ) 和 式 ( 6 ) 可知 , 当 
   　 　 　 　 　 　 　 　 　 ( 8 ) 
 时 , 方法 3 比 方法 1 有效 . 这 表明 采用 细化 一部分 任务 的 计算 粒度 使得 任务 均衡 , 系统 性能 因 计算 粒度 的 细化 而 提高 . 比较 式 ( 4 ) 和 式 ( 6 ) 可 得 , 当 
   　 　 　 　 　 　 　 　 ( 9 ) 
 时 , 方法 3 比 方法 2 有效 . 这 表明 完全 细化 计算 粒度 引起 通信量 的 增加 , 增大 的 通信 开销 导致 性能 下降 , 因此 必须 在 并行度 与 粒度 间 进行 充分 折衷 并 尽可能 使 负载平衡 . 
 　 　 在 实际 应用 中 使用 PVM 并行 环境 , 为了 减少 通信 开销 , 可 采用 集中 通信 方式 , 减少 通信 次数 , 从而 减少 通信 启动 时间 , 缩短 tcomm . 另外 , 每一 结点 机 的 通信 开销 可以 分成 两 部分 : 一部分 是 接收 来自 其他 处理机 的 相邻 边界 数据 ; 另 一部分 是 发送 本 结点 机 的 相邻 边界 数据 的 过程 , PVM 发送 采用 异步 过程 , 基本 可以 与 计算 重叠 进行 . 因此 , 通信 开销 主要 体现 在 接收 方面 . 
 3 　 数值 结果 
 　 　 取 压力 方程组 的 收敛 判别 为 | | pi + 1 - pi | | 2   5 × 10 － 3 , pi + 1 , pi 分别 为 第 I + 1 和 第 i 迭代 步 的 压力 . 设 Nx , Ny 分别 表示 油层 X , Y 方向 上 的 网格 划分 , Nk 表示 油层 数 . 选取 的 实际 油藏模型 有 以下 几个 . 模型 1 :   Nx × Ny × Nk 为 142 × 75 × 12 , 节点 数为 127   800 , 每个 阶段 N 有 MP ＝ 8 个 时间 步 . 模型 2 :   Nx × Ny × Nk 为 146 × 125 × 16 , 节点 数为 292   000 , 每个 阶段 N 有 MP ＝ 8 个 时间 步 . 模型 3 :   Nx × Ny × Nk 为 211 × 203 × 17 , 节点 数为 728   161 , 每个 阶段 N 有 MP ＝ 23 个 时间 步 . 这 3 种 模型 在 N ＝ 1 ～ 17 个 阶段 的 计算 层数 k 如表 1 所示 . 在 实际 应用 中 , 为了 提高 并行 效率 , 采用 压缩 通信 技术 . 并行计算 环境 是 通过 PVM 用 以太网 连接 两个 基于 共享 主存 的 SGI   Challenge 并行机 组成 的 , 每个 Challenge 有 两个 处理器 . 采用 上述 3 种 粒度 划分 方法 对 这 3 种 模型 分别 求解 , 方法 2 与 方法 3 中 每层 划分 的 子 区域 数为 4 , 运行 加速 比 结果 见表 2 . 
 表 1 
 
 时间 阶段 N1234567891011121314151617 
 模型 1 :   计算 层数 k55566779101010111112121212 
 模型 2 :   计算 层数 k111277911111111121212121212 
 模型 3 :   计算 层数 k1717171717171717171717171717171717 
 
 　   
 表 2 
 
 模型 1 模型 2 模型 3 
 S1p ( 方法 1 ) 3.02 . 452.30 
 S2p ( 方法 2 ) 2.742 . 031.70 
 S3p ( 方法 3 ) 3.162 . 742.72 
 
 　   
 　 　 采用 方法 2 对 这 3 个 模型 的 效果 都 不 理想 , 主要 是 由于 在 整个 运行 阶段 , 时间 步及 计算 层数 较 多 , 时间 步 分别 总计 为 136 , 136 , 391 , 计算 层数 分别 总计 为 1   200 , 1   152 和 6   647 , 而 每 一时间 步 都 有层 间通信 同步 , 细化 并行 粒度 引起 的 通信 同步 开销 大大增加 了 . 方法 3 对 3 种 模型 的 Sp 都 有 改善 . 我们 求解 有 多达 72 万个 网格 节点 的 大规模 油藏 模拟 生产 实际 问题 3 的 实践 表明 , 方法 3 划分 产生 的 并行 求解 任务 均衡 , 有利于 进一步提高 加速 比 . 
 注释 ： 本文 研究 得到 国家 863 高科技 项目 基金 资助 。 
 作者简介 ： 舒 继武 ： 1969 年生 ， 博士生 ， 主要 研究 领域 为 并行处理 ， 分布式计算 
 　 　 　 　 　 赵 金熙 ： 1950 年生 ， 博士 ， 副教授 ， 主要 研究 领域 为 计算 数学 ， 数值 计算 
 　 　 　 　 　 周维四 ： 1942 年生 ， 教授级 高工 ， 博士生 导师 ， 主要 研究 领域 为 计算技术 ， 油藏 数值 
 　 　 　 　 　 模拟 。 
 　 　 　 　 　 张德富 ： 1937 年生 ， 教授 ， 博士生 导师 ， 主要 研究 领域 为 计算机软件 ， 并行处理 技 
 　 　 　 　 　 术 ， 分布式计算 
 作者 单位 ： 舒 继武 、 赵 金熙 、 张德富 ： 南京大学 计算机软件 新 技术 国家 重点 实验室   南京   210093 
 　 　 　 　 　 舒 继武 、 赵 金熙 、 张德富 ： 南京大学 计算机科学 与 技术 系   南京   210093 
 　 　 　 　 　 周维四 ： 胜利油田 地质 科学 研究院   东营   257000 
 参考文献 
 1 　 Kendall   R   P   et   al .   Large   Scale   Reservoir   Simulation   in   the   Concurrent   Processing   
 　 　 Milieu .   Los   Alamitos ,   CA :   IEEE   Computer   Society   Press ,   1991 
 2 　 Killough   J   E   et   al .   Simulation   of   compositional   reservoir   phenomena   on   a   
 　 　 distribute   memory   parallel   computer .   In :   Killough   J   E   et   al   eds .   The   1991   SPE   
 　 　 Symposium   on   Reservoir   Simulation .   Anaheim :   University   of   Anaheim   Press ,   1991 .   
 　 　 69 ～ 82 
 3 　 Bhogeswara   Rao ,   Killough   J   E .   Parallel   linear   solvers   for   reservoir   simulation :   a 
 　 　 generic   approach   for   existing   and   emerging   computer   architectures .   In :   Killough   
 　 　 J   E   et   al   eds .   Proceedings   of   the   12th   SPE   Symposium   on   Reservoir   Simulation .   
 　 　 Houston :   University   of   Houston   Press ,   1993 .   71 ～ 82 
 4 　 徐向明 , 孙家 昶 等 . 多层 二维 二相 油藏 模拟 的 并行 试验 . 见 : 李晓梅 等 编 . 全国 第 4 届 并行算法 学 
 　 　 术 会议 论文集 . 北京 : 航空工业 出版社 , 1993.255 ～ 260 
 　 　 ( Xu   Xiang - ming ,   Sun   Jia - chang   et   al .   Parallel   experiment   for   multiple   layers   
 　 　 two - dimension   two - phases   flow   reservoir   simulation .   In :   Li   Xiao - mei   et   al   eds .   
 　 　 Proceedings   of   the   4th   Parallel   Algorithms   Conference .   Beijing :   Aviation   
 　 　 Industry   Press ,   1993 .   255 ～ 260 ) 
 收稿 日期 : 1998 - 05 - 12 修稿 日期 : 1998 - 10 - 09 
