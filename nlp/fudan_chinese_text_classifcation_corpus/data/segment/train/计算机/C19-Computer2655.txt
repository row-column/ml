软件 学报 
 JOURNAL   OF   SOFTWARE 
 1999 年 　 第 10 卷 　 第 9 期 　 Vol.10 　 No.9 　 1999 
 
 
 
 一个 面向对象 数据库系统 的 TPC - C 测试 与 分析 * 
 于戈 　 王国 仁 　 王欣晖 　 郑 怀远 
 摘要 　 文章 介绍 了 一个 著名 的 在线 事务处理 系统 性能 测试 标准 TPC - C 及其 在 面向对象 数据库 管理系统 Fish 上 的 设计 与 实现 ， 并 基于 实验 结果 对 影响 数据库系统 性能 的 主要 因素 进行 了 验证 和 分析 . 
 关键词 　 Benchmark ， 面向对象 数据库系统 ， TPC - C . 
 中图法 分类号 　 TP311 
 Performance   Analysis   of   an   Object - oriented   Database   System   with   TPC - C   Benchmark 
 YU   Ge   WANG , Guo - ren   WANG , Xin - hui , ZHENG   Huai - yuan 
 ( Department   of   Computer   Science   and   Engineering   Northeastern   University   Shenyang   110006 ) 
 Abstract 　 In   this   paper ,   the   authors   discuss   a   known   on - line   transaction   processing   testing   benchmark   TPC - C ,   and   its   design   and   implementation   on   an   object - oriented   database   management   system — — Fish .   Based   on   the   testing   results ,   the   evaluation   and   analysis   on   the   major   factors   that   affect   the   database   system   performance   are   given . 
 Key   words 　 Benchmark ,   OODBMS ,   TPC - C . 
 　 　 数据库系统 测试 标准 由于 提供 了 衡量 一个 数据库系统 各 方面 性能 的 规范 和 方法 ， 变得 越来越 重要 ［ 1 ］ . 作为 新一代 的 数据库系统 ， 面向对象 数据库系统 常常 被 设计 成 面向 复杂 应用环境 , 如 工程设计 ( CAD / CAM ) 、 多媒体 数据处理 等 . 各国 的 大学 、 机构 和 组织 为 测试 面向对象 数据库系统 在 这些 应用 中 的 性能 , 已经 提出 一些 著名 的 测试 标准 ， 如 Cattell ［ 2 ］ 设计 的 OO1 测试 标准 、 美国威斯康星大学 设计 的 OO7 ［ 3 ］ 测试 标准 等 . 许多 面向对象 数据库系统 ， 如 ObjectStore , O2 已经 完成 了 这些 测试 , 并 基于 测试 结果 对系统 作 了 有益 的 改进 . 这些 测试 标准 所 模拟 的 工程 应用 具有 数据类型 与 结构复杂 、 大 对象 、 关联 查询 和 批量 更新 等 新 的 特点 ， 因此 ， 不同于 传统 的 事务处理 型 应用 . 
 　 　 随着 数据库 技术 的 发展 ， 面向对象 数据库系统 也 被 用于 在线 事务处理 之中 ， 尤其 是 随着 低价位 、 高性能 的 工作站 和 PC机 的 普及 ， 面向对象 数据库系统 的 应用领域 变得 越来越 广泛 . 但据 我们 所知 ， 还 很少 有人 对 面向对象 数据库系统 在 在线 事务处理 领域 中 的 性能 做过 测试 . 因此 ， 我们 选择 了 TPC - C 测试 标准 对此 加以 测试 . 本文 以下 部分 给出 了 TPC - C 测试 标准 在 面向对象 数据库系统 Fish 上 的 设计 与 实现 ， 并 对 测试 的 结果 进行 了 分析 和 比较 ， 为 构建 高性能 OLTP ( online   transaction   processing ) 面向对象 数据库系统 提出 了 一些 改进 建议 . 文中 的 被 测系统 Fish 是 我们 和 日本 九州 大学 合作开发 的 一个 运行 于 Solaris   2.5 / ( X86 ， Sparc ) 或 Windows   NT 平台 、 基于 NOW ( network   of   workstation ) / NOPC ( network   of   PC ) 网络 计算环境 的 分布式 面向对象 数据库 管理系统 . Fish 系统 包括 分布式 页 式 对象 服务器 WAKASHI ［ 4 ］ ， 符合 ODMG   2.0 ［ 5 ］ 标准 ， 支持 持久 化 对象 的 C++ 风格 编程语言 INADA / ODMG . 图 1 为 Fish 的 系统结构 层次 . WAKASHI 为 面向对象 数据库 的 应用 提供 了 存储管理 和 基于 2PC 的 事务管理 ， 采用 Callback ( 回 叫 ) 协议 支持 事务 间 ( intra - transaction ) 的 数据 缓存 ， 在 系统 内 实现 了 诸如 严格 两段 锁 ( 2PL ) 、 等待 图 ( WFG ) 、 分布式 受限 等待 深度 ( DWDL ) ［ 6 ］ 等 封锁 机制 ， 并 支持 嵌套 事务处理 和 并行处理 . 我们 采用 TPC - C 测试 标准 从 两个 方面 对 Fish 系统 进行 了 测试 : ( 1 )   功能性 测试 ： 包括 测试 商业 应用 所 要求 的 功能 、 OLTP 所 要求 的 功能 、 遵守 事务 的 ACID 特性 的 能力 、 处理 大量 数据 的 能力 ； ( 2 )   性能 测试 ： 包括 测试 OLTP 的 响应 特性 、 多用户 并发 操作 的 性能 、 操作 大 数据库 的 能力 . 
 
 图 1 　 Fish 系统 的 要 层 结构 
 　 　 本文 第 1 节概 要 地 描述 了 TPC - C 测试 标准 . 第 2 节 论述 了 TPC - C 测试 在 Fish 系统 上 的 设计 与 实现 . 第 3 节对 测试 结果 进行 了 比较 和 评价 . 第 4 节 总结 全文 . 
 1 　 TPC - C 概述 
 　 　 TPC - C ［ 7 ］ 测试 标准 是 TPC ( transaction   processing   performance   council ) 委员会 于 1992 年 公布 的 一个 用于 衡量 在线 事务处理 系统 性能 和 性能 价格比 ( performance / cost ) 的 测试 标准 . TPC - C 测试 标准 的 主要 设计 目标 是 : （ 1 ）   模拟 包括 更新 操作 和 只读 操作 的 多 类型 事务 ； （ 2 ）   模拟 不同 特征 的 事务处理 ， 包括 在线 式 ( 对 响应 时间 有 严格要求 ) 和 延时 式 ( 对 响应 时间 的 要求 比较 宽松 ) ； （ 3 ）   所有 事务 必须 严格 符合 ACID 特性 ( atomicity , consistency , isolation , durability   ) ； （ 4 ）   拥有 复杂 的 数据结构 和 联系 ； （ 5 ）   采用 多样 的 数据 访问 方式 ； （ 6 ）   模拟 重 负载 下大 数据库 上 的 多用户 并发 操作 . TPC - C 测试 标准 以 实际 批发 商业活动 作为 其 设计 模型 ， 此 模型 如图 2 所示 . 
 
 图 2 　 TPC - C 的 设计 模型 
 　 　 其中 , 批发 公司 ( company ) 拥有 许多 仓库 ( warehouse ) 并 提供 商品 ( item ) ， 每个 仓库 提供 其 下属 10 个 分店 ( district ) 各 1   000   000 种 商品 ， 每个 分店 为 3   000 个 顾客 ( customer ) 提供 零售 服务 . TPC - C 测试 标准 还 定义 了 5 种 事务 ： 订购 ( new - order ) 、 付款 ( payment ) 、 订购 情况 ( order - status ) 、 发货 ( delivery ) 、 库存 情况 ( stock - level ) . 其中 订购 、 付款 、 发货 等 3 种 事务 为 更 新型 事务 ， 订购 情况 和 库存 情况 是 只读 型 事务 ， 这 5 种 事务 代表 了 由 订货 、 付款 、 发货 到 查询 顾客 订购 情况 和 查询 库存 情况 等 组成 的 一个 完整 的 商业 处理过程 . 在 TPC - C 测试 中 ， 每个 仓库 有 10 个 运行 上述 5 种 TPC - C 事务 的 终端 并发 地 对 TPC - C 数据库 进行 操作 ， 每个 终端 上 运行 的 TPC - C 事务 都 必须 满足 一定 的 混合 比 . 这样 的 运行 要 持续 规定 的 时间 ( 最少 8 小时 ) ， 记录 在 此 时间段 内 完成 的 订购 事务 数 ， 将 测试 时间 ( 单位 ： min . ) 除以 完成 的 订购 事务 数 , 得到 TPC - C 测试 最 重要 的 结果 指标 MQTh ( maximum   qualified   throughput ) ， 表示 平均 每分钟 完成 了 多少 个 订购 事务 ， 显然 , MQTh 的 值 越 大 意味着 OLTP 的 能力 越高 . 
 2 　 TPC - C 测试 的 设计 与 实现 
 　 　 本 节 描述 了 按照 ODMG   2.0 标准 对 TPC - C 测试 数据库 进行 的 设计 和 TPC - C 测试 在 NOPC 环境 下 的 实现 . 
 2.1 　 TPC - C 测试 设计 
 　 　 在 TPC 委员会 所 提供 的 TPC - C 规范 中 , TPC - C 数据库 模型 是 以 关系 形式 来 描述 的 ， 不 加 变换 地 直接 将 其 应用 到 面向对象 数据库 上 显然 是 不 合适 的 . 因此 ， 首先 我们 要 将 TPC - C 规范 中 传统 的 关系 模型 转换成 符合 ODMG   2.0 标准 的 面向对象 模型 ， 然后 以 面向对象 的 方法 重新 设计 TPC - C 数据库 ， 最后 用 INADA / ODMG 语言 实现 这一 设计 . 通过 对 关系 模型 和 ODMG   2.0 标准 中 一些 基本成分 的 相互 对应 关系 的 考察 ， 我们 定义 了 映射 规则 来 将 关系 定义 转换 为 ODMG   2.0 定义 ， 如表 1 所示 . 
 表 1 　 数据库 定义 的 映射 规则 
 
 关系 模型 ODMG   2.0 模型 
 表 模式 类 
 表 外延 
 元组 对象 
 属性数据 成员 
 数据类型 ( short , long , float , char , char , vchar , ... ) 字面 量 ( literal )   ( d - Short , d - Long , d - Float , d - Char , d - String , ... ) 
 主 关键字 关键字 
 外 关键字 联系 ( d - Rel - Ref , ... ) 
 
 　 　 按照 该 映射 规则 , 采用 如下 的 步骤 将 TPC - C 测试 数据库 的 关系 模式 转换成 OO 模式 ： 
 　 　 ( 1 )   定义 9 个类 来 代替 TPC - C 规范 所 规定 的 TPC - C 数据库 中 的 9 张 二维 表 ； 
 　 　 ( 2 )   定义 类 的 数据 成员 来 代替 相应 表中 的 属性 ； 
 　 　 ( 3 )   定义 联系 或 联系 集合 来 代替 相应 表中 的 外 关键字 ； 
 　 　 ( 4 )   为 每个 类 定义 构造函数 和析构 函数 ； 
 　 　 ( 5 )   通过 对类 的 概括 定义 了 3 个 基类 ， 以 形成 继承 层次 ； 
 　 　 ( 6 )   在 类 的 继承 层次 中 对 基类 进行 提炼 ； 
 　 　 ( 7 )   定义 每个 类 的 方法 接口 . 
 　 　 经过 以上 各步 ， 完成 对 TPC - C 测试 数据库 的 OO 模式 的 定义 ， 图 3 显示 了 依照 ODMG   2.0 标准 重新 设计 的 TPC - C 测试 数据库 的 类 关系 图 . 考虑 到 影响 面向对象 数据库系统 用于 在线 事务处理 应用 的 因素 ， 我们 选择 以下 两个 方面 作为 测试点 .   
 
 
 图 3 　 类 关系 图 
 　 　 ( 1 )   用户数 ：   因为 每个 用户 始终保持 在 活动状态 ， 所以 实验 中 的 用户数 就 相当于 多用户 编程 级 ( MPL ) . 在 并发 执行 的 情况 下 ， 不同 的 MPL 值 将 会 导致 不同 程度 的 资源 竞争 和 锁 冲突 ， 这 对 事务 的 吞吐量 ( throughput ) 是 至关重要 的 . 尽管 TPC - C 测试 规范 只 需 测试 10 个 用户 和 1 个 仓库 的 情况 ， 但 在 实验 中 ， 我们 分别 对 用户数 1 ～ 10 甚至 更 多 的 情况 都 做 了 测试 ， 目的 在于 考察 不同 情况 下 的 性能 表现 ， 探索 在 NOPC 环境 下 ， 面向对象 数据库系统 为 达到 最大 事务 吞吐量 而 所能 取得 的 最优 MPL 值 . 
 　 　 ( 2 )   不同 的 死锁 检测 机制 ：   许多 面向对象 数据库系统 采用 两段 锁 ( 2PL ) 来 保证 事务 并发 执行 时 的 可 串行 性 . 由于 2PL 可能 会 导致 死锁 ， 因此 , 提供 死锁 检测 机制 ( deadlock   detection , 简称 DD ) 来 检测 和 解除 死锁 是 十分必要 的 . 但是 死锁 检测 和 解除 机制 会 给 系统 增加 额外 开销 ， 因此 , 优化 的 死锁 检测 机制 对 提高 系统 性能 十分 重要 . 为 考察 不同 的 死锁 检测 和 解除 机制 对 面向对象 数据库系统 性能 的 影响 ， Fish 设计 和 实现 了 3 种 不同 的 死锁 检测 和 解除 机制 ， 分别 为 基于 超时 ( timeout ) ［ 8 ］ 、 基于 事务 等待 图 ( wait   for   gragh , 简称 WFG ) ［ 8 ］ 和 基于 分布式 受限 等待 深度 ( distributed   wait - depth   limited , 简称 DWDL ) ［ 6 ］ . 基于 Timeout 的 方法 是 最 简单 的 死锁 检测 和 解除 办法 . 它用 超时 机制 来 检测 死锁 ， 每当 超时 后 ， 由 它 负责 重启动 被 阻塞 的 事务 . 超时 机制 在 客户端 实现 ， 当 客户程序 申请 锁时 被 调用 ， 如果 申请 锁时 被 阻塞 ， 事务 将 等待 一段时间 ， 等待时间 的 长度 由 变量 Timeout - limit 控制 . 一旦 事务 的 等待 超过 等待时间 长度 ， 就 被 认为 产生 了 死锁 ， 该 事务 将会 被 终止 ( abort ) ， 以 解除 死锁 . 但 这种 方法 也 存在 一定 的 问题 ， 在 某些 情况 下 ， 一个 长 事务 的 执行 时间 会 超过 Timeout - Limit ， 于是 检测 到 假死 锁 ， 导致 在 没有 死锁 发生 的 时候 ， 长 事务 执行 失败 . 我们 的 实验 中写 锁 的 Timeout - Limit 设为 20s ， 读锁 的 Timeout - Limit 设为 10s . 基于 WFG 的 方法 是 一个 精确 的 死锁 检测 办法 . 数据库 服务端 维护 一张 等待 图 ， 有锁 申请 时 ， 反映 申请 锁 的 事务 之间 等待 关系 的 边 将 会 被 插入 等待 图 ， 对 更新 后 的 等待 图作 死锁 检测 ， 确定 是否 存在 死锁 ， 如果 检测 到 死锁 ， 选择 死锁 环路 上 某个 事务 作为 “ 牺牲者 ” ( victim ) ， 发信号 ( signal ) 通知 它 重启动 . “ 最 年轻 ” ( 执行 时间 最短 的 事务 ) 的 事务 被选为 牺牲者 . 用 等待 图 的 方法 来 检测 死锁 是 正确 的 ， 它 总能 检测 到 所有 死锁 的 存在 . 分布式 受限 等待 深度 ( DWDL ) 是 改进 的 并发 控制 方法 ， 被 用来 减少 由于 很 高 的 MPL 值 而 引起 的 数据 拥塞 ( data   contention ) . 在 基于 DWDL 的 方法 中 ， 用 限制 事务 等待 深度 的 策略 来 预防 死锁 的 发生 . 类似 于 基于 WFG 的 方法 ， 数据库 服务端 维护 一张 等待 图 ， 有锁 申请 时 ， 反映 申请 锁 的 事务 之间 等待 关系 的 边 被 插入 等待 图 ， 对 更新 后 的 等待 图作 事务 之间 等待 深度 的 检查 . 如果 等待 深度 大于 1 ， 按照 一定 的 策略 , 选择 等待 图中 的 某个 事务 作为 牺牲者 ， 发信号 通知 它 重启动 . 由于 在 死锁 发生 时 ， 事务 之间 的 等待 深度 总是 大于 1 的 ， 因此 , DWDL 能够 预防 死锁 的 发生 ， 也就是说 ， DWDL 能够 检测 潜在 的 死锁 . 但 事实上 ， 当 等待 深度 大于 1 时 ， 并 不是 总会 有 死锁 发生 ， 所以 说 ， DWDL 可能 会 导致 事务 的 假 重启动 ( fake   restart ) . 
 　 　 在 我们 的 实验 中 ， 分别 对 Timeout ， WFG ， DWDL 这 3 种 方法 作 了 3 组 实验 ， 每 一组 实验 包括 用户数 从 1 ～ 10 或 更 多 的 TPC - C 测试 . 为 评价 系统 性能 ， 在 每 一次 测试 中 我们 记录 如下 两个 参数 : MQTh 值 和 重启动 率 ， 即 重启动 的 事务 数 与 总 的 完成 的 事务 数之比 . 
 2.2 　 测试环境 配置 
 　 　 在 实验 中 ， 我们 使用 了 两台 由 连接 在 100M 快速 以太网交换机 上 的 AMD   K6 - 233   PC机 . 一台 运行 数据库 服务器 ， 另一台 运行 远程 终端 仿真 程序 ， 如图 4 所示 . 每台 PC机 的 配置 为 AMD   K6 - 233CPU ， 64MB 内存 ， 4.3 GB 硬盘 . 测试代码 由 INADA / ODMG   1.0 和 C++ 编写 ， 使用 Sun   Workshop   3.0 . 1 C++ 编译器 编译 . 
 
 图 4 　 测试 平台 
 　 　 在 实验 中 ， TPC - C 测试 数据库 建立 在 分布式 对象 服务器 WAKASHI 运行 的 PC机 上 ， 在 另一台 PC机 上 运行 的 远程 终端 仿真 程序 通过 telnet 远程 登录 到 WAKASHI 所在 的 PC 访问 数据库 . TPC - C 测试 所 要求 的 终端 由 X - Window 系统 的 xterm 模拟 . 每个 启动 的 xterm 就 代表 一个 用户 终端 . 每 一次 测试 持续 8 小时 . 我们 编写 了 Unix   shell 脚本 ( shell   script ) 来 使 所有 的 xterm 在 同一时间 内 运行 ， 并 使用 了 alarm ( ) 函数 来 使 测试程序 在 运行 完 规定 的 时间 后 退出 . 实验 中 的 TPC - C 测试 数据库 大小 为 185MB . 初始状态 时 ， 数据库 中 的 对象 个数 为 ： 1 个 仓库 ( Warehouse ) 、 1   000   000 个 商品 ( Item ) 、 10 个 分店 ( District ) 、 3   000 个 顾客 ( Customer ) 、 1   000   000 个 库存 ( Stock ) 、 30   000 个 历史记录 ( History ) 、 30   000 个 订单 ( Order ) 、 283   998 个 订货 明细 ( OrderLine ) 和 0 个 新 订单 ( New - Order ) . 各种 不同 类型 的 事务 混合 比及 事务 的 等待时间 ( 由 TPC - C 规范 规定 ) 见表 2 . 考虑 单个 用户 ( MPL = 1 ) 时 的 情况 ， 显然 , 单用户 的 MQTh 值 是 与 死锁 检测 机制 无关 的 ， 取 单用户 时 的 MQTh 值 MQTh ( MPL = 1 ) = 1.40 ， 按照 表 2 定义 的 混合 比 和 等待时间 得到 理想 MQTh 与 MPL 的 函数 关系 如下 . 
 MQTh ( MPL = i ) = MQTh ( MPL = 1 ) × i . 　 　 　 　 　 　 　 　 　 　 　 　 ( 1 ) 
 由 公式 ( 1 ) 可知 ， 假设 重启动 率为 0 ， 在 TPC - C 数据库 只有 1 个 仓库 的 情况 下 ， 1 个 仓库 的 10 个 终端 理想 的 MQTh 值为 14.0 tpmC . 
 表 2 　 事务 等待时间 和 混合 比 
 
 事务 类型 事务 混合 比 等待时间 ( sec . ) 
 New - Ordern / a30 
 Payment43.0% 15 
 Delivery4.0% 7 
 Order - Status4.0% 12 
 Stock - Level4.0% 7 
 
 　 　 TPC - C 的 测试 过程 要求 重复 做 如下 4 步 ： ( 1 )   按照 预定 义 的 混合 比 ， 从 5 种 TPC - C 事务 中 选取 1 种 事务 . （ 2 ）   在 屏幕 上 显示 命令 菜单 ， 然后 休眠 一段时间 ， 休眠 时间 按 TPC - C 规范 的 要求 决定 ， 由 变量 keyingtime 控制 . （ 3 ）   执行 所 选定 的 事务 ， 对 数据库 进行 添加 、 删除 、 修改 等 操作 . （ 4 ）   在 屏幕 上 显示 执行 结果 ， 然后 休眠 一段时间 ， 休眠 时间 按 TPC - C 规范 的 要求 决定 ， 由 变量 thinkingtime 控制 . 如前 文 所述 ， 这 5 种 事务 中有 3 种 是 更 新型 事务 ， 再 参考 表 2 所述 的 事务 混合 比 可知 ， 共有 92% 的 TPC - C 事务 是 更 新型 事务 . 因此 ， 锁 冲突 的 发生 随着 用户数 的 增长 而 越发 频繁 .   
 3 　 结果 和 分析 
 　 　 本 节 给出 了 3 种 实验 的 结果 图表 及 性能 分析 ， 表 3 列出 了 所有 的 测试数据 ， 结果 曲线 如图 5 所示 . 
 表 3 　 测试 结果 
 
 　 MQTh 值 重启动 率 
 MPLTimeoutWFGDWDL 理想 值 TimeoutWFGDWDL 
 11.401 . 401.381 . 400.000 . 000.00 
 22.602 . 352.552 . 800.880 . 000.00 
 34.104 . 103.654 . 200.651 . 241.16 
 45.104 . 655.055 . 605.240 . 880.00 
 53.956 . 206.157 . 008.211 . 810.36 
 62.757 . 707.358 . 4015.941 . 472.13 
 70.958 . 458.509 . 8021.903 . 172.63 
 80.659 . 7010.1011 . 2038.543 . 543.07 
 90.5510 . 6510.7512 . 6059.473 . 464.50 
 100.0311 . 5011.1514 . 0061.224 . 646.90 
 11 　 11.8511 . 2015.40 　 8.408 . 82 
 12 　 12.4012 . 1516.80 　 11.3817 . 61 
 13 　 12.5012 . 3018.20 　 13.9317 . 59 
 14 　 13.4513 . 3519.60 　 17.5119 . 82 
 15 　 13.1017 . 5521.00 　 21.4317 . 17 
 16 　 13.1517 . 2522.40 　 28.1721 . 62 
 17 　 18.9515 . 9523.80 　 26.0224 . 15 
 18 　 18.55 　 25.20 　 30.56 　 
 19 　 17.32 　 26.60 　 29.21 　 
 20 　 12.40 　 28.00 　 51.72 　 
 
 
 图 5 　 3 种 试验 的 结果 曲线 
 　 　 ( 1 )   基于 Timeout 方法 的 实验 与 结果 . 由图 5 ( a ) 和表 3 可知 ， Timeout 方法 的 最大 MQTh 值为 5.10 ， 最小 的 MQTh 值为 0.03 ， MQTh 值 的 峰值 出现 在 用户数 为 4 的 时候 . 在 用户数 小于 4 时 ， 由于 事务 的 并发 执行 度 加大 , MQTh 的 值 随 用户数 的 增长 而 递增 . 这 是因为 每个 TPC - C 事务 都 必须 休眠 规定 的 keyingtime 和 thinkingtime 的 时间 ， 用户数 的 增长 导致 事务 的 并发 执行 度 加大 ， 事务 吞吐量 也 随着 并发 执行 度 的 提高 而 提高 . 但是 当 用户数 大于 4 后 ， MQTh 值 随 用户数 的 增长 而 递减 ， 因为 这时 有 更 多 的 事务 并发 执行 ， 数据 的 访问 冲突 加大 ， 由于 锁 的 存在 ， 被 阻塞 的 事务 必须 等待 Timeout - Limit 的 时间 ， 但 此时 较 高 的 事务 并发 执行 度 导致 很多 事务 在 等待 了 Timeout - Limit 的 时间 后 仍旧 没有 得到 锁 ， 于是 越来越 多 的 事务 被 重启动 ， 但 这时 并不一定 发生 了 死锁 . 与 理论 MQTh 值 相比 ， 在 用户数 小于 4 时 , 实测 MQTh 值 与 理想 MQTh 值 比较 吻合 . 这 说明 当 MPL 值 小于 4 时 ， 基于 Timeout 的 死锁 检测 机制 能 使 系统 取得 很 好 的 性能 . 从图 5 ( b ) 可以 看出 ， 事务 的 重启动 率 随着 用户数 的 增加 而 增加 . 在 用户数 小于 4 时 ， 重启动 率 较 低 ， 在 用户数 从 5 ～ 9 的 区间 ， 重启动 率以 平均 60% 的 速度 递增 . 这 就是 在 用户数 大于 4 后 ， MQTh 值 急剧下降 的 原因 . 用户数 大于 9 时 ， 事务 的 重启动 率 反而 没有 很大 的 增加 ， 从 用户数 为 9 到 用户数 为 10 ， 重启动 率仅 增加 了 2% . 因为 这时 不管 大部分 的 死锁 有没有 被 检测 出来 ， 在此之前 ， 由于 系统 负荷 过重 ， 大部分 事务 已经 由于 超时 而 被 重启动 了 . 当然 ， 我们 可以 通过 延长 超时 的 等待时间 Timeout - Limit 来 提高 系统 在 这种 情况 下 的 事务处理 量 ， 可 这种 处理 方法 会 带来 负面影响 ： 在 用户数 较少 的 情况 下 ， 事务 的 并发 执行 度会 很 低 ， 从而 阻碍 了 MQTh 值 的 提高 . 可见 ， 采用 基于 Timeout 的 死锁 检测 机制 要 面临 一个 Timeout - Limit 长度 的 选择 问题 ， 而 事实上 这个 长度 是 很 难 确定 的 ， 因为 它 与 应用 系统 和 负载 水平 等 方面 相关 . 
 　 　 ( 2 )   基于 WFG 方法 的 实验 与 结果 . 由图 5 ( a ) 和表 3 可知 ， WFG 方法 的 最大 MQTh 值为 18.95 ， 最小 MQTh 值为 1.40 ， MQTh 值 的 峰值 出现 在 用户数 为 17 的 时候 ， 在 用户数 小于 17 时 ， MQTh 值 随 用户数 的 增长 而 递增 ， 这 也 是 由于 事务 的 并发 执行 度 加大 的 缘故 . 当 用户数 为 17 时 ， MQTh 值 达到 峰值 . 过 了 峰值 之后 ， 随着 用户数 的 增加 ， MQTh 值 开始 下降 ， 在 19 ～ 20 用户数 区间 ， MQTh 值 急剧下降 . 在 用户数 小于 6 的 情况 下 ， 实测 MQTh 值 与 理想 MQTh 值 吻合 得 较 好 . 从图 5 ( b ) 可以 看出 ， 当 用户数 小于 10 时 ， 事务 的 重启动 率 非常低 ， 而且 在 用户数 小于 19 之前 增长 较 缓慢 ， 用户数 大于 19 后 ， 以 77% 的 速度 急剧 增长 . MQTh 值 和 重启动 率 的 变化趋势 表明 ， WFG 方法 的 性能 在 相当 大 的 一个 MPL 范围 内 是 平稳 增长 的 . 在 用户数 为 16 个 时 的 重启动 率 和 在 用户数 为 19 个 时 的 重启动 率 基本上 相同 ， 但 MQTh 值 在 达到 了 17 个 用户 时 的 峰值 18.95 之后 不再 随 用户数 的 增加 而 增加 . 我们 采用 了 以 邻接 表 储存 等待 图 节点 ， 用 拓扑 排序 检查 有向图 中 环路 的 死锁 检测 算法 . 实验 中 发现 ， 对 任意 复杂 的 含有 20 个 节点 的 等待 图作 拓扑 排序 检查 是否 存在 环路 的 时间 开销 为 10 - 1s ， 要 远远 小于 包括 keyingtime 和 thinkingtime 的 一个 TPC - C 事务 几十秒 的 执行 时间 . 因此 ， 尽管 由于 用户数 的 增长 带来 更 多 的 死锁 检测 开销 ， 但 这些 开销 还 不足以 使 MQTh 值 在 过 了 峰值 之后 而 急剧下降 ( MQTh ( MPL = 17 ) = 18.95 而 MQTh ( MPL = 20 ) 仅为 12.40 ) . 最 根本 的 原因 在于 资源 ( CPU 、 内存 、 I / O 设备 ) 的 拥塞 ， 这时 的 系统资源 被 多个 事务 耗尽 ， 已经 没有 更 多 的 资源 可供使用 ， 因而 制约 了 系统 性能 的 进一步提高 ， 18.95 是 系统 在 本 实验 的 NOPC 环境 下所能 达到 的 最大 MQTh 值 . 
 　 　 ( 3 )   基于 DWDL 方法 的 实验 与 结果 . 由图 5 ( a ) 和表 3 可知 ， DWDL 方法 的 最大 MQTh 值为 17.55 ， 最小 的 MQTh 值为 1.40 ， 在 用户数 小于 15 时 ， MQTh 值 随 用户数 的 增长 而 依次 递增 ， 当 用户数 为 15 时 ， MQTh 值 达到 峰值 . 过 了 峰值 之后 ， 由于 数据 冲突 的 加剧 ， 随着 用户数 的 增加 ， MQTh 值 逐渐 下降 . 相对 于 理想 的 MQTh 值 ， 在 用户数 小于 6 的 情况 下 ， 实测 MQTh 值 逼近 于 理想 MQTh 值 . 从图 5 ( b ) 可以 看出 ， 用户数 小于 10 时 ， 事务 的 重启动 率 非常低 ， 在 用户数 为 10 ～ 12 之间 时 ， 事务 的 重启动 率以 112% 的 速度 急剧 增长 . 在 用户数 大于 12 之后 ， 事务 的 重启动 率 反而 缓慢 增长 , 这 说明 了 基于 DWDL 的 系统 性能 在 重 负载 的 情况 下 不 平稳 ， 也 就 很 好 地 说明 了 MQTh 值 在 用户数 大于 9 之后 会 急剧下降 . 当 用户数 为 17 时 ， 事务 的 高 重启动 率 导致 低 的 MQTh 值 . 
 　 　 ( 4 )   性能 比较 . 从 最大 MQTh 值 角度 来看 ( 见图 5 ( a ) 和表 3 ) ， 基于 WFG 方法 的 最高 MQTh 值为 18.95 ， 基于 Timeout 方法 的 最低 的 MQTh 值为 5.10 ， WFG 比 Timeout 高 了 270% . DWDL 的 最高 MQTh 值为 17.55 ， 但 它 的 峰值 出现 在 用户数 为 15 时 ， 说明 WFG 性能 较 好 . 从 最大 重启动 率 角度 来看 ( 见图 5 ( b ) 和表 3 ) ， 在 用户数 为 10 时 ， 基于 Timeout 的 方法 有 最高 的 重启动 率 61.22 ， 基于 WFG 的 方法 有 最低 的 重启动 率 4.64 . 基于 Timeout 的 方法 比 基于 WFG 的 方法 高 了 1200% ， 比 DWDL 高 了 800% . 这 说明 了 为什么 Timeout 不能 像 WFG 和 DWDL 方法 那样 获得 高 吞吐量 ， 其 原因 是 基于 Timeout 的 死锁 检测 机制 不可避免 地 导致 假死 锁 的 存在 . 按照 TPC - C 规范 ， 在 用户数 为 10 的 情况 下 ， WFG 获得 的 最高 MQTh 值为 11.50 ； Timeout 最低 仅为 0.03 ； DWDL 为 11.15 ， 比 WFG 低 3% . WFG 的 系统 性能 在 这 三者 之间 是 最 平稳 的 . 
 4 　 结   论 
 　 　 本文 描述 了 运行 在 NOPC 环境 下 的 面向对象 数据库系统 Fish 的 TPC - C 测试 实验 , 包括 ： TPC - C 测试 标准 的 OO 设计 、 在 Fish 上 的 TPC - C 测试 的 实现 、 3 种 死锁 检测 机制 的 性能 对比 实验 、 基于 事务 吞吐量 和 重启动 率 的 性能 分析 . 我们 的 测试 结果 和 性能 分析 包括 ： 在 低 MPL 值 的 情况 下 ， WFG ， Timeout ， DWDL 的 性能 都 差不多 ， 实验 值 与 理想 值 吻合 得 较 好 . 在 高 MPL 值 的 情况 下 ， WFG ， DWDL 的 性能比 Timeout 好 ， Timeout 方法 是 三者 中 最差 的 ， 原因 是 其 事务 的 重启动 率太高 . DWDL 在 用户数 为 15 时 出现 峰值 ， 而 WFG 的 峰值 出现 在 用户数 为 17 的 时候 ， 这 说明 在 重 负载 下 的 表现 WFG 要 强于 DWDL . 
 　 　 如 文中 第 1 节所 提到 的 ， MQTh 值 是 TPC - C 测试 中 一个 很 重要 的 衡量 指标 ， 但 因为 硬件平台 对 结果 影响 很大 ， 所以 一个 体现 被 测系统 价格 性能比 的 指标 更能 客观 地 说明 问题 . 正是 基于 这 一点 考虑 ， TPC 委员会 在 TPC - C 规范 中 发布 了 一个 不容忽视 的 价格 性能比 指标 ， 它 被 定义 为 被 测系统 的 价格 除以 MQTh 值 ( 以 美元 计 ) ， 这个 价格 包括 硬件 、 软件 ( 操作系统 和 数据库系统 ) 及其 他 外设 ， 如 UPS 等 的 价格 . 由表 3 可知 ， Fish 系统 的 MQTh 值 应为 11.50 tpmC ， 测试 平台 的 价格 计为 2   000 美元 ， 所得 价格 性能比 为 173.91 ＄ / tpmC ， 在 可比性 强 的 价格 性能比 指标 上己 接近 了 世界 著名 厂商 产品 的 测试 指标 . 例如 ， 运行 在 有 96 个 AlphaCPU 的 Compaq   AlphaServer8400 服务器 上 的 Oracle8.0 所 表现 的 价格 性能比 为 139.49 ＄ / tpmC . 有关 各 厂商 产品 的 TPC - C 测试 结果 可以 从 http : / / www . tpc . org / new - result 网址 得到 . 
 　 　 通过 这次 TPC - C 测试 ， 我们 认为 ， 要 提高 在 多用户 并发 操作 情况 下 的 事务 吞吐量 ， 关键问题 之一 就 在于 通过 改进 事务 调度 和 封锁 机制 来 使 重启动 率 降低 . 但 由于 单台 PC 的 资源 局限性 ， 当 事务 之间 的 资源 竞争 加剧 ， 使 系统 达到 资源 拥塞 点 ( thrash   point ) 时 ， 任何 试图 优化 或 改进 事务 调度 算法 和 封锁 算法 以 获取 更高 事务处理 能力 的 努力 都 将 是 徒劳 的 ， 此时 , 如果 想 在 不 降低 系统 性能 价格比 的 条件 下 取得 较 高 的 事务处理 能力 ， 就 必须 利用 NOPC 的 并行处理 优势 . 因此 , 我们 下 一步 的 工作 将 侧重于 从 以下 两 方面 进行 NOPC 环境 下 的 并行处理 TPC - C 测试 ： ( 1 )   TPC - C 测试 数据库 和 TPC - C 事务 的 分布 化 ， 形成 事务 间 的 并行处理 ; ( 2 )   TPC - C 事务 的 并行 化 ， 形成 事务 内 的 并行 和 面向对象 数据库 的 并行 查询处理 .   
 * 　 本文 研究 得到 第 6 届 霍英东 青年 基金 、 教育部 资助 优秀 年轻 教师 基金 和 辽宁省 自然科学 基金 资助 . 
 本文 通讯联系 人 ： 于戈 ， 沈阳 110006 , 东北大学 计算机科学 与 工程系 
 作者简介 ： 于戈 ， 1962 年生 ， 教授 ， 博士生 导师 ， 主要 研究 领域 为 数据库系统 理论 与 技术 . 
 　 　 　 　 　 王国 仁 ， 1966 年生 ， 教授 ， 主要 研究 领域 为 数据库 集成 ， 面向对象 数据库 ， 并行 数据库 ， 查询处理 . 
 　 　 　 　 　 王欣晖 ， 1973 年生 ， 博士生 ， 主要 研究 领域 为 面向对象 数据库系统 ， 数据库系统 测试 ， 查询处理 . 
 　 　 　 　 　 郑 怀远 ， 1931 年生 ， 教授 ， 主要 研究 领域 为 数据库 理论 和 技术 . 
 作者 单位 ： 东北大学 计算机科学 与 工程系   沈阳   110006 ， E - mail : { yuge , wanggr } @ mail . neu . edu . cn 
 参考文献 ： 
 ［ 1 ］ Jim   G .   The   Benchmark   Handbook .   2nd   ed . ,   New   York :   Morgan   Kaufmann   Publishers ,   Inc . ,   1993 
 ［ 2 ］ Cattell   R ,   Skeen   J .   Object   operations   benchmark .   New   York :   ACM   Transactions   on   Database   Systems ,   1992 , 17 ( 1 ) : 32 ～ 49 
 ［ 3 ］ Carey   N   J ,   DeWitt   D   J ,   Naughton   J   F .   The   OO7   Benchmark .   In :   Buneman   P ,   Sushil   Jajodia   eds .   Proceedings   of   SIGMOD ,   Washington ,   D . C :   ACM   Press ,   1993 .   12 ～ 21 
 ［ 4 ］ Yu   Ge ,   Kaneko   H ,   Bai   Guang - Yi   et   al .   Transaction   management   for   a   distributed   object   storage   system   WAKASHI — — design ,   implementation   and   performance .   In :   Gray   A ,   Larson   Per - Ake   eds .   Proceedings   of   the   12th   ICDE ,   Birmingham ,   U   K :   IEEE   Computer   Society   Press ,   1996 .   380 ～ 389 
 ［ 5 ］ Cattell   R   et   al .   The   Object   Database   Standard   ODMG   2.0 .   New   York :   Morgan   Kaufmann   Publisher ,   Inc . ,   1997 
 ［ 6 ］ Franaszek   P   A   et   al .   Distributed   Concurrency   control   based   on   limited   wait - depth .   IEEE   Transactions   on   Parallel   Distributed   Systems ,   1993 , 11 ( 1 ) : 1246 ～ 1264 
 ［ 7 ］ Transaction   Processing   Performance   Council ( TPC ) .   TPC   BenchmarkTM   C   Standard   Specification   Revision   1.0 .   New   York :   Morgan   Kaufmann   Publishers ,   Inc . ,   1992 
 ［ 8 ］ Bernstein   P   A ,   Hadzilacos   V ,   Goodman   G .   Concurrency   Control   and   Recovery   in   Database   Systems .   Madison :   Addison - Wesley   Publishing   Company ,   1987 
 收稿 日期 ： 1998 - 06 - 02 ， 修改 日期 ： 1998 - 09 - 25 
