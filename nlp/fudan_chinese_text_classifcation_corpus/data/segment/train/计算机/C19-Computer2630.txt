软件 学报 
 JOURNAL   OF   SOFTWARE 
 1999 年   第 10 卷   第 7 期 　 No.7   Vol.10   1999 
 
 
 
 多层 前向 网络 的 交叉 覆盖 设计 算法 
 张 　 铃 　 张 　 钹 　 殷 海风 
 　 　 摘要 　 文章 根据 多层 前向权 、 阈值 神经网络 的 设计 原则 , 将 设计 过程 分成 两步 进行 : 先 用 尽可能少 的 领域 将 样本 中 的 各类 分隔 开来 , 然后 再用 作者 提出 的 交叉 覆盖 算法 进行 网络 设计 . 文章 给出 两个 很 有 代表性 的 模拟 例子 , 一个 是 平面 上 两根 螺线 的 分离 问题 , 另 一个 是 “ 无穷 样本 学习 ” 的 例子 . 模拟 结果 证明 了 此 方法 的 有效性 . 
 　 　 关键词 　 多层 神经网络 , 设计 原则 , 交叉 覆盖 算法 . 
 　 　 中图法 分类号 　 TP18 
 An   Alternative   Covering   Design   Algorithm   of   Multi - layer   Neural   Networks 
 ZHANG   Ling1 , 3 　 ZHANG   Bo2 , 3 　 YIN   Hai - feng1 
 1 ( Institute   of   Artificial   Intelligence   Anhui   University   Hefei   230039 ) 
 2 ( Department   of   Computer   Science   and   Technology   Tsinghua   University   Beijing   100084 ) 
 3 ( Laboratory   of   Intelligent   Technology   and   Systems   Tsinghua   University   Beijing   100084 ) 
 　 　 Abstract 　 In   this   paper ,   the   authors   present   a   new   principle   for   designing   a   sort   of   multi - layer   weight - sum - and   - threshold   neural   networks .   The   design   process   consists   of   two   steps .   First ,   each   class   of   the   given   training   samples   is   covered   by   using   neighbor   coverings   as   less   as   possible .   Then   a   neural   network   is   specifically   designed   by   an   approach   called   alternative   covering   algorithm .   The   simulation   results   of   two   representative   hard   classification   problems   are   shown .   One   is   so   called   “ two   spirals   separation ”   problem ,   the   other   is   “ the   learning   problem   of   infinitetraining   samples ” .   These   simulation   results   are   given   to   illustrate   the   effectiveness   of   the   new   method . 
 　 　 Key   words 　 Multi - layer   neural   network ,   principle   for   design ,   alternative   covering   algorithm . 
 　 　 在 文献 ［ 1 ］ 中 , 我们 利用 M - P 神经元 模型 的 几何 意义 , 给出 一种 设计 神经网络 ( 作为 分类器 ) 的 原则 方法 , 称为 FP 覆盖 算法 . 本文 将 按照 文献 ［ 1 ］ 中 给出 的 构造 FP 覆盖 算法 的 原则 , 深入 地 进行 讨论 , 给出 一种 常用 的 覆盖 算法 , 暂且 称之为 “ 交叉 覆盖 算法 ” . 本 算法 在 一定 意义 上 解决 了 多年 来 一直 未 解决 的 ( 作为 分类器 ) 多层 前向 网络 的 设计 问题 . 最后 给出 两个 模拟 的 例子 , 并 指出 本 算法 可以 用来 解决 “ 无穷 样本 的 学习 问题 ” ( 而 无穷 样本 学习 问题 用 其他 学习 算法 是 无法 解决 的 ) , 这 充分说明 本 算法 的 有效性 . 为 方便 读者 阅读 , 下面 简单 介绍 文献 ［ 1 ］ 中 所用 到 的 一些 内容 ( 详细情况 见 文献 ［ 1 ］ ) . 
 　 　 M - P 神经元 模型 的 几何 意义 简介 . 
 　 　 若 我们 限定 输入 向量 的 长度 相等 , 即 输入 向量 是 限定 在 n + 1 维空间 的 某个 球面 Sn 上 ( 其 中心 在 原点 , 半径 为 R ) , 那么 这时 ( W * x - θ ) > 0 ( 其中 W 是 权 向量 , θ 是 阈值 ) , 就 表示 球面 上落 在 由 超平面 P ( 其 方程 为 : ( W * x - θ ) ＝ 0 ) 所 分割 的 正半 空间 的 部分 , 这个 部分 恰好 是 球面 上 的 某个 “ 球形 领域 ” . 若取 W 与 x 等长 , 则 这个 “ 球形 领域 ” 的 中心 恰好 是 W , 其 半径 为 r ( θ ) ( r ( θ ) ＝ R ( cos - 1 ( θ / R2 ) ) , 如图 1 所示 . 
 
 
 （ a ） 超平面 P 与 超 球面 相交 ， 形成 “ 球形 领域 ” 的 示意图 （ b ） 从 D → Sn 变换 的 示意图 
 图 1 
 
 
 　 　 若 我们 令 , 且取 神经元 的 激励函数 为 σ ′ ( W * x - θ ) , 则 一个 神经元 的 激励函数 正好 是 它 所 代表 的 球面 上 “ 球形 领域 ” 的 特征函数 , 这样 , 我们 就 将 神经元 与 球面 上 的 球形 领域 对应 起来 . 利用 神经元 的 这种 几何 意义 , 我们 就 能 非常 直观 地 进行 神经网络 的 各种 研究 . 
 　 　 由 上面 给出 的 神经元 的 几何 意义 得知 , 构造 一个 网络 , 使 对 给定 的 样本 集能 进行 符合要求 的 分类 , 等价 于求 出 一组 领域 , 对 给定 样本 集 K 中 的 点 , 能 按 分类 的 要求 用 领域 覆盖 将 它们 分隔 开来 . 这样 , 我们 就 将 神经网络 的 最优设计 问题 转化成 某种 求 最优 覆盖 的 问题 . 
 　 　 当 给定 的 输入 向量 的 长度 不 相等 时 , 可用 下面 给出 的 方法 , 将 它 变换 成 长度 相等 的 情况 . 
 　 　 设 输入 的 定义域 为 n 维空间 中 的 有界 集合 D , 令 Sn 是 n + 1 维空间 中 的 n 维 的 超 球面 , 作 变换 
 　 　 　 　 　 　 　 　 
 其中 d ≥ max { ｜ x ｜ ｜ x ∈ D } . 
 　 　 这个 变换 可 从 几何 上 直观 地 理解 为 : 将 D 看成 是 位于 n + 1 维空间 中过 原点 的 一个 n 维 超平面 上 , 而且 D 位于 Sn 的 内部 , 则 变换 T 就是 将 D 上 的 点 垂直 投射 到 Sn 的 上 半球 面上 . 这种 变换 显然 是 一一对应 的 . 如 上面 所述 , 这时 每 一个 神经元 ( W , θ ) 就是 在 超 球面 Sn 上 , 以 W 为 中心 , 以 r ( θ ) 为 半径 的 一个 “ 球形 领域 ” 的 特征函数 ( 其中 r ( θ ) ＝ r ( cos - 1 ( θ / R2 ) ) ) . 
 1 　 多层 前向 神经网络 的 交叉 覆盖 设计 算法 
 1.1   问题 的 提出 
 　 　 设 给定 一 输入 集 K ＝ { x1 , x2 , ... , xk } ( K 是 n 维 欧氏 空间 的 点集 ) , 设 K 分为 s 个 子集 K1 ＝ { x1 , x2 , ... , xm ( 1 ) } , ... , Ks ＝ { xm ( s - 1 ) + 1 , xm ( s - 1 ) + 2 , ... , xk } . 现求作 一个三层 网络 N , 满足 : 通过 这个 网络 后 , 属于 Ki 的 点 的 输出 均 为 “ yi ” , 其中 yi ＝ ( 0 , ... , 1 , 0 , ... , 0 ) ( 即 其 第 i 个 分量 为 1 , 其余 分量 为 0 的 向量 ) . i ＝ 1 , 2 , ... , s . 
 　 　 下面 , 为 讨论 方便 , 令 s ＝ 2 , 且 令 y1 ＝ 1 , y2 ＝ - 1 . 
 1.2   交叉 覆盖 算法 
 　 　 由 文献 ［ 1 ］ 知 , 用 三层 神经网络 构造 分类器 , 等价 于求 出 一组 领域 , 这组 领域 能 将 不同 类 的 点 分隔 开来 . 下面 , 我们 给出 一个 称为 “ 交叉 覆盖 法 ” 的 算法 . 其 主要 思路 是 : 先求 一个 领域 C1 , 它 只 覆盖 K1 中 的 点 , 而 不 覆盖 K2 中 的 点 , 然后 将 被 C1 覆盖 的 点 删去 . 对 余下 的 点求 另 一 领域 C2 , 它 只 覆盖 K2 的 点 , 而 不 覆盖 K1 的 点 , 然后 将 被 C2 覆盖 的 点 删去 , ... , 如此 交叉 进行 覆盖 , 直到 K1 ( 或 K2 ) 的 点 全部 被 删除 为止 . 
 　 　 在 上面 求 Ci 时 , 当然 希望 它 覆盖 的 点 越多越好 , 因为 这样 就 能 用 较 少 的 领域 完成 覆盖 的 任务 , 也 就是 , 说 所 得到 的 网络 的 元件 个数 就 越少 . 下面 给出 一个 求 Ci 的 方法 ( 此法 未必 能求 到 最优 的 领域 Ci , 但 一般 可 得到 较优 的 领域 ) . 其 求法 的 要点 是 : 用 “ 求 重心 ＋ 求 领域 ” 和 “ 平移 ＋ 求 领域 ” 交互进行 , 求得 较 好 的 领域 Ci . 
 　 　 算法 1 .   求 交叉 覆盖 的 步骤 
 　 　 首先 将 K1 , K2 的 点 映射 到 球面 Sn 上 ( Sn 是 n + 1 维空间 中 , 中心 在 原点 , 半径 ＝ R 的 n 维 球面 , 取其 半径 R ＞ max | xi | ) 仍记 为 K1 , K2 . 
 　 　 第 1 步 : 作一 覆盖 C ( i ) ( 开始 时 i ＝ 1 ) , 它 只 覆盖住 K1 的 点 , 被 C ( i ) 覆盖 的 K1 中 的 子集 为 K1i , 
 　 　 令 K2 ← K1 / K1i , K1 ← K2 , 若 K1 或 K2 为 空集 , 停止 . 否则 , i ＝ i + 1 , 返回 第 1 步 . 
 　 　 由 算法 1 求到 一个 覆盖 集合 , 记为 C ＝ { C1 , C2 , ... , Cp } . 
 　 　 网络 设计 : 
 　 　 第 1 元件 层 , 取 p 个 元件 A1 , A2 , ... , Ap , 其中 Ai 为 对应 于 Ci 的 神经元 , i ＝ 1 , 2 , ... , p . 其 功能 函数 暂设 为 特征函数 . 
 　 　 第 2 层取 一个 p 输入 的 神经元 B , 设其权 阈值 为 ( u , a ) , ui 和 a 可 由 下面 的 方法 求得 ( 不妨 设 最后 K1 为 空集 , 而 K2 不为 空集 , 以及 K1 对应 的 输出 为 1 , K2 对应 的 输出 为 - 1 ) : 
 　 　 　 　 　 　 　 　 　 　 　 　 - a ＜ 0 　 ( 剩下 的 K2 对应 的 方程 ) , 
 　 　 　 　 　 　 　 　 　 　 　 up - a ＞ 0 　 ( 第 p 个 覆盖 中 各点 满足 的 方程 ) , 
 　 　 　 　 　 　 　 　 　 up - 1 + up - a ＜ 0 
 　 　 　 　 　 　 　 或   up - 1   ... - a ＜ 0 　 ( 第 p - 1 个 覆盖 中 的 各点 满足 的 方程 ) , 
 　 　 u1 + b2u2 + b3u3 +...+ bpup - a ＞ 0 　 ( 第 1 个 覆盖 中 的 各点 满足 的 方程 ) , 
 其中 bi 取 1 或 0 , 由 各点 的 具体情况 而定 . 不管 bi 取何值 , 上 式 一定 有解 . 可取 a ＝ 1 , up ＝ 2 , up - 1 ＝ - 2 , up - 2 ＝ 4 , 一般 
 　 　 这样 的 网络 就 构成 分类器 , 将 K 分为 K1 和 K2 ( 即 对应 于 K1 ( K2 ) 中 的 点 , 其 输出 ＝ 1 ( - 1 ) ) . 
 　 　 注 : 按 上述 方法 求到 的 输出 层 神经元 的 权 系数 , 将 随 样本 个数 的 增加 , 呈 指数 增加 . 为 避免 这个 问题 , 我们 可以 增加 一个 隐层 , 则 可 使 输出 层 的 权 系数 至多 只 按 样本数 呈 线性 增加 . 
 　 　 算法 2 .   求 覆盖 C ( i ) 的 步骤 
 　 　 第 1 步 : 若 K1 或 K2 有 一个 是 空集 , 则 停止 ; 否则 ( 不妨 设 K1 ≠ ) 任取 ai ( 开始 时 , j ＝ 1 , i ＝ 1 ) 属于 K1 . 
 　 　 第 2 步 : 求以 ai 为 中心 的 领域 C ( ai ) . 令 C ( ai ) ∩ K1 ＝ Di , i ＝ 1 , 2 , ... , D0 ＝ , 
 　 　 ［ C ( ai ) 对应 的 权 和 阈值 ( Wi ＝ ( wij ) , θ ＝ ( θ i ) ) , 可 按 下面 的 公式 求得 : 
 令 　 　 　 　 　 　 　 　 　 　 　 　 
 　 　 　 　 　 　 　 　 　 　 　 　 
 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 θ i ＝ d ( i ) , 
 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 W ＝ ( ai ) , θ ＝ ( θ i ) ］ . 
 　 　 第 3 步 ( 求 重心 ) : 若 Di - 1 是 Di 的 真 子集 , 则 求 Di 重心 a - , 令 ai + 1 ←   a - , i ← i + 1 , 返回 第 2 步 . 否则 , 进入 第 4 步 . 
 　 　 第 4 步 ( 平移 ) : 求 ai 的 平移 点 a ′ , 令   ai + 1 ＝ a ′ ( a ′ 的 求法 见 算法 3 ) , 并求 对应 的 领域 C ( ai + 1 ) ( 求 领域 C 时 , 需将 ai - 1 投射 到 球面 上 ) , 得 Di + 1 . 
 　 　 若 Di 是 Di + 1 的 真 子集 , 则 求 Di + 1 重心 a - , 令 ai + 1 ← a - , i ← i + 1 , 返回 第 2 步 . 
 　 　 否则 , 令 Cj ＝ C ( ai ) , 这样 我们 就求 到 一个 覆盖 Cj . 
 　 　 然后 , 将 被 Cj 覆盖 的 点 删去 , 即令   K1j ＝ Cj ∩ K1 , K2 ← K1 / K1j , K1 ← K2 , j ← j + 1 , 回到 算法 1 的 第 1 步 , 求 另 一个 覆盖 . 最后 得到 一组 领域 { C1 , C2 , ... , Cp } . 
 　 　 算法 3 .   求 平移 算法 ( 求 a 的 平移 点 a ′ ) 
 　 　 设 a ∈ K1 , , 其中 d ( a , x ) 表示 a 与 x 的 距离 . 
 　 　 第 1 步 : 若 | B | ＝ k ＞ n , 则 取 a ′ ＝ a . 若 成功 , 则 停止 . 
 　 　 否则 , 求 a 到 P ( B ) ( 其中 P ( B ) 是 由 B 构成 的 线性 流型 ) 的 垂足 b , 令 P ( k ) ＝ P ( B ) , 再 对 每个 x ∈ K2 / P ( k ) , 求 d ( x ) : 
 　 　 　 　 　 　 　 　 　 　 　 　 
 其中 c 是 P ( k ) 中 的 任 一点 . 
 　 　 若 存在 x : 〈 a , c - x 〉 ＝ 0 , 则 令 x ＝ ck + 1 , 取 a ′ ＝ a , 令 P ( k + 1 ) ＝ P ( k ) ∪ { ck + 1 } . 进入 第 2 步 . 
 　 　 否则 , 令 
 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 　 ( 1 ) 
 令 　 　 　 　 　 　 　 　 　 　 　 　 　 　 
 其中 R 是 球面 Sn 的 半径 . 即将 ( a - db ) 的 向量 投影 到 Sn 球面 上 . 再取 ck + 1 ＝ x * . 
 　 　 第 2 步 : 令 P ( k + 1 ) ＝ P ( k ) ∪ { ck + 1 } ( 这里 , 我们 为 简单 起 见 , 用 P ( k ) ∪ { ck + 1 } 表示 由 P ( k ) 和 ck + 1 构成 的 线性 流型 ) . 
 　 　 若 k + 1 ＞ n , 则 a ′ 为 所求 . 若 成功 , 则 停止 . 
 　 　 否则 , 求 a ′ 到 P ( k + 1 ) ( 开始 时 , k ＝ | B | ) 的 投影 bk + 1 , 令 b ＝ bk + 1 , a ＝ a ′ , k ← k + 1 , 返回 第 1 步 . 
 　 　 求 投影 算法 . 
 　 　 设 P ( k ) ＝ { c1 , c2 , ... , ck } ( P ( k ) 是 算法 3 中所 定义 的 P ( k ) ) , a 不 属于 由 P ( k ) 构成 的 流型 ( 仍记 为 P ( k ) ) , 求 a 到 P ( k ) 的 投影 . 
 　 　 我们 可用 先求 归一化 的 正交 基 , 然后 再 用求 投影 的 方法 来求 投影 . 
 　 　 求 P ( k ) 的 正交 归一化 基的 方法 为 
 　 　 　 　 　 　 　 　 P ( k ) ＝ { c1 , c2 , ... , ck } , di ＝ ci - c1 ,   i ＝ 2 , ... , k , 
 令 　 　 
 于是 , 求 a 到 P ( k ) 的 投影 为 
 　 　 　 　 　 　 　 　 　 　 
 　 　 这样 , 当 P ( k - 1 ) 的 正交 基已 求得 , 再求 P ( k ) 的 正交 归一化 基时 , 只要 再求 ek , 连同 e1 , ... , ek - 1 , 就 构成 P ( k ) 的 正交 归一化 的 基 . 
 　 　 下面 我们 要 证明 的 是 , 按 算法 3 , 将 a 平移 后 得到 a ′ 点 , 若以 a ′ 为 中心 , 作只 覆盖 K1 点 的 领域 , 则 此 领域 的 半径 比以 a 为 中心 , 只 覆盖 K1 点 的 领域 的 半径 大 . 这样 就 证明 了 , 通过 平移 , 有 可能 求到 覆盖 更 多 K1 点 的 领域 . 
 　 　 命题 1 .   设 a , P ( k ) 是 算法 3 中 对应 的 符号 , 则 有 a 到 P ( k ) 中 各点 的 距离 相等 . 
 　 　 证明 : 当 k ≤ | B | 时 , 由 B 的 定义 知 , 命题 结论 成立 , 现 用 归纳法 加以 证明 . 
 　 　 若 存在 x : 〈 a , c - x 〉 ＝ 0 , 由 〈 a , c 〉 ＝ 〈 a , x 〉 , 直接 得 d ( a , c ) ＝ d ( a , x ) ; 若求 到 x * , 取 ck + 1 ＝ x * , 由 d ( x * ) ＝ , 得 〈 a - d ( x * ) b , c 〉 ＝ 〈 a - d ( x * ) b , x * 〉 , 故有 d ( a ′ , c ) > ＝ d ( a ′ , x * ) ＝ d ( a ′ , ck + 1 ) . 　 　 □ 
 　 　 命题 2 .   设 a ′ 是 a 按 算法 3 求到 的 平移 点 , 则 C ( a ) C ( a ′ ) , 且 C ( a ′ ) 只 覆盖 K1 的 点 . 
 　 　 证明 : 作 C ( a ′ ) ( C ( a ) ) 是 以 a ′ ( a ) 为 中心 , 以 a ′ ( a ) 到 c ( c 是 P ( k ) 中 的 任 一点 ) 的 距离 为 半径 的 领域 , 于是  C ( a ′ ) ( C ( a ) ) 的 方程 为 〈 a ′ , x - c 〉 ＞ 0 ( 〈 a , x - c 〉 ＞ 0 ) . 下面 证明 , 若 x 满足 〈 a , x - c 〉 ＞ 0 , 则 x 一定 也 满足 〈 a ′ , x - c 〉 ＞ 0 . 
 　 　 由于 当 x 落 在 C ( a ) 内时 , 有 d ( x ) ＝ , 于是 〈 a ′ , x - c 〉 ＝ 〈 a - d ( x * ) b , x - c 〉 ＝ 〈 a , c - x 〉 - d ( x * ) 〈 b , c - x 〉 , 由 〈 a , c - x 〉 ＞ 0 及 d ( x ) ＜ 0 得 , 〈 b , c - x 〉 ＜ 0 , 故有 〈 a ′ , c - x 〉 ＞ 0 , 即 x 也 属于 C ( a ′ ) , 得 C ( a ) C ( a ′ ) . 
 　 　 另外 , 由 d ( x * ) 的 定义 易得 , C ( a ′ ) ( C ( a ) ) 只 覆盖 K1 的 点 . 　 □ 
 　 　 由 命题 1 、 2 知 , 按 算法 3 求 平移 点 所 得到 的 对应 的 领域 , 覆盖 K1 点 的 范围 将会 越来越 大 , 这 正是 我们 所 要 达到 的 目的 . 
 　 　 注 : 我们 这里 给出 的 只是 求 覆盖 领域 的 方法 之一 . 此 方法 未必 能 保证 每次 求到 的 领域 C ( a ) 覆盖 K1 的 点 达到 最 多 , 故 算法 还有 改进 的 余地 . 
 2 　 模拟 结果 
 　 　 本 节 给出 两个 很 有 代表性 的 例子 , 由 这些 例子 就 可 看出 本文 所 给出 的 方法 的 潜力 . 
 　 　 例 1 : 平面 上 双螺旋 线 的 识别 问题 ( 如图 2 所示 ) . 
 
 曲线 为 双螺旋 线 ， ○ 及 △ 表示 两类 训练样本 点 
 图 2 　 平面 双螺旋 分类 问题 
 　 　 设 K1 是 在 极 坐标系 中 曲线 r ＝ θ 上 的 子集 , K2 是 在 极 坐标系 中 曲线 r ＝ － θ 上 的 子集 , π / 2 ≤ θ ≤ 6 π . 
 　 　 K1 ( K2 ) 上 各有 77 点 , 其 θ 值为 θ ＝ i π / 2 , i ＝ 1 , ... , 12 , 以及 π / 2 到 π , 取 二等 分点 , π 到 3 π / 2 取 三等分 点 , 一般 i π / 2 到 ( i + 1 ) π / 2 区间 取 i + 1 等 分点 . 
 　 　 求 一个三层 前向 神经网络 , 将 K1 , K2 分开 . 这个 例子 是 神经网络 学习 中 有名 的 难 学习 的 问题 之一 . 
 　 　 在 文献 ［ 2 ］ 中 , Raum 等 人用 BP 算法 求解 双螺旋 线 问题 , 结果 失败 了 . 在 文献 ［ 3 ］ 中 , Chen 等 人 提出 “ 生成 - 收缩 ” 法 , 来 求解 双螺旋 线 学习 问题 , 经过 3   000 次 的 迭代 , 得到 一个 解 , 此解 识别 的 正确率 只有 89.6% . 在 文献 ［ 4 ］ 中 , Fahlman 等 人用 “ 级联 式 ” 网络结构 才 勉强 解决 了 双螺旋 线 学习 问题 , 所得 的 网络 要 用 几十个 神经元 . 可见 此 问题 的 难度 . 下面 我们 用 交叉 覆盖 算法 求解 此 问题 , 得到 了 非常 令人满意 的 结果 . 
 　 　 解 : 用 交叉 覆盖 算法 求解 此 问题 , 得 网络 第 1 层 共有 10 个 神经元 ( 如图 3 所示 , 其中 椭圆 是 各 领域 在 二维 平面 上 的 投影 ) . 第 2 层仅 一个 神经元 , 整个 网络 共用 11 个 神经元 . 网络 对 样本 的 分类 正确率 为 100% . 
 
 
 　 　 ( a ) 训练 数据 为 双螺旋 上 156 个 样本 点 　 　 ( b ) 训练 数据 为 20   000 个 数据 点 
 　 　 图中 黑色 表示 网络 所 划分 的 第 1 类 样本 的 覆盖 区域 , 白色 表示 第 2 类 样本 的 覆盖 区域 , ○ 及 △ 表示 两类 训练样本 点 
 　 　 图 3 　 采用 逐次 覆盖 法对 平面 双螺旋 分类 问题 的 求解 结果 
 
 
 　 　 然后 我们 在 曲线 r ＝ θ ( r ＝ － θ ) 上 随机 各取 1 万个 点 作为 测试 样本 , 输入 所 得到 的 网络 进行 识别 , 正确率 达到 98.245% . 另外 , 我们 又 随机 地 在 K1 , K2 上 各取 1 万个 点 作为 样本 点 , 然后 进行 学习 , 仍 得到 10 个 神经元 ( 其 在 二维 上 的 投影 如图 3 ( b ) 所示 ) , 这时 不但 其 分类 的 正确率 为 100% , 而且 我们 在 两类 中 各 随机 取 1 万个 点 进行 识别 , 其 识别 正确率 也 达到 99.995% . 
 　 　 另外 , 我们 还 进行 了 平面 三 螺旋线 和 三维空间 三 螺旋线 的 学习 问题 , 都 得到 了 非常 令人满意 的 结果 , 见表 1 . 
 　 　 　 　 表 1 　 用 交叉 覆盖 算法 学习 的 情况表 
 
 问题 训练样本 
 ( 样本数 ) 学习 时间 覆盖 数 测试 样本 
 ( 样本数 ) 识别率 ( % ) 
 平面 双螺旋 线 1   ( 156 ) 
 2 ( 20   000 ) ＜ 1ms 
 5.16 s10 
 10 ( 20   000 ) 
 ( 20   000 ) 98.245 
 99.995 
 平面 三 螺旋线 1   ( 234 ) 
 2 ( 30   000 ) 0.06 s 
 14.61 s24 
 26 ( 30   000 ) 
 ( 30   000 ) 91.11 
 99.067 
 空间 三 螺旋线 1   ( 183 ) 
 2 ( 30   000 ) 0.07 s 
 19.34 s28 
 37 ( 30   000 ) 
 ( 30   000 ) 96.293 
 99.653 
 
 
 　 　 例 2 : 求 三维空间 上 两根 螺旋线 的 识别 问题 . 
 　 　 设在 柱 坐标系 中 , K1 ＝ { ( θ , r , z ) | z ＝ θ , r ＝ 1 , 0 ≤ θ ≤ 4 π } , K2 ＝ { ( θ , r , z ) | z ＝ θ ＋ π , r ＝ 1 , 0 ≤ θ ≤ 4 π } , 求 一个三层 前向 神经网络 将 K1 , K2 分开 . 
 　 　 注 : 例 2 是 一个 无穷 样本 的 识别 问题 , 用 其他 方法 ( 如 BP 算法 ) 是 无法 解决 的 . 用 本文 提供 的 方法 , 可以 比较 圆满 地 解决 这个 学习 问题 . 
 　 　 解 : 用 交叉 覆盖 设计 法 ( 要求 覆盖住 K1 , K2 曲线 上 的 所有 点 ) 求得 的 网络 , 第 1 层 10 个 元件 , 第 2 层 1 个 元件 . 
 　 　 我们 随机 地 在 曲线 K1 和 K2 上共取 30   000 个点 , 当作 测试 样本 输入 所得 的 网络 进行 识别 , 结果 全部 识别 正确 . 
 　 　 上面 的 两个 例子 可以 充分说明 本文 所 给 的 设计 方法 的 有效性 . 此 两例 若用 其他 算法 ( 如 各种 改进 过 的 BP 算法 ) 进行 设计 将 是 相当 困难 的 .   
 3 　 结束语 
 　 　 本文 利用 M - P 神经元 模型 的 几何 意义 得出 一个 领域 覆盖 的 设计 算法 . 这个 算法 在 一定 意义 上 考虑 到 网络 的 结构 优化 问题 ( 指 网络 的 规模 最小 ) , 并且 方法 切实可行 , 从而 解决 了 多年 来 一直 未能 很 好 地 得到 解决 的 多层 前向 网络 的 设计 问题 . 本文 给出 的 几个 模拟 例子 也 充分说明 了 本 方法 的 潜力 . 
 　 　 另外 , 我们 这里 给出 的 覆盖 设计 算法 只是 领域 覆盖 设计 算法 中 的 一个 特例 , 任何 一个 求 最小 ( 次 小 ) 覆盖 算法 与 本文 提出 的 设计 原则 相结合 , 都 可 得出 一个 新 的 设计 算法 . 这 就 给 研究 网络 设计 问题 开辟 了 一个 新途径 . 
 　 　 致谢 　 清华大学 的 李凌 同学 为 本文 的 表 1 提供 了 模拟 例子 , 在 此 表示感谢 . 
 　 　 本文 研究 得到 国家自然科学基金 和 国家 863 高科技 项目 基金 资助 . 作者 张铃 , 1937 年生 , 教授 , 主要 研究 领域 为 人工智能 理论 , 人工神经网络 理论 . 张钹 , 1935 年生 , 教授 , 博士生 导师 , 中国科学院 院士 , 主要 研究 领域 为 人工智能 理论 及 应用 , 计算机 应用 技术 . 殷 海风 , 1970 年生 , 硕士 , 主要 研究 领域 为 人工神经网络 理论 及 应用 . 
 　 　 本文 通讯联系 人 : 张铃 , 合肥 230039 , 安徽大学 人工智能 研究所 
 　 　 作者 单位 ： [ 张 　 铃 （ 清华大学 智能 技术 与 系统 国家 重点 实验室 　 北京 　 100084 ） ； 殷 海风 ( 安徽大学 人工智能 研究所 　 合肥 　 230039 ) ] 　 张 　 钹 ( 清华大学 计算机科学 与 技术 系 　 北京 　 100084 、 清华大学 智能 技术 与 系统 国家 重点 实验室 　 北京 　 100084 ) 
 　 　 E - mail :   zling @ mars . ahu . edu . cn 
 参考文献 
 　 1 　 张铃 , 张钹 . M - P 神经元 模型 的 几何 意义 及其 应用 . 软件 学报 , 1998 , 9 ( 5 ) : 334 ～ 338 
 　 　 ( Zhang   Ling ,   Zhang   Bo .   A   geometrical   representation   of   M - P   neural   model   and   its   applications .   Journal   of   Software ,   1998 , 9 ( 5 ) : 334 ～ 338 ) 
  2 　 Baum   E    B ,   Lang   K    J .   Constracting   hidden   units   using   examples   and    queries .  In :   Lippman   R   P   et   al    eds .   Neural   Information   Processing .   San   Mateo ,   CA :   Morgan   Kaufmann   Publishers ,   Inc . ,   1991 .   904 ～ 910 
 　 3 　 Chen   Q   C   et   al .   Generating - shrinking   algorithm   for   learning   arbitrary   classification .   Neural   Networks ,   1994 , 5 ( 7 ) : 1477 ～ 1489 
 　 4 　 Fahlman   S   E ,   Lebiere   C .   The   cascade - correlation   learning   archtecture .   In :   Tourdtzhy   D   S   ed .   Advances   in   Neural   Information - processing   System .   San   Mateo ,   CA :   Morgan   Kaufmann   Publishers ,   Inc . ,   1990 .   524 ～ 532 
 1998 - 01 - 16 收到 原稿   
 1998 - 08 - 24 收到 修改稿 
