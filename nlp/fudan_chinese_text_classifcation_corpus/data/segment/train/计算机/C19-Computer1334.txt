自动化 学报 
 ACTA   AUTOMATICA   SINICA 
 1997 年   第 23 卷   第 1 期   Vol.23   No.1   1997 
 
 
 
 多层 前向 网络 的 研究 
 — — 遗传 BP 算法 和 结构 优化 策略 
 陈荣 　 徐用 懋 　 兰鸿森 
 摘 　 要 　 分析 了 引起 BP 算法 局部收敛 现象 的 原因 ， 探讨 了 解决 的 途径 . 通过 对 遗传算法 中 的 基因 群体 的 实数 化 ， 并 将 其 与 BP 算法 有机 地 集成 起来 ， 提出 了 遗传 BP 算法 . 此外 ， 在 借鉴 网络 剪枝 法 思想 的 基础 上 ， 重新 定义 网络结构 复杂度 函数 ， 并 以 遗传算法 直接 求解 网络结构 优化 问题 ， 给出 了 网络结构 优化 策略 . 仿真 结果 和 实际 应用 均 表明 了 上述 研究 的 成效 . 
 关键词 　 人工神经网络 ， 遗传算法 ， BP 算法 ， 结构 优化 . 
 RESEARCH   ON   MULTILAYER   FEEDFORWARD   NEURAL   NETWORKS 
 — — GENETIC   BACKPROPAGATION   ALGORITHM   &   STRUCTURE 
 OPTIMIZATION   STRATEGY 
 CHEN   RONG   XU   YONGMAO 
 ( Department   of   Automation ,   Tsinghua   University ,   Beijing   100084 ) 
 LAN   HONGSEN 
 ( Fujian   Refinery ,   Fujian   Hui ' an   362100 ) 
 Abstract 　 In   this   paper ,   when   classical   genetic   algorithms   are   applied   to   the   region   of   real   number   and   integrated   with   BP   algorithm ,   a   hybrid   GA - BP   learning   algorithm   is   proposed .   Besides ,   with   the   aid   of   genetic   algorithms   as   well   as   the   improvement   of   network   complexity   function ,   a   structure   optimization   strategy   which   is   on   the   basis   of   network   stripping   is   proposed .   The   efficiency   of   research   work   mentioned   above   has   been   shown   by   numerical   simulations   and   industrial   applications .   
 Key   words   Artificial   neural   networks ,   genetic   algorithms ,   backpropagation   algorithm ,   structure   optimization . 
 1 　 引言 
 　 　 在 当前 已有 的 诸多 人工神经网络 中 ， 多层 前向 网络 是 在 实际 中 应用 最为 广泛 的 一类 . 关于 它 的 研究 有 两大 方面 ： 学习 算法 和 结构 优化 . 其中 ， BP 算法 ( Backpropagation   Algorithm ) 是 目前 使用 最为 普遍 的 网络 学习 算法 ， 但 存在 着 收敛 速度慢 、 可能 陷入 局部 极小 点 这 两个 突出 弱点 . 一般而言 ， 可以 采取 动态 调整 确定 学习 步幅 、 自 适应 改变 惯性 系数 等 措施 来 加快 BP 算法 的 收敛 速度 ； 而 为了 克服 局部收敛 ， 则 必须 彻底 摆脱 依赖 梯度 信息 来 指导 权值 调整 方向 这种 方式 . 
 　 　 长期以来 ， 网络 的 结构 单凭 经验 而定 ， 为 保障 精度 往往 偏向 于 冗余 ， 这 将 造成 ： 第一 ， 网络 训练 过程 所 需 时间 加长 ， 增加 了 学习 算法 在 训练 速度 上 的 负担 ， 不利于 网络 的 在线 适应性 ； 第二 ， 所得 网络 的 高精度 很 可能 是 冗余 节点 存在 的 结果 ， 因而 极易 具有 病态 ， 表现 为 对于 训练样本 之外 的 数据 其 精度 急剧下降 ， 网络 的 泛化 能力 弱 . 所以 ， 应当 科学 地 确定 网络结构 . 
 2 　 遗传 BP 算法 
 　 　 遗传算法 ( Genetic   Algorithms ,   简称 GAs ) 是 根据 达尔文 的 自然界 生物进化 思想 ， 将 其 灵活运用 到 优化 运算 领域 而 产生 的 一种 寻优 算法 ［ 1 ， 3 ， 4 ］ ， 它 具有 以下 优点 ： 
 　 　 1 ) 在 可行 解 空间 同时 由 多个 起始 点 开始 搜索 ， 搜索 效率高 ； 
 　 　 2 ) 本质 上 属于 随机 寻优 过程 ， 不 存在 局部收敛 问题 ； 
 　 　 3 ) 不 要求 准则 函数 可导 ， 可 用于 求解 非 连续函数 优化 问题 . 
 　 　 它 的 缺点 在于 ： 
 　 　 1 ) 通过 参数 的 二进制 编码 字符串 间接 运算 ， 人为 将 连续 空间 离散 化 ， 导致 计算精度 与 字符串 长度 、 运算量 之间 的 矛盾 ； 并且 对于 那些 变量 取值 范围 不 明确 的 问题 ( 例如 求取 人工神经网络 权值 的 问题 ) 也 无从 编码 . 
 　 　 2 ) 完全 依 概率 随机 进行 的 寻优 操作 虽 避免 了 陷入 局部 极小 点 ， 但 在 有限 次 寻 优时 一般 只能 得到 全局 范围 的 次优 解 ， 不易 获取 最优 解 . 
 　 　 针对 以上 问题 本文 做 如下 工作 ： 
 　 　 1 ) 取消 二进制 编码 ， 直接 将 待处理 的 参数 数值 ( 实数 ) 逐位 数字 地 转化 为 数字 字符 ( 形成 字符串 ) ， 之后 便 可以 完全 类似 于 遗传算法 对 二进制 字符串 的 处理 ， 以 相同 方式 对此 实数 型 字符串 进行 选择 ( selection ) 、 交叉 ( crossover ) 操作 ， 不同之处 在于 发生 变异 ( mutation ) 时 ， 不再 是 原 二进制 字符 “ 0 ” 、 “ 1 ” 之间 的 跳变 ， 而 将 按模 10 和 的 运算 或 M 序列 的 产生 来 完成 . 例如 ， 对 如下 两个 随机数 ： 3.141592 ， 2.718030 ， 经 数字 → 字符 转换 ， 生成 第一代 基因 ： 
 
 3.141592 
 
 和 
 
 2.718030 
 
 　 　 若取 第一代 基因 的 后 三位 进行 交叉 操作 ， 则 演化 为 第二代 基因 ： 
 
 3.141030 
 
 和 
 
 2.718592 
 
 　 　 再取 第二代 基因 的 第一位 按模 10 和 进行 变异 操作 ， 则 形成 第三代 基因 ： 
 
 7.141030 
 
 和 
 
 8.718592 
 
 　 　 当然 ， 上述 过程 只是 最 简单 的 示意 ， 具体 研究 工作 请参阅 文献 ［ 1 ］ . 
 　 　 2 ) 将 上述 实数 化 之后 的 遗传算法 直接 与 BP 算法 相 集成 ， 以 前者 的 全局 寻优 能力 防止 陷入 局部 极小 点 ， 同时 依赖 后者 的 梯度 下降 搜索 法 保证 在 有限 次 搜索 后 快速 找到 全局 最优 解 . 
 　 　 据此 ， 本文 提出 遗传 BP 算法 ， 其 具体 过程 为 ： 
 　 　 ①   随机 产生 N 组在 不同 实数 区间 内 取值 的 初始 网络 权值 . 
 　 　 ②   用 BP 算法 对 这 N 组 初始 权值 分别 进行 预 训练 ， 若 经过 预 训练 后 ， 这 N 组权值 中 至少 已有 一组 满足 精度 要求 ， 则 算法 结束 ； 否则 转入 步骤 ③ . 
 　 　 ③   分别 依据 经过 预 训练 的 上述 N 组权值 所 对应 的 上 下限 确定 取值 区间 ， 在 区间 内 随机 生成 r * N 组新 的 权值 ， 连同 经过 预 训练 的 N 组权值 一起 ， 构成 完整 的 基因 群体 ， 共 ( r + 1 ) * N 组权值 . 
 　 　 ④   对 这 ( r + 1 ) * N 组权值 进行 选择 、 交叉 、 变异 等 遗传操作 . 
 　 　 ⑤   如果 经过 步骤 ④ 的 操作 已 至少 得到 一组 符合 精度 要求 的 权值 ， 则 算法 结束 ； 否则 从 经过 遗传操作 的 这 ( r + 1 ) * N 组权值 中 选出 N 组较 好 的 ， 回复 到 步骤 ② . 
 　 　 限于 篇幅 ， 关于 遗传 BP 算法 的 详尽 描述 和 算法 实现 请参阅 文献 1 ） . 
 
 　 　 陈荣 . 人工神经网络 及其 在 常压塔 质量 控制 中 的 应用 。 清华大学 硕士论文 ， 1994 . 
 3 　 结构 优化 策略 
 　 　 关于 人工神经网络 的 结构 优化 工作 ， 近年 才 逐渐 开展 . 其中 以 Bhat 等 人 提出 的 网络 剪枝 法 较为 引人瞩目 ［ 2 ］ ， 其 基本 思想 是 ： 引入 网络结构 复杂度 函数 Ecom 来 定量 考察 网络结构 优化 程度 ， 之后 ， 在 保证 网络 学习 精度 Ebpn 的 前提 下 ， 尽量 简化 网络 的 结构 复杂度 ， 即 减少 Ecom 值 ， 这 在 数学 上 表现 为 求解 一个 带 约束 的 极值 问题 . 但 因为 Bhat 等 人 以 BP 算法 为 网络 训练 手段 ， 难以 直接 处理 这种 非 连续函数 形式 ， 所以 不得不 借助于 罚 函数 的 思想 将 上述 极值 问题 加以 变换 ， 改为 求解 
 E = Ebpn + λ Ecom ， 　 λ ＞ 0 　 　 　 ( 1 ) 
 一维 无约束 极值 问题 . 式 中 ， E 为 网络 综合性 能 评价 指标 ； 
 　 　 λ 为 比例 因子 ， 用以 表征 Ebpn 和 Ecom 的 相对 重要 程度 . 
 　 　 由于 Ebpn 和 Ecom 之间 并 不 存在 数量级 上 的 优先 次序 关系 ， 而 λ 的 不同 取值 又 直接 影响 着 网络结构 最终 的 优化 结果 与 精度 ， 所以 确定 λ 的 取值 成为 一个 极为 棘手 的 问题 . 针对 Bhat 等 人 工作 中 的 问题 ， 本文 提出 了 基于 遗传算法 改造 后 的 网络结构 优化 策略 ， 其 具体做法 为 ： 
 　 　 ① 重新 定义 网络结构 复杂度 函数 Ecom 为 
 Ecom ＝ （ 2Nin + Nhid - Nk )  i  jw2ij 　 　 　 ( 2 ) 
 其中 ， Nin 为 输入 层 节点 数目 ；   Nhid 为 隐层 节点 数目 ；   w2ij 为 从 节点 i 指向 节点 j 的 权值 ； Nk   为 结构 优化 指数 ， 初始值 置 为 零 ， 每当 删去 一个 输入 节点 其值 增 2 ， 删去 一个 隐 节点 其值 增 1 . 某 节点 被 删除 的 标准 是 ： 当由该 节点 出发 指向 下 一层 节点 的 所有权 值 ( 包括 阈值 ) 均 落于 死区 之中 时 ， 则 该 节点 被 删去 ( 此处 死区 为 预先 设定 的 用来 衡量 权值 对 网络 精度 所起 作用 显著 与否 的 一个 数值 区间 ) . 
 　 　 依 ( 2 ) 式 重新 定义 的 Ecom 将 能够 指导 训练 过程 倾向 于 优先 删除 网络 节点 ， 实现 网络结构 的 最 简化 而 不仅仅 是 网络 节点 间 联接 的 稀疏 化 . 
 　 　 ② 根据 所 需 解决问题 的 难易 程度 ， 预先 给出 一个 相对 于 该 问题 来说 “ 足够 复杂 ” 的 多层 前向 网络 . 
 　 　 ③   以依 概率 全局 寻优 的 遗传算法 来 训练 步骤 ② 中 给出 的 网络 ， 并 直接 求解 网络结构 优化 问题 的 原始 形式 ， 即 
 minEcom ． 　 　 　 ( 3 ) 
 约束条件 为 
 Ebpn ＜ ε ， 　 ε ＞ 0 　 　 　 ( 4 ) 
 其中 ， Ebpn 为 反映 网络 映射 精度 的 相对 均方 误差 ， ε 为 所 允许 的 Ebpn 最大值 ， 它 根据 实际 需要 而 给定 . 
 　 　 ④   当 遗传算法 结束 上述 寻优 过程 ， 即 在 Ebpn 满足 约束条件 的 前提 下 ， Ecom 到达 收敛 点时 ， 网络结构 将 已经 自动 实现 优化 ( 最 简化 ) . 
 　 　 需要 指出 的 是 ： 
 　 　 由于 以 ( 4 ) 式 为 约束条件 对 ( 3 ) 式 进行 目标 优化 ， 所以 只会 删除 冗余 的 网络 节点 ， 而 不会 导致 网络结构 的 过于 简化 . 
 4 　 仿真 与 实际 应用 举例 
 4.1 　 仿真 举例 
 　 　 这里 我们 选取 一个 输入 层 节点 数为 2 、 输出 层 节点 数为 1 、 隐层 节点 数为 5 的 三层 前向 网络 ， 分别 采取 标准 BP 算法 、 基本 遗传算法 和 遗传 BP 算法 作为 训练方法 ， 以求 实现 如下 具有 多个 极值 点 的 非线性 函数 ： 
 　 　 　 　 ( 5 ) 
 其中 训练样本 数为 30 ， 检验 样本数 为 30 ， 精度 要求 为 Ebpn = 0.002 . 
 表 1.1 　 三种 算法 所得 网络 训练 及 检验 精度 
 
 　 标准 BP 算法 基本 遗传算法 遗传 BP 算法 
 训 　 练 
 过 　 程 Ebpn0.00460 . 00340.0018 
 Emax0.07130 . 05260.0216 
 检 　 验 
 过 　 程 Ebpn0.00480 . 00340.0019 
 Emax0.07540 . 05300.0283 
 
 　 　 注 ： 1 . Ebpn 为 相对 均方 误差 ， Emax 为 最大 相对误差 ； 
 　 　 　 　 2 . 检验 样本 与 训练样本 是 内 插 关系 . 
 表 1.2 　 三种 算法 对应 的 网络 训练 次数 
 
 相对 均方 误差 标准 BP 算法 基本 遗传算法 遗传 BP 算法 
 0.00509 ， 0334 ， 510210 
 0.004617 ， 725 — — — — 
 0.0040 ∞ 8 ， 400460 
 0.0034 ∞ 15 ， 820 — — 
 0.0030 ∞ ∞ 690 
 0.0018 ∞ ∞ 1 ， 020 
 
 　 　 注 ： 1 . “ ∞ ” 表示 算法 达 不到 对应 精度 ， “ — — ” 表示 算法 直接 跳过 了 对应 精度 ； 
 　 　 　 　 2 . 基本 遗传算法 和 遗传 BP 算法 对应 训练 次数 系 根据 所用 CPU 时间 折算 成 标准 BP 算法 中 的 训练 次数 来 表示 的 . 
 　 　 表 1.1 　 给出 了 三种 算法 在 网络 的 训练 和 检验 过程 中 的 精度 比较 结果 ， 从中 我们 可以 看出 ： 经过训练 ， 只有 遗传 BP 算法 达到 预先 设定 的 精度 要求 ； 从 检验 结果 来看 ， 遗传 BP 算法 能够 较 好 地 复现 学习 成果 ， 表明 它 所 取得 的 较 高精度 不是 病态 的 . 
 　 　 表 1.2 　 记录 了 三种 算法 在 不同 精度 时 所 需 经历 的 训练 次数 ， 从中 可以 看出 ： 标准 BP 算法 的 速度 最慢 ； 基本 遗传算法 在 较为 迅速 地 找到 次优 解后 在 求取 最优 解时 却 发生 了 困难 ； 相比之下 ， 只有 遗传 BP 算法 始终保持 着 快捷 的 训练 速度 ， 迅速 地 求得 了 满足 所 需 精度 的 解 . 
 　 　 上述 用到 的 神经网络 结构 实际上 是 经 结构 优化 策略 处理 后 而 得到 的 ， 最初 给出 的 是 一个 输入 层 节点 数为 3 ( 三个 输入 分别 为 x1 、 x2 、 x3 = x1 + 2x2 ) , 输出 层 节点 数为 1 ， 隐层 节点 数为 10 的 三层 前向 网络 ， 经过 网络结构 优化 ， 冗余 的 输入 节点 x3 被 删去 ， 同时 隐层 节点 也 从 最初 的 10 个 减少 为 5 个 ， 整个 网络结构 大为 简化 . 
 　 　 那么 简化 之后 的 网络 其 映射函数 的 能力 是否 也 削弱 了 呢 ? 为此 采用 相同 的 样本 对 结构 优化 前后 的 网络 分别 进行 训练 和 检验 ， 结果 如表 2 所示 . 
 表 2 　 结构 优化 前后 网络 训练 及 检验 精度 
 
 　 未经 结构 优化 的 网络 经过 结构 优化 的 网络 
 训 　 练 
 过 　 程 Ebpn0.00170 . 0018 
 Emax0.02070 . 0216 
 检 　 验 
 过 　 程 Ebpn0.00210 . 0019 
 Emax0.03010 . 0283 
 
 
 　 　 从表 2 中 不难 得出结论 ： 网络 经过 结构 优化 之后 ， 其 精度 不但 未 受到 损害 ， 相反 由于 其 能够 将 冗余 的 输入 节点 和 隐层 节点 剔除 ， 使得 它 对于 所 需 实现 的 函数 关系 的 本质 认识 得 更为 准确 、 深入 ， 因此 当换 用 不同 的 样本 来 检验 时其 精度 基本 维持 不变 . 
 4.2 　 实际 应用 举例 
 　 　 在 原油 常压 蒸馏塔 的 优化 与 控制 中 ， 由于 常压塔 各 侧线 抽出 产品 的 质量 信息 无法 在线 获取 ， 给 进行 闭环控制 带来 了 很大 困难 ， 因此 利用 人工神经网络 技术 建立 常压塔 质量 估计 模型 十分必要 . 而 在 建立 神经网络 模型 时 ， 网络 输入 变量 的 选取 和 隐层 节点 数目 的 多少 对于 模型 的 精度 及其 适应性 强弱 有着 直接 的 影响 ， 所以 这里 我们 采用 上面 的 网络结构 优化 策略 来 确定 之 . 又 由于 常压塔 为 典型 非线性 大型 复杂 工业 对象 ， 样本空间 极为 复杂 ， 故 采用 遗传 BP 算法 来 训练 之 . 
 　 　 以常 一线 汽油 干 点 模型 的 建立 为例 ， 结果 如图 1 — 4 所示 . 图 1 为 依据 工艺 和 机理 分析 而 初步 确定 的 网络结构 ， 图 2 为 经过 结构 优化 之后 得到 的 网络 模型 ， 图 3 和 图 4 分别 为 图 2 所示 模型 的 训练 和 检验 精度 ， 它们 均 满足 误差 小于 4 ℃ 的 工艺 要求 . 而图 1 所示 模型 的 训练 精度 虽然 能 满足 工艺 需要 ， 检验 精度 却 发散 了 ， 限于 篇幅 ， 文中 略去 未示 . 
 　 　 本文 开发 了 多层 前向 网络 的 一种 全局 快速 寻优 算法 ； 遗传 BP 算法 ； 同时 给出 了 网络结构 的 优化 策略 . 上述 研究 的 成效 经受 了 数值 仿真 和 实际 工业 应用 的 检验 . 并且 文中 所 依据 的 思想 并 不仅 局限于 多层 前向 网络 的 研究 ， 几乎 不 需加 任何 重大 改动 就 可 拓展 用于 其它 领域 的 优化 搜索 和 极值 求解 . 
 
 
 
 图 1 　 初始 汽油 干 点 网络 模型 
 
 
 
 图 2 　 优化 汽油 干 点 网络 模型 
 
 
 图 3 　 优化 汽油 干 点 网络 模型 的 学习 精度 
 
 
 图 4 　 优化 汽油 干 点 网络 模型 的 检验 精度 
 注 ： 本文 部分 结果 曾 发表 于 1994 年 第一届 中国 智能 控制 与 智能 自动化 学术会议 . 
 作者简介 ： 陈荣 　 1969 年 生于 江苏省 南京市 ， 1992 年 获 清华大学 生产 过程 自动化 学士学位 和 环境工程 学士学位 ， 1994 年 获 该校 自动控制 理论 及 应用 专业 硕士学位 . 目前 在 该校 自动化系 任教 ， 主要 从事 人工神经网络 、 过程 建模 与 优化 、 连续 过程 CIMS 等 方面 的 研究 工作 . 
 　 　 　 　 　 徐用 懋 　 清华大学 自动化系 教授 ， 博士生 导师 ， 长期 从事 过程 控制 的 教学 工作 ， 讲授 “ 过程 控制 ” 等 课程 ， 科研 方向 是 工业 过程 建模 、 优化 及 先进 控制 . 承担 了 国家 多项 重点 科技攻关 课题 ， 多次 获部 、 委 科技 进步奖 . 近期 专著 有 《 模糊 理论 和 神经网络 的 基础 与 应用 》 ， 近年来 发表 论文 40 余篇 . 
 作者 单位 ： 清华大学 自动化系 　 北京 　 100084 ； 福建 炼油厂 　 福建 惠安 　 362100 
 参考文献 
 ［ 1 ］ 　 Holland   J   H .   Genetic   algorithms   and   the   optimal   allocations   of   trials .   SLAM   Jounal   of   Computing ,   1973 , 2 : 88 - 105 . 
 ［ 2 ］ 　 Bhat   N   V , McAvoy   T   J . Determining   model   structure   for   neural   models   by   network   stripping .   Computers   and   Chem . Engng . ,   1992 , 16 ( 4 ) : 271 - 281 .   
 ［ 3 ］ 　 Goldberg   D   E .   Genetic   algorithms   in   search ,   optimization   and   machine   learning .   Mass : Addison - Wesley ,   1989 . 
 ［ 4 ］ 　 Davis   L .   Handbook   of   Genetic   Algorithms .   London : Pitman ,   1991 . 
 收稿 日期 　 1994 - 07 - 16 
