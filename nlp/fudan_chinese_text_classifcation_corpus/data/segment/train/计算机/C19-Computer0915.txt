自动化 学报 
 ACTA   AUTOMATICA   SINICA 
 1997 年 　 第 23 卷 　 第 4 期 　 Vol.23 　 No.4 　 1997 
 
 
 
 基于 迭代 学习 的 机械手 操作 空间 
 力 / 位置 混合 控制算法 1 ） 
 韦庆 　 常文森 　 张 彭 
 　 　 摘 　 要 　 基于 对 常规 机械手 操作 空间 力 / 位置 混合 控制算法 的 简单 回顾 ， 及 对 该 算法 所 遇到困难 的 分析 ， 提出 了 一种 基于 迭代 学习 的 机械手 操作 空间 力 / 位置 混合 控制算法 ， 来 改善 机械手 同高 刚度 环境 接触 时 ， 机械手 力 / 位置 混合 控制 的 动态控制 性能 . 给出 了 学习 算法 的 收敛 条件 及其 证明 . 实验 表明 该 算法 具有 快速 的 收敛性 ， 能 达到 很 高 的 力 / 位置 动态 控制精度 . 
 　 　 关键词 　 迭代 学习 控制 ， 力 / 位置 混合 控制 ， 机械手 操作 空间 控制 . 
 HYBRID   FORCE / POSITION   CONTROL   OF   ROBOT 
 MANIPULATORS   BASED   ON   ITERATIVE   LEARNING 
 WEI   QING 　 CHANG   WENSEN   ZHANG   PENG 
 ( Department   of   Automatic   Control ,   National   University   of   Defense   Technology ,   Changsha   410073 ) 
 Abstract 　 By   analyzing   the   difficulties   of   the   conventional   force / position   hybrid   control   algorithm   in   applications ,   this   paper   presents   a   new   operational   space   control   algorithm   of   hybrid   force / position   control   based   on   iterative   learning   to   improve   the   dynamic   force   control   performance   of   robot   manipulators   of   contacting   with   high   stiffness   environment .   The   proof   of   the   algorithm   convergence   is   given .   Experiments   show   the   validity   of   the   new   algorithm .   It   converges   rapidly   and   can   acquire   high - precision   force / position   dynamic   control   performance   of   robot   manipulators . 
 Key   words 　   Iterative   learning   control ,   hybrid   force / position   control ,   operational   space   control . 
 1 　 引言 
 　 　 我们 知道 ， 机器人 具备 了 力 控制 功能 ， 可以 表现 出 一种 智能化 特征 ， 因而 能够 胜任 更为 复杂 的 操作 任务 . 机器 人力 控制技术 历经 多年 的 研究 ， 力 / 位置 混合 控制算法 的 理论 框架 大体 建立 ， 然而 力 控制技术 却 还 没有 达到 实用化 的 程度 . 这同 其中 一个 重要 问题 没有 得到 解决 有 很大 的 关系 ， 即 高 刚度 机械手 同高 刚度 环境 接触 时 ， 力 控制 的 动态 控制精度 的 提高 问题 . 我们 采用 基于 迭代 学习 的 机械手 操作 空间 力 / 位置 混合 控制算法 来 解决 此 问题 . 
 　 　 迭代 学习 控制 是 1984 年 由 Arimoto ［ 1 ］ 等 首先 提出 来 的 ， 他们 对于 线性 时变 系统 提出 了 通用 的 学习 算法 .   Bondi ［ 2 ］ 1988 年 对于 机器人 控制 ， 发展 了 一种 迭代 学习 算法 ， 利用 系统 的 位置 、 速度 、 加速度 信号 来 改进 每次 迭代 的 控制 输入 ， 他们 通过 高增益 反馈 将 轨迹 跟踪 误差 限制 在 某 一上 确界 之内 ， 这个 上 确界 被 用来 证明 他们 学习 控制算法 的 收敛性 . Kuc ［ 3 ］ 1992 年 对于 一类 非线性 系统 提出 了 一种 迭代 学习 控制策略 ， 在 他们 的 算法 中 没有 使用 跟踪 误差 的 微分 项来 改进 前馈 学习 ， 而是 通过 闭环 系统 的 高增益 反馈 来 保证 该 迭代 算法 的 收敛性 . 
 2 　 机械手 操作 空间 力 / 位置 混合 控制算法 及其 所 遇到 的 困难 
 　 　 常规 的 机械手 操作 空间 力 / 位置 混合 控制算法 的 控制 力矩 由 两个 部分 组成 ： ( 1 ) 非线性 前馈 项 ， 其 作用 是 补偿 机械手 重力 、 哥氏力 以及 离心力 的 影响 . ( 2 ) 通过 引入 一个 非线性 反馈 矩阵 ， 使 机械手 在 操作 空间 各个 方向 上 的 控制 解 耦 ， 这样 可以 在 操作 空间 各个 方向 上 设计 独立 的 力 或者 位置 控制器 . 操作 空间 机械手 的 动力学 方程 为 
 M ( x ) + H ( x , ) + G ( x ) = Fc + Fe 
 ( 1 ) 
 式 中 M ( x ) 为 机械手 惯量 矩阵 ， H ( x , ) 为 机械手 哥氏力 、 离心力 向量 ， G ( x ) 为 重力 力矩 向量 ， Fc 为 机械手 操作 空间 控制力 ， Fe 为 环境 对 机械手 末端 执行器 的 作用力 . 把 操作 空间 控制力 Fc 分为 非线性 前馈 项 Fa 和 非线性 反馈 项 Fb 
 Fc = Fa + Fb 
 ( 2 ) 
 Fa = ( x , ) + ( x ) 
 ( 3 ) 
 
 ( 4 ) 
 式 中 ( x , ) 是 H ( x , ) 的 估计 ， ( x ) 为 G ( x ) 的 估计 ， ( x ) 为 M ( x ) 的 估计 ， S 为 机械手 操作 空间 位置 和 姿态 选择 矩阵 ， 为 操作 空间 力 和 力矩 选择 矩阵 . 这里 的 力 和 位置 控制器 采用 了 普遍 使用 的 PD 控制算法 ， 方程 ( 1 ) ， ( 2 ) ， ( 3 ) ， ( 4 ) 构成 机械手 操作 空间 力 / 位置 混合 控制算法 . 
 　 　 机械手 在 工业生产 中 的 大多数 接触 作业 都 是 同高 刚度 环境 接触 ， 例如 对 某种 金属表面 的 加工 作业 ， 然而 在 同高 刚度 环境 接触 时 ， 机械手 力 控制 的 动态控制 性能 不能 令人满意 ， 这 就 大大 限制 了 机器 人力 控制技术 在 生产 中 的 广泛应用 ， 主要 是 由 以下 几 方面 的 原因 造成 的 ： ( 1 ) 上述 机械手 操作 空间 力 / 位置 混合 控制算法 客观 上 存在 动态 耦合 ， 也 就是 机械手 既 有力 控制 又 有 位置 控制 时 ， 即 Fe ≠ 0 时 ， 其 操作 空间 各个 方向 的 控制 实际上 是 静态 解 耦 的 ， 其 动态控制 存在 维间 耦合 问题 ， 这是 由于 M ( x ) 矩阵 的 非 对角 特性 造成 的 . 机械手 操作 空间 力 / 位置 混合 的 动态 维间 耦合 是 影响 机械手 力 / 位置 混合 控制 动态 性能 的 一个 主要 因素 . ( 2 ) 机械手 操作 空间 力 / 位置 混合 控制算法 的 复杂性 . 机械手 力 / 位置 混合 控制算法 的 复杂性 . 机械手 力 / 位置 混合 控制算法 是 个 复杂 的 算法 ， 完全 实现 各种 精细 的 补偿 和解 耦 需要 大量 的 计算 ， 这会 造成 系统 采样 控制 周期 过长 . ( 3 ) 机械手 力 控制 未 建模 动力学 特性 . 我们 在 文献 ［ 4 ］ 中 对 机械手 未 建模 动力学 特性 如 机械手 驱动 电机 的 动力学 特性 、 机械手 力 传感器 动力学 特性 、 环境 动力学 特性 、 系统 采样 控制 延迟 等 对 机械手 力 控制 稳定性 的 影响 进行 了 分析 ， 得到 机械手 未 建模 特性 同 机械手 力 控制 动态 稳定性 密切相关 ， 采样 控制 延时 的 减少 对系统 稳定性 的 改善 有 很大 作用 ， 在 环境 刚度 很 高时 ， PD 力 控制算法 很难 保持 力 控制系统 稳定性 ， 也 就是 高 刚度 机械手 同高 刚度 环境 接触 时 的 力 控制 性能 的 提高 ， 不能 通过 增大 力反馈 增益 而 达到 ， 而 只能 另辟 奚径 了 . 
 3 　 基于 迭代 学习 的 机械手 操作 空间 力 / 位置 混合 控制算法 
 　 　 本 节 应用 迭代 学习 控制 ， 来 解决 机械手 同高 刚度 环境 接触 时 ， 力 控制 的 动态 性能 的 提高 问题 . 我们 的 控制策略 是 采用 恒定 增益 PD 控制 + 前馈 的 学习 控制 ， PD 控制 是 为了 保证 机械手 力 / 位置 混合 控制 的 稳定性 ， 而 机械手 控制 性能 的 提高 是 通过 前馈 项 的 学习 而 渐进 得到 . 我们 重写 机械手 操作 空间 的 动力学 方程 为 
 M ( x ) + H ( x , ) + G ( x ) = Ub + Uf + Fe 
 ( 5 ) 
 其中 Ub 是 线性 恒定 增益 PD 反馈 控制器 的 输出 ， Uf 代表 前馈 控制 量 ， 通过 它 的 学习 来 渐进 改进 机械手 力 控制 的 动态 控制精度 . 考虑 第 k 次 迭代 
 
 ( 6 ) 
 定义 机械手 的 误差 
 ek ( t ) = xd ( t ) - xk ( t ) ， 
 ( 7 ) 
 线性 恒定 增益 反馈 控制 控制器 输出 为 
 
 ( 8 ) 
 机械手 控制 的 前馈 输出 的 迭代 学习 控制 律为 
 
 ( 9 ) 
 式 ( 6 ) ， ( 7 ) ， ( 8 ) ， ( 9 ) 构成 基于 迭代 学习 的 机械手 操作 空间 力 / 位置 混合 控制算法 . 该 迭代 学习 算法 的 收敛性 ， 以下 将 只 证明 机械手 在 操作 空间 全 位置 控制 的 收敛性 ， 机械手 力 / 位置 混合 控制 的 收敛性 证明 ， 将 力反馈 看成 是 机械手 位置 的 高增益 反馈 ， 其 收敛性 证明 也 同上 . 
 引理 1 　 对于 机械手 的 控制 方程 ( 5 ) ， 若 其中 M ( x ) , H ( x , ) ， G ( x ) 满足 Lipschitz 条件 ， 即 
 ‖ M － 1 ( x ) - M - 1 ( y ) ‖ ≤ m ‖ x - y ‖ ,   x , y ∈ S ， 
 ‖ H ( x , ) - H ( y , ) ‖ ≤ h1 ‖ x - y ‖ + h2 ‖ - ‖ ， 　 x , y ∈ S ， 
 ( 10 ) 
 ‖ G ( x ) - G ( y ) ‖ ＜ g . ‖ x - y ‖ ,   x , y ∈ S . 
 其中 S 为 机械手 操作 空间 的 可能 的 状态 域 ， m , h1 , h2 , g 为 有限 正常 数 . 恒定 PD 控制器 的 输出 为 Ub ＝ KDc + KP . e ， 对于 不同 前馈 输入 ， ， 系统 状态 满足 
 
 ( 11 ) 
 其中 c , d 为 有限 正常 数 . 
 定理 1 . 机械手 迭代 学习 控制算法 ( 6 ) ， ( 7 ) ， ( 8 ) ， ( 9 ) 收敛 的 充分条件 为 
 ‖ ［ I - M － 1 ( xk ) ］ ‖ ≤ ρ ＜ 1 . 
 ( 12 ) 
 　 　 证明 . 考虑 第 k 和 k + 1 次 控制 ， 有 
 
 两 式 分别 乘以 再 相减 ， 考虑 到 ek = xd - xk ,   k = d - k ,   k = d - k ， 有 
 
 将 ( 9 ) 式 代入 上 式 ， 
 
 
 两边 取 范数 ， 考虑 到 引理 1 有 
 
 式 中 　 r1 = ‖ KP ‖ ( 1 + ‖ M - 1 ( x ) ‖ m ) + ‖ M - 1 ( x ) ‖ m ( h1 + g ) + m ‖ ‖ m ( ‖ H ‖ m + ‖ G ‖ m + ‖ KD ‖ ‖ k + 1 ‖ m + ‖ KP ‖ ‖ ek + 1 ‖ m + ‖ ‖ m ) ,   r2 = ‖ KD ‖ ( 1 + ‖ M - 1 ( x ) ‖ m ) + ‖ M - 1 ( x ) ‖ mh2 , R = r1 * c + r2 * d ,   其中 定义 ‖ f ( x ) ‖ m = ( ‖ f ( x ) ‖ ) ,   对于 x ( t ) ∈ Rn [ 0 , ∞ ) ， 我们 定义 其 λ 范数 为 ‖ x ( t ) ‖ λ = e - λ t . ‖ x ( t ) ‖ ， 上 式 两边 乘 e - λ t ，   取 λ 范数 得 
 
 所以 
 
 只要 ‖ ［ I － M - 1 ( xk ) ］ ‖ ≤ ρ ＜ 1 ， 我们 总 可以 找到 充分 大 的 正数 λ ， 使 ［ ‖ ［ I － M - 1 ( xk ) ］ ‖ ＋ ＜ 1 成立 ， 这样 迭代 学习 误差 就 满足 ‖ k ＋ KDk ＋ KPek ‖ λ → 0 ， 所以 合理 地 选择 控制参数 KD ， KP ， 则 有 ‖ ek ‖ → 0 ， 所以 ‖ xd ( t ) - xk ( t ) ‖ → 0 ， 则 迭代 学习 控制 收敛 ， 证毕 . 
 　 　 说明 . 在 定理 1 的 证明 中 ， 我们 并 没有 用 系统 的 高增益 反馈 来 保证系统 迭代 学习 控制 的 收敛性 ， 甚至 没有 要求 系统 必须 稳定 这一 性质 ， 没有 采用 高增益 反馈 来 保证系统 迭代 学习 的 收敛性 ， 对于 机械手 力 控制系统 来说 是 个 优良 的 性质 ， 它 允许 我们 采用 较 低 增益 的 PD 控制器 参数 ， 只要 保证系统 最低 限度 的 稳定性 即可 ， 系统 的 控制 性能 由 迭代 学习 来 逐渐 改善 ， 而 不必 采用 高增益 的 力反馈 ， 从而 引起 系统 力 控制 的 动态 不 稳定 . 上述 迭代 算法 要 采用 系统 加速度 变量 来 改进 系统 的 前馈 输入 ， 一般 系统 中 加速度 变量 并 不能 轻易 得到 ， 要 采用 某种 估计 方法 ， 因而 会 不可避免 的 造成 信号 的 时间延迟 ， 这样 得到 的 加速度 信号 是 不能 应用 于 系统 的 实时控制 的 . 上述 迭代 算法 的 优点 是 其 控制 过程 与其 前馈 的 学习 过程 实际上 是 两个 可以 分离 的 过程 ， 也 就是 其 前馈 的 学习 过程 可以 离线 进行 ， 所以 其 加速度 信号 也 可以 离线 进行 处理 ， 这样 不仅 可以 对 加速度 信号 进行 滤波 ， 而且 可以 矫正 其 滤波 后 而 产生 的 时间延迟 ， 从而 得到 满意 的 系统 加速度 信号 . 采取 了 离线 式 学习 ， 所以 同 PD 控制器 相比 ， 该 算法 的 所 需 CPU 处理量 仅 增加 了 一些 存储 时间 ， 因此 该 迭代 控制算法 具有 很 好 的 实时性 . 
 4 　 实验 
 　 　 我们 所 进行 的 基于 迭代 学习 的 机械手 操作 空间 力 / 位置 混合 控制 实验 是 在 通用 力 控制系统 GKD3 上 完成 的 ， GKD3 机械手 力 控制系统 硬件 结构 由 DELTA - 3000 工业 控制机 和 两台 PUMA - 562 机械手 ， 两台 六维力 传感器 组成 . 基于 VME 总线 插 板式 结构 的 DELTA - 3000 工业 控制机 作为 系统控制 结构 的 主体 ， 实现 了 两个 层次 的 控制 ， 即 上层 的 组织 、 协调 级 ， 和 底层 的 伺服 控制 级 . GKD3 的 特色 是 实现 了 机械手 操作 空间 六维力 ( 力矩 ) / 位置 ( 姿态 ) 的 混合 伺服 控制 . 每次 进行 迭代 学习 过程 前 ， 采用 常规 力 / 位置 混合 控制算法 ， 控制 机械手 运动 到 迭代 学习 控制 的 初始 位置 过程 ， 然后 开始 该 迭代 学习 过程 ， 在 每次 控制 过程 中 ， 我们 仅 将 学习 所 需要 的 量 ， 例如 PD 恒定 增益 控制器 的 输出 ， 机械手 操作 空间 各个 方向 上 的 速度 ， 机械手 操作 空间 的 惯量 矩阵 ( x ) 储存 在 内存 中 ， 在 控制 过程 中 并 不 处理 ， 在 每次 控制 过程 结束 后 ， 首先 对 机械手 操作 空间 各个 方向 的 速度 进行 滤波 ， 矫正 时间 滞后 ， 对 其 进行 差分 得到 机械手 操作 空间 各个 方向 上 的 加速度 信号 ， 然后 再 按 迭代 学习律 ( 9 ) 计算 下 一次 控制 的 前馈 . 以下 为 我们 进行 的 迭代 学习 控制 实验 ， ( x ) 近似 取为 对角 矩阵 ， 系统控制 周期 为 2.4 ms . 
 　 　 1 ) 机械手 操作 空间 纯 位置 控制 实验 
 　 　 机械手 x 方向 位置 移动 为 0.10 m ， y 方向 位置 移动 为 - 0.10 m ， z 方向 位置 移动 - 0.30 m . 机械手 运动 时间 为 5s . 机械手 操作 空间 各个 方向 位置 控制参数 ： 
 　 　 P = ［ 500 ， 500 ， 500 ， 500 ， 500 ， 500 ］ ； 
 　 　 D = ［ 20 ， 20 ， 20 ， 20 ， 20 ， 20 ］ . 
 　 　 实验 结果 见图 1 ， 图中 第一行 序号 代表 迭代 学习 的 次数 . 
 
 
 图 1 ( a ) 　 x 方向 位置 误差 
 
 
 图 1 ( b ) 　 y 方向 位置 误差 
 
 
 图 1 ( c ) 　 z 方向 位置 控制 误差 
 　 　 2 ) 平面 跟踪 实验 
 　 　 机械手 xy 方向 为 位置 控制 ， x 方向 移动 0.20 m ， y 方向 移动 0.0 m ， z 方向 为力 控制 ， z 方向 指令 力为 - 10.0 N . 机械手 移动 时间 为 10s . 机械手 操作 空间 各个 方向 力 / 位 控制参数 为 
 　 　 P = ［ 500 , 500 , 1 , 500 , 500 , 500 ］ ； 
 　 　 D = ［ 20 , 20 , 200 , 20 , 20 , 20 ］ . 
 　 　 实验 结果 如图 2 ， 图中 第一行 序号 代表 迭代 学习 的 次数 . 
 
 
 图 2 ( a ) 　 x 方向 位置 控制 误差 
 
 
 图 2 ( b ) 　 y 方向 位置 控制 误差 
 
 
 图 2 ( c ) 　 z 方向 力 控制 误差 
 　 　 为了 比较 该 迭代 学习 控制 律 的 控制 效果 ， 我们 选取 本 实验 第 8 次 迭代 的 控制 效果 与 常规 机械手 操作 空间 力 / 位 混合 控制算法 的 控制 效果 进行 比较 ， 如图 3 . 常规 算法 的 PD 控制参数 为 
 　 　 P = ［ 5000 , 5000 , 1 , 5000 , 5000 , 5000 ］ ; 
 　 　 D = ［ 20 ， 20 ， 200 ， 20 ， 20 ， 20 ］ . 
 
 
 图 3 ( a ) 　 x 方向 位置 控制 误差 
 
 
 图 3 ( b ) 　 y 方向 位置 控制 误差 
 
 
 图 3 ( c ) 　 z 方向 力 控制 误差 
 　 　 以上 机械手 操作 空间 力 / 位置 混合 控制 实验 表明 了 该 算法 具有 快速 的 收敛性 ， 能 达到 较 高 的 力 / 位置 动态 和 静态 控制精度 ， 同 常规 的 机械手 操作 空间 力 / 位置 混合 控制算法 相比 ， 该 迭代 学习 机械 操作 空间 力 / 位置 混合 控制算法 的 性能 是 优越 的 . 
 1 ) 　 “ 八 六三 — 五一 二 ” 智能 机器人 主题 专家组 基础 研究 资助 项目 . 
 作者简介 : 韦庆 　 男 ， 1969 年生 . 1991 年 7 月 于 复旦大学 电子 工程系 获 理学 学士学位 . 1993 年 5 月 起 在 国防科技大学 自动控制 系 攻读 博士学位 ， 研究 方向 为 机械 人 智能 控制 ， 在 攻读 博士学位 期间 完成 两个 “ 八 六三 ” 计划 项目 和 一个 国防 预研 项目 的 研究 ， 目前 主要 研究 领域 为 机器人 智能 控制 和 机械手 力 控制 . 
 作者 单位 : 国防科技大学 自动控制 系 　 长沙 　 410073 
 参考文献 
 ［ 1 ］ 　 Arimoto   S ,   Kawamura ,   Miyazaki   F .   Bettering   operation   of   robots   by   learning .   Journal   of   Robotics   System ,   1984 , 1 ( 2 ) : 123 — 140 . 
 ［ 2 ］ 　 Bondi   P , Casalino   G ,   Gambardella   L . On   the   iter   ative   learning   control   theory   for   robotic   manipulators .   IEEE   Journal   on   Robotics   and   Automation ,   1988 ,   4 ( 1 ) : 14 — 22 . 
 ［ 3 ］ 　 Kuc   T   Y ,   Lee   J   S ,   Nam   K .   An   iterative   learning   control   theory   for   a   class   of   nonlinear   dynamic   systems .   Automatica ,   1992 ,   28 ( 6 ) : 1215 — 1221 . 
 ［ 4 ］ 　 韦庆 ， 常文森 ， 张 彭 等 . 机械手 力 控制 动态 稳定性 分析 . 《 机器人 》 ， 1996 ， 18 ( 3 ) ： 173 — 178 . 
 收稿 日期 　 1995 - 05 - 29 
