自动化 学报 
 ACTA   AUTOMATICA   SINICA 
 1998 年   第 24 卷   第 5 期     Vol.24     No.5   1998 
 
 
 
 一种 特征选择 的 动态 规划 方法 1 ) 
 章 新华 
 摘 　 要 　 通过 分析 特征选择 的 机理 ， 提出 了 一种 特征选择 性能指标 和 基于 此 指标 的 动态 规划 特征选择 方法 . 使 复杂 的 多类 特征 信息 选择 的 全局 满意 解 寻求 过程 ， 转变成 一个 简单 的 阶段性 最优化 问题 . 在 一定 条件 下 ， 由 各 阶段 最优 决策 构成 的 整体 策略 等价 于原 问题 的 全局 满意 解 . 本文 法较 好 地 应用 于 水声 信号 特征分析 . 
 关键词 　 特征选择 ， 动态 规划 ， 模式识别 ， 信息 融合 . 
 DYNAMIC   PROGRAMMING   METHOD 
 FOR   FEATURE   SELECTION 
 ZHANG   XINHUA 
 ( Dalian   Naval   Academy ,   Dalian   116018 ) 
 ( Dept .   of   Underwater   Acoustical   Engineering ,   Harbin   Engineering   University ,   Harbin   150001 ) 
 Abstract 　 The   selection   of   multiple   classes   of   features   plays   an   important   role   in   the   field   of   pattern   recognition .   By   analyzing   the   mechanism   of   feature   selection ,   a   performance   measure   of   feature   selection   is   proposed   in   this   paper .   Based   on   it ,   a   dynamic   programming   method   for   feature   selection   is   presented ,   by   which   a   complex   process   of   obtaining   globally   satisfactory   solution   to   feature   selection   can   be   converted   into   a   simple   piecewise   optimization .   It   is   theoretically   proved   that   the   optimum   strategy   consisting   of   optimized   decisions   in   each   phase   corresponds   to   the   globally   satisfactory   solution   of   feature   selection .   The   proposed   approach   is   applied   to   feature   selection   of   underwater   acoustical   signals . 
 Key   words 　 Feature   selection ,   dynamic   programming ,   pattern   recognition , information   fusion . 
 1 　 引言 
 　 　 模型 识别 是 利用 特征向量 中 所 包含 的 类别 信息 进行 类别 划分 的 过程 . 为了 实现 鲁棒 分类 ， 分类器 使用 的 特征向量 必须 含有 足够 的 类别 信息 . 通常 ， 针对 某一 特殊 的 模式识别 问题 ， 可 从 多个 不同 的 角度 ( 如 时域 和 频域 ) 得到 多种类型 的 特征 信息 ， 这些 不同 类型 特征 信息 的 综合利用 ， 对 模式识别 具有 十分 重要 的 作用 . 多类 特征 信息 的 综合 不是 诸类 特征 集 的 简单 合并 ， 也 不是 常见 的 合并 后 的 特征 压缩 ， 而应 是 有 机理 的 融合 . 研究 发现 ， 两类 具有 较 好 分类 效果 特征向量 的 简单 联合 ， 其 分类 效果 并不一定 优于 单类 特征 . 究其原因 主要 有 二 ： 1 ) 根据 信息论 的 观点 ， 诸类 特征 的 类别 信息 既有 互补性 ， 又 有 矛盾性 ， 特征 集 的 简单 合并 所 带来 的 互补 信息 可能 不 敌 它们 之间 的 矛盾 信息 ； 2 ) 按 分类 原理 ， 多 类 特征 信息 的 简单 合并 使得 特征 空间 维数 增加 ， 此时 ， 若 训练样本 数目 不变 ， 则 由此 得到 的 分类器 的 类别 可分离性 会 下降 ， 且 在 训练 集 规模 受限制 时 这种 下降 会 更 明显 ［ 1 ］ . 
 　 　 特征选择 一直 受到 本 领域 的 广泛 关注 ： 整数 规划法 ［ 2 ］ 仅 适用 于 逐段 线性 分类器 ； 巴氏 距离 法对 特征 分布 有 一定 要求 ［ 3 ］ ； 基于 互信息 的 贪婪 算法 ［ 4 ］ 得到 的 不是 全局 满意 解 ， 被 选择 的 特征 维数 是 预先 固定 的 ； 遗传算法 ［ 5 ］ 是 一种 随机 优化 搜索算法 ， 可望 得到 全局 满意 解 ， 但 仍 具有 较大 的 计算 复杂性 . 本文 从 理论 上 分析 了 特征选择 的 机理 ， 提出 了 一种 近似 最优 的 特征选择 性能指标 和 基于 此 的 动态 规划 选择 方法 . 
 2 　 特征选择 的 机理 
 　 　 设 Ω C = ｛ W , σ w , P ｝ 是 样本 的 类别 概率 空间 ， 其中 W = ｛ ω 1 , … , ω C ｝ 表示 模式 类别 集合 ， C 是 模式 类别 数 ， σ w 是 W 的 子集 生成 的 一个 σ 代数 ， P 是 定义 在 σ w 上 的 概率 测度 . 其中 ， 各类 别 出现 的 先验概率 为 P ( ω i ) , i = 1 , … , C . Ω F = ｛ X , β x , p ( X ) ｝ 是 样本 的 特征 概率 空间 ， 其中 X = ( x1 ， … , xF ) T 是 样本 的 F 维 特征向量 ， β x 是 X 的 Borel 域 ， p ( X ) 是 定义 在 β x 上 的 特征 概率密度函数 . 对于 给定 的 模式 分类 问题 ， 模式 类别 的 初始 不确定性 
 　 　 ( 1 ) 
 是 固定 的 . 但 其后 验熵 
 　 　 ( 2 ) 
 可 根据 已知 的 模式 特征 信息 Ω F ， 通过 特征选择 加以 改变 . 其 改变 量 
 　 　 ( 3 ) 
 即 为 模式 特征 空间 与 类别 空间 之间 的 互信息 ， 它 反映 了 样本 的 特征向量 与其 各类 别 之间 的 整体 相关性 . 这里 ， Xj ∈ RF 为 X 的 第 j 种 选择 . 当 特征 分量 之间 不 存在 关于 类别 空间 的 互补 信息 时 ， 它 具有 最简 形式 
 　 　 ( 4 ) 
 　 　 特征选择 的 目的 是从 不同 信息 含量 的 许多 特征 分量 中 选择 若干 分量 ， 使 ( 2 ) 式 表示 的 后验 熵 达到 最小 . 这 等价 于 使 ( 3 ) 式 表示 的 特征 概率 空间 与 类别 概率 空间 的 互信息 达到 最大 . 即 通过 特征选择 使 模式 类别 的 平均 不确定性 达到 最小 . 因为 ( 3 ) 式 的 计算 量 随 F 和 变量 的 离散 区间 数目 指数 增长 ， 用 它 直接 作为 特征选择 的 性能指标 ， 计算 十分复杂 . 而 ( 4 ) 式 又 只是 ( 3 ) 式 的 特殊 形式 ， 并 不 满足 一般 特征 分布 条件 . 实际上 ， ( 4 ) 式 表示 的 互信息 没有 考虑 特征 分量 之间 的 信息冗余 ， 它 与 ( 3 ) 式 有 如下 关系 
 　 　 ( 5 ) 
 可见 ， 将 Is ( Ω C ， Ω F ) 减去 一个 正 的 修正 项 ， 可能 得到 互信息 I ( Ω C ， Ω F ) 的 较 好 近似 . 这一 修正 项 ( 实际上 是 一 惩罚 项 ) 应能 较 好 地 表征 特征 集内 各 分量 之间 的 相关性 ， 它 可用 各 分量 间 的 互信息 表示 . 这样 就 找到 了 一种 既 简单 又 能 较 好 近似 互信息 I ( Ω C ， Ω F ) 的 特征选择 性能指标 . 
 　 　 综上所述 ， 特征选择 的 基本 思想 是 把 各类 特征向量 组成 一个 大 向量 ， 然后 从中 选择 使 性能 函数 
 　 　 ( 6 ) 
 达到 最大 的 m 个 分量 . 其中 ， α 为 特征 相关性 系数 ， 一般 取 0.1 — 1.0 . 如果 α 取值 合适 ， ( 6 ) 式 能 较 好 地 近似 ( 3 ) 式 表示 的 互信息 ， 从而 使 特征 空间 与 类别 空间 之间 具有 较 好 的 整体 相关性 . 
 3 　 基于 动态 规划 的 特征选择 
 　 　 设 原始 特征 分量 集合 为 O = ｛ x1 , … , xF ｝ ， F 为 可 供选择 的 特征 总维数 . 取 状态变量 sk0O 为 第 k 阶段 已选 特征 构成 的 集合 ， FkO 为 第 k 阶段 可 供选择 的 候选 特征 集合 ， dk ( sk ) ∈ Fk 表示 第 k 阶段 的 决策 变量 ， 即 从 候选 特征 集合 中 选择 新 的 特征 分量 . 则 第 k 阶段 的 状态变量 可 表示 为 
 sk = Tk - 1 ( sk - 1 , dk - 1 ( sk - 1 ) ) , 
 其中 Tk - 1 表示 在 状态 sk - 1 下 的 状态 转移 变换 . 令 Pk , n - 1 ( sk ) 为 k 阶段 到 n - 1 阶段 所有 允许 策略 的 集合 ， 用 ( 6 ) 式 作为 决策 的 性能 函数 . 则 从 初始状态 s0 以 策略 p0 , n 到达 状态 sn + 1 时 得到 的 性能指标 函数 V0 , n ( s0 , p0 , n ) 可 表示 为 
 　 　 ( 7 ) 
 其中 
 　 　 ( 8 ) 
 表示 第 n + 1 阶段 在 状态 sn 下 采用 决策 dn 所 得到 的 性能指标 . 这里 Ns 为 已选 特征 集合 的 元素 个数 . 
 　 　 这样 ， 特征选择 就 变成 了 一个 动态 规划 问题 . 根据 动态 规划 原理 ， 允许 策略 p * 0 , n - 1 = ( d * 0 , d * 1 , … , d * n - 1 ) 是 最优 策略 的 充要条件 是 对 任意 0 < k < n - 1 , s0 有 
 　 　 ( 9 ) 
 其中 spk = Tk - 1 ( sk - 1 , dk - 1 ) 表示 了 由 初始状态 s0 和子 策略 p0 , k - 1 确定 的 第 k 阶段 的 状态 . 这就是说 ： 如果 p * 0 , n - 1 是 选择 n 个 特征 的 最优 策略 ， 则 它 的 前级子 策略 p * 0 , n - 2 应该 是 选择 n - 1 个 特征 的 最优 策略 . 换言之 ， 若 s * n 是 经 最优 策略 p * 0 , n - 1 = ( d * 0 , d * 1 , … , d * n - 1 ) 得到 的 最优 状态 ( 具有 整体 满意 解 的 n 个 特征 ) ， 则 由 最优 策略 ( p * 0 , n - 1 , d * n ) 得到 的 s * n + 1 = Tn ( s * n , d * n ) 也 是 最优 状态 . 
 　 　 特征选择 算法 
 　 　 1 ) 置 k = 0 , sk = s0 = ｛ Φ ｝ , Fk = ｛ O ｝ , p0 , k - 1 = ｛ Φ ｝ , V0 , k - 1 ( s0 , p0 , k - 1 ) = 0 ; 
 　 　 2 ) 若 k > pro - num ， 则 转 8 ； 否则 ， 转 3 ； 
 　 　 3 ) 对 x ∈ Fk , 按 ( 7 ) 式 计算 性能 函数 vk ( sk , x ) ， 并 确定 
 　 　 4 ) 若 vk ( sk , dk ) < 0 ， 则 转 8 ； 否则 ， 转 5 ； 
 　 　 5 ) V0 , k ( s0 , p0 , k ) = V0 , k - 1 ( s0 , p0 , k - 1 ) + vk ( sk , dk ) ; 
 　 　 6 ) sk + 1 ← dk , , Fk ← Fk ＼ dk , p0 , k = ｛ p0 , k - 1 , dk ｝ ; 
 　 　 7 ) k ← k + 1 , 转 2 ； 
 　 　 8 ) 结束 . 
 其中 pro - num 为 预定 的 特征 数目 . 
 　 　 算法 中有 两个 结束 条件 ： 1 ) 到达 预定 的 特征 数目 ； 2 ) 性能 函数 有 减无增 . 条件 2 ) 表明 ， 由于 特征 间 存在 相关性 ， 甚至 矛盾性 ， 特征 数目 并非 越多越好 . 算法 可 同时 给出 特征 数目 与 被 选 特征 分量 的 满意 解 . 如 无 特殊要求 ， 可设 pro - num = F ， 由 算法 自动 确定 应 选择 的 特征 数目 . 
 　 　 特征选择 属于 NP 难解 的 组合 优化 问题 ， 被 选 特征 空间 维数 的 增加 会 引起 给合 爆炸 . 基于 动态 规划 的 特征选择 算法 ， 利用 特征 - 模式 样本 集 的 内部 信息 ， 实现 了 自 适应 优化 搜索 ， 大大减少 了 特征选择 的 计算 量 . 
 4 　 应用 实例 
 　 　 上述 方法 用于 回音 声纳 目标 的 特征选择 . 通过 对 目标 回波 信号 的 时频 分析 ， 可 提取 多种类型 的 时频 特征 . 在 此 ， 考虑 两种 类型 的 模式 特征 ： 一类 是 信号 的 倒 谱 特征 ( 图 1 中 的 前 30 维 ) ， 另一类 是 包含 信号 幅值 分布 、 过 零点 分布 等 的 波形 结构特征 ( 图 1 中 的 后 13 维 ) . 
 
 
 图 1 　 两类 目标 的 特征向量 典例 
 　 　 本文 考虑 两类 目标 的 分类 问题 ， 即 C = 2 . 训练 集取 136 个 样本 ， 测试 集取 396 个 样本 . 在 同一 训练 集内 ， 用 30 维倒 谱 特征 、 13 维 波形 结构特征 ， 以及 它们 简单 合并 后 的 43 维 特征 分别 训练 结构 自 适应 神经网络 ［ 6 ］ ， 得到 三个 品质 最好 的 分类 模型 . 它们 在 同一 测试 集 的 正确 识别率 如表 1 所示 . 
 　 　 本文 采用 离散 区间 法 估计 互信息 . 考虑 特征 分量 幅值 的 大 与 小 所 包含 的 信息量 可能 是 等价 的 ， 文中 取 各 特征 分量 的 离散 区间 数目 相同 ， 均取 10 . 这 对 融合 从 不同 渠道 得到 的 特征 信息 更有意义 ， 因为 不同 类型 特征 之间 难以实现 一致性 归一化 . 图 2 表示 了 43 个 特征 分量 各自 包含 的 类别 信息 . 
 　 　 特征选择 与 相关性 系数 α 有关 . α 的 大小 决定 于 模式 的 特征 分布 ， 文中 采用 试验 法 . 
 表 1 　 各类 特征 集下 测试 结果 比较 
 
 特   征   集识 　 别 　 率 　 ( % ) 
 Ⅰ 　 类 Ⅱ 　 类 Ⅲ 　 类 
 30 维倒 谱 86.589 . 388.0 
 13 维 波形 87.183 . 985.4 
 43 维 合并 85.784 . 685.1 
 
 
 图 2 　 各 特征 分量 与 类别 空间 的 互信息 
 　 　 一般 在 不 预定 所 选 特征 数目 的 情况 下 ， α 越小 选择 的 特征 个数 越 多 ， 反之 越少 . 用 与 计算 表 1 相同 的 训练 集 、 测试 集 和 神经网络 模型 ， 选用 不同 的 α ， 得到 的 特征 数目 和 融合 性能 如表 2 . 
 表 2 　 特征 融合 后 的 测试 结果 
 
 α 特   征   集识 　 别 　 率 　 ( % ) 
 Ⅰ 　 类 Ⅱ 　 类平 　 均 
 0.23591 . 892.191 . 9 
 0.253291 . 693.292 . 4 
 0.352589 . 790.189 . 9 
 
 5 　 结 　 语 
 　 　 多 类 特征 信息 的 综合 选择 是 模式识别 领域 的 重要环节 ， 有效 、 快速 的 选择 算法 一直 为 人们 所 关注 . 本文 从 理论 上 分析 了 特征选择 的 机理 ， 提出 了 一种 特征选择 的 性能指标 . 基于 这种 性能指标 ， 特征选择 问题 可用 动态 规划 方法 描述 . 这样 一个 复杂 的 多类 特征 信息 融合 的 全局 满意 解 寻求 过程 ， 转变成 一个 简单 的 阶段性 局部 最优化 问题 ， 且 由 各 阶段 最优 决策 构成 的 整体 策略 等价 于原 问题 的 全局 满意 解 . 本文 法 的 特点 是 计算 简单 ， 所 选 特征 数目 可 由 算法 自动 确定 ， 在 本文 的 实例 中 取得 了 较 满意 的 效果 ， 其 满意 程度 受 相关性 系数 α 的 限制 . 文中 α 需 通过 试验 确定 . 由于 所 采用 的 性能指标 是 一定 前提 下 的 近似 最优 ， 所以 在 一般 意义 下 ， 本 方法 得到 的 不 一定 是 最 满意 解 . 
 1 ) 中国 博士后 科学基金 资助 项目 . 
 作者 单位 ： ( 海军 大连 舰艇 学院 　 大连 　 116018 ) ( 哈尔滨工程大学 水声 工程系 　 哈尔滨 　 150001 ) 
 参考文献 
 　 1 　 Elshaikl   T   S ,   Wacker   A   G .   Effect   of   dimensionality   and   estimation   on   the   performance   of   Gaussin   classifiers .   IEEE   trans .   PAMI ,   1980 ,   2 ( 12 ) : 115 — 126 
 　 2 　 Foroutan   I ,   Sklansky   J .   Feature   selection   for   automatic   classification   of   non   Gaussian   data .   IEEE   trans .   SMC ,   1987 ,   17 ( 2 ) : 187 — 198 
 　 3 　 宣国荣 ， 柴佩琪 . 基于 巴氏 距离 的 特征选择 ， 模式识别 与 人工智能 ， 1996 ， 9 ( 4 ) ： 324 — 329 
 　 4 　 Battiti   R .   Using   mutual   information   for   selecting   features   in   supervised   neural   net   learning .   IEEE   trans .   NN ,   1994 , 5 ( 4 ) : 537 — 550 
 　 5 　 章 新华 . 遗传算法 及其 应用 . 火力 与 指挥 控制 ， 1997 ， 22 ( 4 ) ： 49 — 53 
 　 6 　 Zhang   X   H ,   Lin   L ,   Wang   J   C .   A   neural   network   with   self - organizing   structure   and   its   applications .   In : Proc .   of   Inte .   Conf .   on   Neural   Information   Processing ,   Beijing ,   1995 ,   2 : 906 — 909 
 收稿 日期 　 1997 - 06 - 20 
