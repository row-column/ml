计算机 应用 研究 
 APPLICATION   RESEARCH   OF   COMPUTERS 
 2000   Vol.17   No.3   P.30 - 32 , 68 
 
 
 
 
 利用 集群 技术 构建 Linux   Virtual   Server 
 沈中林 　 金宝鼎 　 扬明 
 摘 　 要 ： 在 网络系统 性能 研究 中 ， 集群 技术 是 提高 系统 综合性 能 的 一种 重要 方法 。 在 Linux 操作系统 平台 上 构建 了 集群 Virtual   Server ， 并 详细 论述 了 其 原理 和 构建 过程 。 重点 描述 了 地址 转换 ( NAT ) 、 IP 隧道 ( IP   Tunneling ) 和 直接 路由 ( Direct   Routing ) 三种 IP 层 的 负载 均衡 办法 及 满足 不同 应用 需要 的 四种 分担 算法 ( RR 、 WRR 、 LC 和 WLC ) 等 核心 过程 ， 实践 结果 证明 ， 集群 技术 研究 是 成功 的 ， 对系统 性能 的 提高 是 明显 的 。 
 关键词 ： 集群   负载 均衡   Virtual   Server   地址 转换 
 1 　 集群 概述 
 　 　 随着 因特网 的 爆炸性 发展 ， 服务器 性能 出现 了 瓶颈 ， 当 访问 需求 增长 时 ， 服务器 会 在 很 短 的 时间 内 超载 。 对 现有 服务器 硬件 进行 升级 ， 过程 十分复杂 ， 而且 升级 越高 ， 花费 越 多 。 一旦 该 服务器 出现 问题 ， 整个 系统 会 陷入 瘫痪 。 集群 技术 由此 应运而生 。 
 　 　 广义 说 ， 一个 集群 是 相互 独立 的 一些 系统 作为 一个 系统 工作 ， 它们 构成 了 一个组 ， 叫 集群 。 构成 集群 的 目的 是 为了 提高 系统 的 可用性 和 规模 可扩展性 。 在 集群 系统 中 ， 每台 服务器 承担 各自 的 任务 ， 因而 服务器 的 个数 将 与 工作效率 呈 正比 增长 。 集群 具有 的 优点 ： 
 　 　 可用性 ( Availability ) ： 当 集群 中 的 一个 系统 发生 故障 时 ， 集群 软件 迅速 作出反应 ， 将 该 系统 的 任务分配 到 集群 中 其它 正在 工作 的 系统 上 执行 ， 即 提供 永不 停机 ( Non - stop ) 的 服务 。 
 　 　 可伸缩性 ( Scalability ) ： 即 规模 可扩展性 。 当 总体 的 工作 流量 超出 了 一个 集群 中 各 系统 的 能力 时 ， 将 有 其它 系统 加入 到 该 集群 中 ， 从而 使 系统 总体 性能 得以 增强 。 
 2 　 创建 Linux   Virtual   Server 
 2.1 　 Virtual   Server 的 概念 
 　 　 Virtual   Server 是 建立 在 若干个 松散 连接 的 独立 服务器 之上 的 高 可靠 、 可 扩展 的 虚拟 服务器 ， 整个 集群 结构 对 外界 用户 来说 是 透明 的 。 客户端 与 集群 相互作用 ， 整个 集群 像 一台 高性能 和 高 可靠 的 服务器 ， 客户端 不 受 任何 影响 ， 也 不 需 任何 改动 。 请 参看 图 1 。 Real   Server 可以 通过 高速 LAN 或 物理 上 分散 的 WAN 相连 。 
 
 图 1 　 Virtual   Server 的 结构 
 　 　 Real   Server 的 前端 是 一 负载 均衡器 ( Load   Balancer ) ， 由 它 将 客户 请求 送到 不同 的 Real   Server ， 每个 Real   Server 有 自己 的 IP地址 ， 但 客户端 仅 看到 一个 IP地址 ( 即 Load   Balancer 的 地址 ) ， 这样 多个 Real   Server 提供 的 相同 并行 服务 就 像 一个 IP地址 提供 的 一样 。 
 　 　 在 Virtual   Server 中 很 容易 加入 或 移走 一 Real   Server ( 结点 ) ， 实现 规模 扩展 ， 分担 负载 ， Load   Balancer 上 运行 的 程序 能 对 结点 或 进程 进行 监测 ， 保证 提供 高 可用 的 服务 。 
 2.2 　 Virtual   Server 工作 原理 
 　 　 Virtual   Server 有 三种 实现 技术 ， 分别 是 NAT 、 IP   Tunneling 和 Direct   Routing 。 
 　 　 NAT ： ( Network   Address   Translation ) Load   Balancer 重写 请求 包 的 目的 地址 ， 转发给 选定 的 Server ， Load   Balancer 再 改 回送 包 的 源地址 为原 目的 地址 ， 回 送给 客户端 。 
 　 　 IP   Tunneling ( IP 隧道 技术 ) ： Load   Balancer 用 IP 数据 报 封装 请求 包并 转发给 选定 的 Real   Server ， 该 Server 直接 响应 用户 ( 不需 Load   Balancer 再次 参与 ) 。 
 　 　 Direct   Routing ( 直接 路由 ) ： 和 IP 隧道 技术 相比 ， 该法 不 需 封装 的 开销 ， 但 要求 Load   Balancer 和 Real   Server 在 同一个 物理 网段 内 。 
 2.2 . 1 　 Virtual   Server   via   NAT 
 　 　 由于 目前 IP地址 的 短缺 和 基于 安全性 的 考虑 ， 越来越 多 的 网络 使用 私有 IP地址 ( 不能 用 在 网络 之外 或 Internet 上 ) 。 当 内部 网络 的 主机 想 访问 因特网 或 能 被 因特网 上 其他 用户 访问 时 ， 必须 对 其 进行 地址 转换 。 Internet 协议 的 信息 头 经过 适当 调整 后 ， 能 使 客户端 相信 它们 在 与 一个 IP地址 通信 ， 但 实际上 是 不同 IP地址 的 多个 Server 。 
 　 　 Load   Balancer 和 Real   Server 用 交换机 或 集线器 相连 ， Load   Balancer 通过 NAT 将 请求 分发 到 不同 的 Servers 。 其 工作 流程 如下 ： 
 　 　 用户 向 集群 服务 发出请求 ， 发 往 虚拟 IP地址 ( Load   Balancer 的 外部 IP地址 ) 的 请求 包 到达 后 ， Load   Balancer 检查 该 请求 包 的 目的 地址 和 端口号 ， 若 与 Virtual   Server 提供 的 服务 相符 ， 便 采用 特定 算法 从 集群 中 选择 某一 Real   Server ， 同时 该 连接 被 加入 所有 已 建立 的 连接 表 ( Hash   table ) 中 。 然后 把 数据包 的 目的 地址 和 端口 改写 成 选定 的 Real   Server 的 地址 和 端口 ， 并 转发给 该 Real   Server 。 当 以后 进入 的 数据包 属于 此 连接 并且 该 连接 能 在 Hash   table 中 找到 ， 都 会 改写 地址 和 端口 并 转发给 Real   Server 。 当 返回 数据包 时 ， Load   Balancer 会 将 其 源地址 和 端口号 改写 为 Virtual   Server 的 地址 和 端口号 。 当 连接 终止 或 超时 后 ， 该 连接 记录 会 从 Hash   table 中 清除 。 
 　 　 优点 ： Real   Server 可 运行 在 任何 支持 TCP / IP 的 操作系统 上 ， 能 使用 私有 IP地址 ， 仅 需要 一 合法 的 IP地址 配给 Load   Balancer 。 
 　 　 缺点 ： 可扩展性 不够 好 ， 当 Server 的 结点 数 增加 至 25 或 更 多 时 ， Load   Balancer 会 成为 整个 系统 的 瓶颈 ， 因为 请求 包 和 回送 包都须 经过 Load   Balancer 重写 。 假设 TCP 包 的 平均 长度 为 536Bytes ， 重写 一个包 的 平均 延时 大约 为 60us ( 跟 处理器 的 速度 有关 ) ， 通过 Load   Balancer 的 最大 流量 为 8.93   Mbytes / s 。 如果 Real   Server 的 平均 流量 为 400Kbytes / s ， Load   Balancer 可 管理 大约 22 个 Real   Servers 。 
 2.2 . 2 　 Virtual   Server   via   IP   Tunneling   ( IP 隧道 ) 
 　 　 IP 隧道 ( IP 封装 ) 是 一种 用 IP 数据包 封装 IP 数据 的 技术 ， 它 能 使 发往 某 一 IP地址 的 数据包 经过 封装 后 转发 到 另 一 IP地址 。 在 Virtual   Server 中 ， Load   Balancer 使用 此 技术 封装 请求 包 ， 转发 到 不同 的 Real   Server 。 经 Real   Server 处理 后 ， 能 直接 把 结果 送给 客户端 ， 使 整个 过程 看起来 仍 像 单一 IP地址 提供 的 服务 。 
 　 　 其 工作 流程 如下 ： 用户 向 集群 服务 发出请求 ， 发 往 虚拟 IP地址 ( Load   Balancer 的 外部 IP地址 ) 的 请求 包 到达 后 ， Load   Balancer 检查 该 请求 包 的 目的 地址 和 端口号 ， 若 与 Virtual   Server 提供 的 服务 相符 ， 便 采用 特定 算法 从 集群 中 选择 某一 Real   Server ， 同时 该 连接 被 加入 所有 已 建立 的 连接 表 ( Hash   table ) 中 。 然后 Load   Balancer 用 IP 数据包 封装 该 数据包 ， 并 转发给 选定 的 Real   Server 。 当 以后 进入 的 数据包 属于 此 连接 并且 该 连接 能 在 Hash   table 中 找到 ， 都 会 被 再 封装 并 转发给 Real   Server 。 Real   Server 接收 封装 的 数据包 后 ， 去除 封装 ， 处理 请求 后 ， 将 结果 直接 送回 客户端 ， 不需 Load   Balancer 再次 参与 。 当 连接 终止 或 超时 后 ， 该 连接 记录 会 从 Hash   table 中 清除 。 
 　 　 注意 Real   Server 在 任何 网络 中 可以 有 合法 的 IP地址 。 
 　 　 优点 ： 很多 Internet 服务 都 是 请求 包较 短 ， 而 回送 包 携带 大量 数据 ， 如 Web 服务 。 在 Virtual   Server   via   IP   Tunneling 中 ， Load   Balancer 只 将 请求 送往 不同 的 Real   Server ， Real   Server 直接 回应 用户 请求 ， 因此 Load   Balancer 可以 处理 大量 请求 ， 管理 大约 100 个 Servers 且 不会 成为 系统 瓶颈 ， 最大 流量 可达 1Gbps 。 
 　 　 可 用于 建设 高性能 的 Virtual   Server ， 尤其 是 虚拟 代理服务器 。 代理服务器 在 接收 请求 后 ， 获得 所 需 数据 后能 直接 回送 客户端 。 
 　 　 缺点 ： 要求 所有 Real   Server 支持 IP 隧道 协议 。 但 随着 IP 隧道 协议 成为 操作系统 的 标准 ， 该 技术 将 应用 于 所有 的 操作系统 。 
 2.2 . 3 　 Virtual   Server   via   Direct   Routing 
 　 　 Real   Server 和 Load   Balancer 共享 一个 虚拟 IP地址 ， 所有 的 Real   Server 须 将 Loopback   Alias 的 接口 配置 成 虚拟 IP地址 ， Load   Balancer 也 要 将 接口 配置 虚拟 IP地址 来 接收 请求 包 。 Real   Server 和 Load   Balancer 通过 HUB / Switch 连接 。 
 　 　 用户 向 集群 服务 发出请求 ， 发 往 虚拟 IP地址 的 请求 包 到达 后 ， Load   Balancer 检查 该 请求 包 的 目的 地址 和 端口号 ， 若 与 Virtual   Server 提供 的 服务 相符 ， 便 采用 特定 算法 从 集群 中 选择 某一 Real   Server ， 同时 该 连接 被 加入 所有 已 建立 的 连接 表 ( Hash   table ) 中 。 然后 Load   Balancer 直接 把 请求 包转发 给 选定 的 Real   Server 。 当 进入 的 数据包 属于 此 连接 并且 该 连接 能 在 Hash   table 中 找到 ， 都 会 被 直接 转发给 Real   Server 。 Real   Server 接收 转发 的 数据包 后 。 发现 地址 与 Loopback   Alias 的 地址 一样 ， 处理 请求 后 ， 将 结果 直接 送回 客户端 ， 不需 Load   Balancer 再次 参与 。 当 连接 终止 或 超时 后 ， 该 连接 记录 会 从 Hash   table 中 清除 。 
 　 　 优点 ： 不 需要 隧道 设备 ， 可 处理 大量 请求 ， Real   Server 可 运行 任何 操作系统 。 
 　 　 缺点 ： Load   Balancer 仅 改变 数据 帧 的 MAC 地址 为 选定 的 Real   Server 的 MAC 地址 ， 要求 它们 在 同一个 网段 内 。 
 　 从 Virtual   Server 中 选择 某一 Real   Server 有 很多 算法 ， 说明 如下 。 
 2.3 　 负载 分担 算法 
 　 　 目前 实现 了 四种 算法 用于 分担 负载 ， 分别 是 循环法 、 量值 循环法 、 最少 连接 法 和 量值 最少 连接 法 。 
 　 　 1 ) 循环法 ( Round - Robin ) 
 　 　 顾名思义 ， 用 循环 法则 选定 不同 的 Server 。 对 所有 Real   Server 平等 对待 不管 已有 的 连接 数目 和 响应 时间 。 注意 和 RRDNS 的 不同 ， RRDNS 是 将 单一 的 域 映射 为 不同 的 IP地址 ， 是 基于 主机 的 ， 缓存 会 使 其 失效 ， 导致 Real   Server 间 的 动态 失衡 。 
 　 　 2 ) 量值 循环法 ( Weighted   Round - Robin ) 
 　 　 对 不同 处理 能力 的 Real   Server 区别对待 ， 每一 Real   Server 会 指定 一 整数 量值 。 该 整数 量值 标志 处理器 能力 ， 默认值 为 1 。 如 Real   Server   A 、 B 、 C ， 量值 分别 为 4 、 3 、 2 ， 在 一个 周期 内 的 转发 顺序 将会 是 ABCABCABA 。 
 　 　 该法 不 需 计算 每一 Real   Server 的 网络连接 ， 开销 小 ， 可 管理 更 多 的 Real   Server ， 但 如果 请求 负载 变化很大 ， 会 导致 负载 动态 失衡 。 
 　 　 3 ) 最少 连接 法 ( Least - Connection ) 
 　 　 以 活动 连接 的 数目 决定 和 哪 一台 Server 连接 ， 是 一种 动态 算法 。 它 需要 动态 计算 每一 Server 的 活动 连接 数目 ， 以 最少 连接 的 Server 作为 转发 的 目的 地址 。 当 集群 中 Server 性能 接近 ， 网络 请求 负载 变化 较大 时 ， 是 一种 很 好 的 解决 算法 ， 因为 所有 较长 的 请求 不会 转发 到 同一 Server 。 
 　 　 4 ) 量值 最少 连接 法 ( Weighted   Least - Connection ) 
 　 　 是 最少 连接 法 的 扩展 ， 考虑 到 Real   Server 处理 的 能力 有所不同 ， 可以 指定 不同 量值 给 每 一 Real   Server 。 量值 大 的 Server 可 接受 更 多 的 连接 ， 每一 Server 的 活动 连接数 和 它 的 量值 成正比 ， 默认 量值 为 1 。 
 3 　 实验 
 　 　 我们 利用 机房 现有 的 条件 ， 搭建 了 一个 简易 的 实验 环境 ， 由于 条件 有限 ， 只用 NAT 构建 了 一 Linux   Virtual   Server ， 验证 了 负载 分担 。 
 3.1 　 实验 要求 
 　 　 1 ) 两台 PC 服务器 ， 运行 Windows   NT   Server   4.0 操作系统 ， 内装 IIS3.0 ， 提供 WWW 服务 。 
 　 　 2 ) 一台 PC ， 运行 Redhat   6.0 ( Linux 的 一个 版本 ) ， 并 安装 Virtual   Server   patch   for   kernel   2.2 . 10 ， 做 Load   Balancer 。 
 3.2 　 实验 步骤 
 　 　 1 ) 在 一台 Pentium   MMX   200MHz ， 内存 为 32M 的 PC机 上 安装 Redhat   6.0 ， 并 从 网上 下载 Virtual   Server   patch   for   kernel   2.2 . 10 ， 因 Redhat   6.0 的 kernel 为 2.2 . 5 ， 所以 在 安装 后须 对 内核 重新 编译 才 可 使用 。 
 　 　 2 ) 这 三台 计算机 以前 连 在 机房 的 局域网 上 ， 均 使用 原 保留 的 IP地址 ， 为了 实验 ， 将 两台 NT 的 地址 改为 10.1 . 1.2 和 10.1 . 1.3 ， Redhat   6.0 的 地址 除 保留 原有 IP地址 10.196 . 1.74 外 ， 再 配置 一 10.1 . 1.1 ， 使 其 和 NT 在 同一 网段 内 ， NT 的 默认 网关 指向 10.1 . 1.1 ， 子网掩码 为 255.255 . 255.248 。 
 　 　 3 ) 两台 NT   Server 提供 WWW 服务 ， 为了 验证 负载 被 均衡 到 两台 Server 上 ， 将 他们 的 主页 设为 不 一样 ， 根据 主页 的 显示 ， 就 可知 连接 的 是 哪 一台 Server 。 
 　 　 4 ) 在 Load   Balancer 上作 如下 配置 ： 
 　 　 ipvsadm   - A   - t   10.196 . 1.74 : 80   - s   wls ( Weighted   Least - Connection ) 注释 ： 使用 量值 最小 连接 算法 
 　 　 ipvsadm   - A   - t   10.196 . 1.74 : 80   - R   10.1 . 1.2 : 80   - m 
 　 　 ipvsadm   - A   - t   10.196 . 1.74 : 80   - R   10.1 . 1.3 : 80   - m   - w   2 
 　 　 5 ) 在 机房 内 任意 两台 连 在 网络 上 的 计算机 用 浏览器 先后 访问 Virtual   Server 的 外部 IP地址 10.196 . 1.74 。 如表 1 。 
 表   1 
 
 Protocol   Virtual   Ip 
 addressPortReal   Ip 
 addressPortWeight 
 TCP10.196 . 1.748010 . 196.1 . 2801 
 10.196 . 1.3802 
 
 3.3 　 实验 结果 
 　 　 用 浏览器 访问 10.196 . 1.74 ， 在 两台 计算机 先后 上 看到 了 不同 的 页面 ， 使用 浏览器 的 刷新 键 ， 页面 不 改变 ， 这 是因为 缓存 的 作用 。 清除 缓存 后 再 访问 ， 看到 的 页面 与 原先 不同 。 这 有效 地 证明 了 访问 的 负载 被 分担 到 两台 NT 上 ， 具体 看到 的 网页 和 访问 次序 以及 在 Load   Balancer 上 使用 的 分担 算法 有关 。 
 3.4 　 结果 分析 
 　 　 所有 目的 地址 为 10.196 . 1.74 端口 为 80 的 数据包 通过 真实 IP 为 10.1 . 1.2 端口 80 和 10.1 . 1.3 端口 80 均衡 ， 以下 给出 表 2 来 说明 ， 以 源地址 10.196 . 1.73 访问 10.196 . 1.74 为例 。   
 表   2 
 
 数据包 源地址 ： 端口 目的 地址 ： 端口 
 请求 包 10.196 . 1.73 ： 3456 （ C ） 10.196 . 1.74 ： 80 （ L ） 
 改写 10.196 . 1.73 ： 3456 （ C ） 10.1 . 1.2 ： 80 （ S ） 
 回送 包 10.1 . 1.2 ： 80 （ S ） 10.196 . 1.73 ： 3456 （ C ） 
 改写 10.196 . 1.74 ： 80 （ L ） 10.196 . 1.73 ： 3456 （ C ） 
 
 　 　 C ： Client   L ： Load   Balancer   S ： Real   Server   
 　 　 集群 系统 的 优势 在于 其 硬件 和 软件 的 冗余 。 通过 监测 结点 、 失败 的 进程 ， 重新 正确 配置 系统 ， 使 工作 流能 被 集群 中 的 其余 结点 接管 ， 以 得到 高可用性 的 集群 系统 。 
 　 　 在 Linux   Virtual   Server 中 ， 使用 软件 “ mon ” 和 “ fake ” 可 实现 高可用性 。 “ mon ” 是 一个 多用途 的 资源 监视 程序 ， 用于 监视 网络服务 的 可用性 和 结点 状态 。 “ fake ” 是 一个 IP 接管 软件 。 
 　 　 “ mon ” 运行 于 Load   Balancer 上 ， 监视 服务 进程 和 结点 状态 。 配置 fping . monitor 用于 监测 结点 每秒 是否 活动 ， 也 可 配置 相关 的 服务 监视 程序 用于 监视 每个 结点 的 服务 进程 ， 如 http . monitor 监测 http 服务 ， ftp . monitor 监测 ftp 服务 。 当 结点 失败 或 进程 死后 ， 会 在 Virtual   Server 中写 一条 警告 记录 并移 去 一条 规则 。 因此 ， Load   Balancer 能 自动 掩盖 进程 或 服务器 的 失败 ， 当 故障 恢复 后 ， 又 可 重新 提供 服务 。 
 　 　 现在 ， Load   Balancer 是 整个 系统 唯一 的 失败 点 了 ， 为了 防止 它 的 失败 ， 可 建立 Load   Balancer 的 备份 服务器 。 一旦 Load   Balancer 出现 故障 ， “ fake ” 运行 于 备份 服务器 上 ， 用于 接管 Load   Balancer ( 下转 第 68 页 ) ( 上接 第 32 页 ) 的 IP地址 ， “ mon ” 同样 运行 于 备份 的 Load   Balancer 上 ， 掌握 集群 的 状态 ， 当主 Load   Balancer 失败 后 ， 备份 Load   Balancer 继续 提供 服务 ， 但 当前 应用 已 建立 的 连接 会 丢失 ， 要求 客户端 重新 发送 请求 。 
 　 　 和 商用 的 成熟 的 集群 方案 比 起来 ， Linux   Virtual   Server 也许 不是 最好 的 ， 但 比起 购买 昂贵 的 高档 服务器 和 对 原有 硬件 升级 而言 ， Linux 的 Virtual   Server 是 一个 非常 物美价廉 的 解决方案 。 相对 于 NT 和 Solaris 等 商业 Unix 系统 来说 Linux 是 完全免费 的 ， 几乎 不花 什么 钱 ， 就 可以 从 网络 上 直接 获得 Linux 的 最新 版本 和 内核 ， 并 以此 来 构建 Linux   Virtual   Server ， 体验 集群 技术 带给 的 巨大 优势 。 
 　 　 当前 许多 的 ISP 都 通过 扩容 解决目前 的 网络 拥塞 问题 、 改善 带宽 ， 但 网络 的 发展 如此 之快 ， 未来 的 要求 就是 不断 扩容 ， 不断更新 。 能 不能 在 大规模 扩容 的 基础 上 ， 也 充分利用 廉价 资源 对 现有 网络 来 一些 适当 的 优化 呢 ？ Linux   Virtual   Server 也许 会 给 我们 一个 启示 。 
 沈中林 ( 新疆大学 数学系   乌鲁木齐   830046 ) 
 金宝鼎 ( 乌鲁木齐市 电信局 数据 分局   乌鲁木齐   830002 ) 
 扬明 ( 乌鲁木齐市 电信局 数据 分局   乌鲁木齐   830002 ) 
 参考文献 
 1   Joseph   Mack .   Creating   Linux   Virtual   Server   in   Linux   Expo ' 99   on   May   20 ,   1999 
 收稿 日期 ： 1999 年 9 月 30 日 
