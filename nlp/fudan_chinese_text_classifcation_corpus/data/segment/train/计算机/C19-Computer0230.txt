软件 学报 
 JOURNAL   OF   SOFTWARE 
 1999 年   第 1 期   No.1   1999 
 
 
 
 基于 局部 优先 的 汉语 句法分析 方法 * 
 周 　 强 　 黄 昌宁 
 　 　 摘要 　 提出 了 一种 利用 局部 优先 信息 对 汉语 分析 算法 进行 优化 的 新 方法 , 通过 利用 从 语料库 中 自动 获取 的 结构 优先 关系数据 作为 优先 判断 依据 . 此 方法 使 目前 的 汉语 概率分析 器 的 整体 效率 提高 了 近 30% , 显示 了 很 好 的 应用 前景 . 
 　 　 关键词 　 基于 优先 分析 , 句法分析 , 汉语 概率分析 器 , 语料库 . 
 　 　 中图法 分类号 　 TP18 
 An   Improved   Approach   for   Chinese   Parsing   Based   on   Local   Preference   Information 
 ZHOU   Qiang 　 HUANG   Chang - ning 
 　 　 Abstract 　 In   this   paper ,   a   new   technique   based   on   local   preference   information   is   proposed   to   improve   the   efficiency   of   Chinese   parsing   algorithm .   By   using   the   statistics   of   structure   preference   relations   as   the   figures   of   merit ,   the   overall   efficiency   of   the   current   Chinese   probabilistic   parser   has   been   improved   30%   by   this   method ,   which   shows   good   application   prospects . 
 　 　 Key   words 　 Preference - based   parsing ,   parsing ,   Chinese   probabilistic   parser ,   corpus . 
  　 在 图 分析 ( Chart   Parsing ) 算法 中 , 一种 很 常用 的 优化 技术 是 Best - First 技术 . 其 主要 思想 是 在 分析 调度 器 ( Agenda ) 的 控制 下 , 每次 尽可能 选择 最佳 的 成分 边 进行 组合 扩展 , 从而 迅速 得到 句子 的 最佳 分析树 , 极大地提高 了 分析 效率 . 在 这 一 过程 中 , 如何 选择 合适 的 优先 评价 机制 , 对 各个 不同 成分 在 正确 的 句法树 中 出现 的 可能性 进行 准确 的 评估 , 就 成 了 一个 关键问题 . 近几年来 , Magerman   &   Weir ［ 1 ］ 和 Charaballo   &   Charniak ［ 2 ］ 开始 探索 将 概率 信息 引入 Best - First 技术 中 , 取得 了 很 好 的 效果 . 
 　 　 Best - First 技术 主要 着眼于 从 全局 上 把握 不同 句法 成分 在 分析树 中 的 优先 关系 . 基于 优先 ( Preference - based ) 技术 ［ 3 ］ 则 更 侧重于 对 局部 语境 下 的 歧义 结构 的 排歧 处理 . 一个 典型 的 例子 是 对 英语 的 介词 短语 连结 ( Prepositional   Phrase   Attachment ) 问题 的 自动 排歧 处理 . Hindle 和 Rooth ［ 4 ］ 提出 可以 利用 从 自动 分析 的 语料库 中 获取 的 介词 与 中心动词 以及 中心 名词 的 关联 强度 的 不同 来 排除 PP 连结 歧义 . R . Basili 等 人 ［ 5 ］ 进一步 利用 了 语义 标记 信息 , 提高 了 排歧 能力 . 而 Collins 和 Brooks ［ 6 ］ 则 采用 了 Backing - Off 方法 对此 问题 进行 处理 . 
 　 　 本文 提出 一种 将 以上 两种 技术 有机 结合 起来 的 高效 分析方法 . 它 将 局部 优先 信息 作为 Best - First 的 选择 控制 机制 , 通过 合理 地 排除 局部 优先 组合 能力 较 小 的 句法 成分 , 从而 达到 提高 整体 分析 效率 的 目的 . 其 基本 分析 框架 是 在 目前 的 汉语 概率分析 器 ［ 7 ］ 中 采用 的 匹配 分析 算法 ［ 8 ］ , 而 局部 优先 信息 则 利用 了 从 语料库 中 自动 获取 的 结构 优先 关系 ( SPR ) 数据 . 目前 的 实验 结果表明 , 此 方法 的 应用 使 分析器 的 整体 效率 提高 了 近 30% , 显示 了 很 好 的 处理 效果 . 本文 第 1 节 简要 介绍 了 汉语 匹配 分析 算法 的 基本 内容 , 第 2 节 分析 了 局部优化 方法 的 基本思路 , 第 3 节 介绍 了 具体 的 实现 方法 , 第 4 节 给出 目前 的 一些 实验 结果 , 并 对此 进行 了 分析 , 第 5 节是 结束语 . 
 1 　 匹配 分析 算法 简介 
 　 　 文献 ［ 7 ］ 中 提出 的 汉语 概率分析 器 对 汉语 句子 的 分析 主要 通过 以下 3 个 阶段 来 完成 ： ①   成分 边界 预测 ; ②   括号 匹配 ; ③   统计 排歧 . 其中 括号 匹配 处理 起着 承上启下 的 作用 , 它 主要 用来 解决 这样 一个 分析 问题 ： 以 特征向量 S = 〈 WTB , MRR 〉 作为 分析器 的 输入 , 如何 通过 其中 左右 括号 的 合理 匹配 , 组合 产生 所有 可能 的 句法 成分 , 最终 形成 输入 句子 的 完整 分析树 （ 或 森林 ） . 
 　 　 其中 WTB = 〈 W , T , B 〉 , W = w1 , w2 , ... , wn 为 句子 的 词语 串 , T = t1 , t2 , ... , tn 为 各 词语 相应 的 词类 标记 串 , B = b1 , b2 , ... , bn 则 是 一串 成分 边界 信息 描述 , bi 可 取值 0 , 1 或 2 , 分别 表示 词语 wi 处于 某个 句法 成分 的 中间 位置 、 左 边界 （ 即 被 赋予 左 括号 ） 和 右 边界 （ 即 被 赋予 右 括号 ） 位置 , 它们 是 进行 括号 匹配 的 基础 , 并且 可以 利用 现有 的 成分 边界 自动 预测 工具 ［ 9 ］ 得到 . 而 MRR 则 是 一组 匹配 限制 区间 描述 , 它们 将 对 其间 的 匹配 操作 进行 有效 的 限制 . ［ 10 ］ 
 　 　 匹配 分析 算法 的 实现 将 涉及 到 两个 重要 的 子 问题 ： ( 1 )   成分 划分 问题 , 即 哪些 左右 括号 对 可以 相互 匹配 形成 一个 可能 的 句法 成分 ; ( 2 )   成分 定性 问题 , 即 这些 匹配 形成 的 成分 能标 以 什么样 的 句法 标记 . 从 直观 上 看 , 它 可以 这样 来 进行 ： 从 左向右 扫描 句子 , 直至 发现 一个 匹配 右项 * , 从此 成分 出发 , 搜索 所有 左 相邻 的 匹配 左项 * * , 通过 匹配 操作 形成 新 的 句法 成分 , 然后 以此 新 成分 为 驱动 , 进行 类似 的 操作 . 这个 过程 自 左向右 、 自 底向上 不断 进行 , 直至 扫描 到 句子 结束 为止 . 
 　 　 而 具体 的 算法 则 是 在 以下 3 个 基本 控制结构 上 实现 的 , 它们 是 通过 对 LR 分析器 ［ 11 ］ 和 图 分析器 ［ 12 ］ 的 有效 控制结构 的 合理 吸收 和 适当 改进 而 形成 的 . 
 　 　 ( 1 )   括号 匹配 栈 ( BMS ) ： 保存 了 进行 句法分析 所 需 的 所有 边界 控制 信息 , 功能 相当于 Tomita 算法 ［ 11 ］ 中 的 图 结构 栈 . 
 　 　 ( 2 )   压缩 共享 森林 ( PSF ) ： 保存 了 经 括号 匹配 得到 的 所有 句法 成分 信息 , 类似 于 chart 结构 . 
 　 　 ( 3 )   待 匹配 成分表 ( PEL ) ： 保存 了 所有 待处理 的 匹配 右项 信息 , 可 作为 一个 分析 调度 器 ( Agenda ) . 
 　 　 有关 这一 算法 的 详细 内容 可 参阅 文献 ［ 8 ］ . 
 2 　 基于 局部 优先 的 优化 分析 
 　 　 考虑 如下 的 输入 信息 片段 ： ［ wi ［ wi + 1 　 wi + 2 ］ wi + 3 ］ ( 为 简便 起 见 , 这里 省略 了 词类 信息 描述 ) . 利用 现有 的 匹配 分析 算法 , 将 同时 得到 图 1 所示 的 两棵 分析 子树 ( a ) 和 ( b ) 中 的 5 个 匹配 成分 Ai , i ∈ ［ 1 , 5 ］ , 而 实际上 , 其中 只能 有 一棵 子树 可以 出现 在 正确 的 句法分析 树中 . 从 这个 角度看 , 目前 的 匹配 算法 中 还 存在 许多 冗余 的 匹配 操作 , 具有 很大 的 可以 优化 的 余地 . 
 
 图 1 　 一个 输入 片段 的 匹配 分析 结果 
 　 　 对图 1 深入 地 分析 可以 得出 , 两棵 子树 优先选择 的 关键 是 确定 匹配 成分 A1 在 局部 语境 wi 和 wi + 3 下 的 优先 组合 关系 ： 如果 左 向 组合 优先 , 即 优先 匹配 产生 句法 成分 A2 , 则 选择 子树 ( a ) ； 如果 右向 组合 优先 , 即 优先 匹配 产生 句法 成分 A3 , 则 选择 子树 ( b ) , 两者 必居其一 . 据此 , 我们 可以 形成 一个 利用 局部 优先 信息 对 现有 匹配 分析 算法 进行 优化 的 基本思路 ： 在 局部 语境 信息 约束 下 , 只 选择 优先 结构 组合 进行 匹配 操作 , 而 排除 对 不 优先 结构 的 匹配 操作 , 从而 达到 减少 冗余 匹配 , 提高 分析 效率 的 目的 . 与 传统 的 Best - First 实现 机制 不同 的 是 , 此 方法 是 通过 对 局部 较差 情况 的 排除 来 间接 体现 Best - First 思想 的 , 因为 这 可以 与 目前 的 概率分析 器中 采用 的 匹配 分析 与 统计 排歧 同时 进行 的 分析 机制 很 好 地 融合 在 一起 . 
 　 　 有 多种 方法 可以 用来 判断 局部 语境 下 的 优先 组合 关系 . 目前 比较 常用 的 是 词 关联 ( Word   Association ) 技术 , 如 相关 信息 ( Mutural   Information ) 测度 等 . 具体做法 是 ： 抽取 中间 成分 的 中心词 wmh , 分别 计算 它 与 左 语境 中心词 wlh 和 右 语境 中心词 wrh 的 关联度 MI ( wlh , wmh ) 和 MI ( wmh , wrh ) , 然后 选择 其中 的 较大 者 作为 优先 组合 结构 . 前面 提到 的 对 英语 的 介词 短语 连结 问题 的 处理 就是 采用 了 这种 方法 . 本文 则 利用 了 结构 优先 关系 描述 项 ( SPR ) 信息 . 其 基本 形式 为 〈 IS , LP , RP 〉 , 其中 IS 为 交段 结构 , 表示 为 { 交段 前境   ＾ 交段 成分   交段 后境 } , 而 LP 和 RP 则 是 交段 成分 在 局部 语境 IS 下 的 左 向 组合概率 和 右 向 组合概率 , 例如 , SPR 项 { p   ＾ np   vp ,   0.97 ,   0.03 } 就 记录 了 这样 的 信息 ： 交段 成分 , 即 名词 短语 ( np ) 在 局部 语境 { p   np   vp } 下 与 交段 前境 , 即 介词 ( p ) 组合 的 概率 为 0.97 , 而 与 交段 后境 , 即 动词 短语 ( vp ) 组合 的 概率 则 为 0.03 . 这些 信息 可以 从 真实 语料 文本 中 自动 获取 , 其 基本 步骤 为 ： 利用 概率分析 器 对 真实 语料 文本 进行 自动 分析 , 得到 每个 句子 的 完全 分析树 , 其中 各个 成分 都 带有 概率分布 信息 ； 然后 遍历 分析树 , 发现 所有 可能 的 交段 结构 , 并 计算 分析树 中交段 左 向 和 右 向 组合 的 预期 频度 . 其 具体内容 将 另文 介绍 . 
 　 　 据此 , 可以 这样 来 对 现有 的 匹配 分析 算法 进行 优化 ： 对于 一个 待 匹配 成分 A , 在 句子 中 搜索 其 左匹配 语境 LMC 和 右 匹配 语境 RMC , 形成 一个 局部 语境 片段 { LMC   A   RMC } , 检索 SPR 表 , 如 在 其中 发现 一个 SPR 项 的 IS 与 此 局部 语境 片段 相同 , 则 可 根据 它 的 LP 和 RP 的 差异 程度 来 进行 优先选择 . 下节 将 介绍 具体 的 实现 方法 . 
 3 　 优化 分析 算法 的 实现 
 　 　 在 匹配 优化 算法 的 具体 实现 过程 中 , 首先 应 解决 以下 几个 问题 ： ( 1 )   如何 确定 一个 待 匹配 成分 的 局部 语境 ; ( 2 )   如何 保证 所 利用 的 SPR 数据 的 可靠性 ; ( 3 )   如何 把 不同 的 优化 控制 机制 很 好 地 结合 入 原来 的 匹配 分析 算法 中 . 下面 将 分别 进行 详细 的 讨论 . 
 3.1 　 局部 语境 的 确定 
 　 　 对于 一个 待 匹配 成分 A , 其 局部 语境 是 由 其 相邻 的 匹配 左项 和 匹配 右项 组成 的 . 在 目前 的 自 左向右 的 匹配 处理 机制 中 , 其 匹配 左项 的 确定 是 很 容易 的 , 因为 在 得到 匹配 成分 A 之前 , 它 左边 的 所有 可能 的 匹配 操作 都 已 完成 了 , 因此 , 只 需 搜索 BMS 和 PSF 就 可以 得到 . 困难 的 是 匹配 右项 的 获取 , 因为 在 当前 的 分析 状态 下 , 成分 A 右部 的 匹配 操作 还 没有 进行 . 
 　 　 考虑 这样 一个 分析 片段 ： ［ wi ［ A   wi + 1 　 wi + 2 ］ ［ wi + 3 　 wi + 4 ］ ］ , 对于 刚刚 匹配 生成 的 成分 A , 其 真正 的 匹配 右项 应为 词语 wi + 3 和 wi + 4 匹配 产生 的 成分 B , 但 目前 还 不能 得到 , 这 就 影响 了 对 成分 A 的 优化 选择 判断 . 为 解决 这个 问题 , 我们 提出 了 一种 延迟 选择 机制 , 具体方法 是 ： 增加 一个 延迟 匹配 成分表 ( DCL ) , 每当 遇到 类似 上面 的 不能 确定 所 需 的 匹配 右项 的 情况 时 , 就 将 该 成分 放入 DCL 中 , 继续执行 自 左向右 的 匹配 操作 , 每当 产生 一个 新 成分 时 , 需 检查 DCL 中 的 延迟 成分 所 需 的 右 语境 条件 是否 已 满足 , 若 是 , 则 将 它 从 DCL 中 取出 , 重新 插入 待 匹配 成分表 ( PEL ) 中 . 这样 , 通过 PEL 和 DCL 的 相互作用 , 保证 了 每个 待 匹配 成分 都 能 获取 其 局部 语境 来 进行 优化 选择 . 
 3.2 　 SPR 阈值 的 合理 选择 
 　 　 目前 的 SPR 数据 的 应用 条件 设置 为 ： | LP － RP | > β , 其中 的 阈值 β 反映 了 在 局部 语境 下交段 左 向 和 右 向 组合概率 的 差异 程度 . 在 此 条件 下 , 如果 LP > RP , 则 只 进行 左 向 组合 匹配 ； 反之 , 则 只 进行 右向 组合 匹配 . 
 　 　 一般来说 , β 越大 , 优化 操作 出错 的 可能性 就 越 小 , 因为 它 只是 排除 了 那些 在 局部 语境 下 极少 可能 出现 的 匹配 组合 情况 . 但 由于 它 对 SPR 项数 的 过强 限制 , 使 优化 效率 的 提高 显得 不是 很 充分 , 极端 情况 是 β = 1 , 此时 优化 机制 将 不起作用 . 反之 , β 越小 , 则 满足 这一 条件 的 SPR 项数 就 越 多 , 从而 可以 对 句子 中 大量 的 局部 语境 进行 优化 , 大大提高 了 分析 效率 , 但 同时 可能 会 排除 一些 正确 的 匹配 组合 情况 , 从而 使 最终 分析 结果 的 准确度 有所 下降 . 因此 , 合理 的 做法 是 通过 选择 一个 合适 的 阈值 β , 在 保证 所 利用 的 SPR 数据 的 可靠性 的 前提 下 , 尽可能 扩大 其 应用 范围 , 从而 在 优化 效率 和 分析 结果 的 准确性 之间 寻找 到 一个 平衡点 . 
 3.3 　 优化 算法 的 基本 控制 流程 
 　 　 通过 将 上 两节 介绍 的 优化 控制 机制 有效 地 结合 入 原有 的 匹配 分析 算法 ［ 8 ］ 中 , 我们 形成 了 一个 改进 的 优化 匹配 算法 , 下面 给出 其 基本 的 控制 流程 . 其中 , 步骤 ( 2 ) 和 ( 3 ) 实现 了 语境 延迟 选择 机制 , 而 步骤 6 则 增加 了 局部 优先 条件 的 判断 , 据此 可以 排除 大量 局部 优先 性较 小 的 匹配 操作 . 
 　 　 ( 1 )   从 PEL 中 获得 一个 待 匹配 成分 A ； 
 　 　 ( 2 )   在 BMS 中 搜索 其 匹配 右项 RMC ； 
 　 　 ( 3 )   如果 找 不到 , 则 将 成分 A 移入 DCL 中 , 转 ( 8 ) ； 
 　 　 ( 4 )   在 BMS 和 PSF 中 搜索 得到 一个 匹配 左项 LMC ； 
 　 　 ( 5 )   检查 局部 语境 { LMC   A   RMC } 下 的 优先 组合 关系 ； 
 　 　 ( 6 )   如果 左 向 组合 优先 , 则 进行 匹配 操作 ： ［ LMC   A ］ , 否则 转 ( 7 ) ； 
 　 　 ( 7 )   如果 还有 其他 的 匹配 左项 , 则 转 ( 4 ) ； 否则 转 ( 8 ) ； 
 　 　 ( 8 )   如果 PEL 不空 , 则 转 ( 1 ) ； 否则 算法 结束 . 
 4 　 实验 结果 分析 
 　 　 我们 采用 了 文献 ［ 10 ］ 中 开发 的 汉语 树库 ( Treebank ) 作为 实验 语料 , 它 由 以下 两 部分 组成 ： ( 1 )   汉英 机器翻译 研究 的 测试 题库 （ 语料 A ） . 语料 的 规模 为 1   434 个 汉语 句子 , 约 11   821 个 词 , 汉字 总数 为 17   058 , 平均 句长 为 8.243 词 / 句 ; ( 2 )   新加坡 小学 语文课 本 语料 （ 语料 B * , 总 规模 为 4   139 个 句子 , 约 52   609 个 词 , 汉字 总数 为 72   434 个 , 平均 句长 为 12.711 词 / 句 . 
 　 　 通过 对 实验 语料 的 均匀 抽样 , 形成 了 11 个 测试 样本 , 平均 每个 样本 包含 约 507 个 汉语 句子 . 然后 取 其中 的 前 10 个 组成 训练 语料 , 共 包含 5   071 个 句子 , 用于 训练 得到 进行 局部 优先 分析 所 需 的 SPR 数据 和 其他 统计数据 . 最后 的 第 11 个 样本 作为 测试 语料 , 共 包含 506 个 句子 , 用于 检测 优化 算法 的 分析 效果 . 
 　 　 实验 的 主要 目的 是 检查 局部 优先 信息 的 运用 对 汉语 概率分析 器 的 分析 效率 和 分析 结果 准确度 的 影响 . 其中 , 对 分析 结果 准确度 的 评估 主要 依据 了 以下 几个 性能指标 ： ①   括号 召回 率 ( MR ) , ②   括号 正确率 ( MP ) , ③   交叉 括号 数 ( CBs ) , ④   标记 正确率 ( LP ) . 有关 它们 的 详细 定义 可 参阅 文献 ［ 7 , 10 ］ . 而 分析 效率 则 是 通过 以下 几个 数据 体现 出来 的 ： 
 　 　 ( 1 )   匹配 成分 总数 ( MCSum ) ： 经 匹配 操作 而 加入 PSF 中 的 所有 匹配 成分 的 数目 , 它 是 与 所 进行 的 匹配 操作 的 数目 一一对应 的 . 
 　 　 ( 2 )   分析树 总数 ( PTSum ) ： PSF 中 所有 的 完整 分析树 * * 的 数目 , 它 从 一个 侧面 反映 了 对 句子 分析 结果 进行 排歧 处理 的 难易 程度 , 其 具体 计算方法 可 参阅 文献 ［ 10 ］ . 
 　 　 ( 3 )   CPU 时间 ： 为 分析 输入 句子 而 花费 的 所有 CPU 时间 （ 包括 进行 统计 排歧 所 需 的 时间 ） . 
 　 　 首先 进行 了 SPR 阈值 选择 实验 . 通过 设置 0.1 ～ 0.9 之间 的 9 个 不同 阈值 , 并 记录 不同 阈值 作用 下 的 优化 分析 数据 , 我们 得到 了 如表 1 所示 的 实验 结果 . 其中 同时 列出 了 原来 的 未经 优化 的 匹配 分析 算法 的 相应 数据 （ β = 1 的 行 ） , 以 作为 对 优化 效果 的 判定 依据 . 
 表 1 　 不同 SPR 阈值 作用 下 的 优化 分析 结果 
 
 β MR ( % ) MP ( % ) CBsLP ( % ) MCSumPTSumCPU 时间 ( s ) 
 189.9390 . 010.8795 . 171.19 × 1046.53 × 106228 
 0.989 . 8790.000 . 8795.218 . 55 × 1031.91 × 105184 
 0.890 . 1090.240 . 8495.228 . 39 × 1039.44 × 104166 
 0.790 . 0890.210 . 8595.278 . 25 × 1036.92 × 104179 
 0.690 . 3190.440 . 8295.318 . 13 × 1034.46 × 104173 
 0.590 . 4090.530 . 8295.318 . 08 × 1034.02 × 104170 
 0.490 . 5790.700 . 8095.308 . 03 × 1033.57 × 104158 
 0.390 . 5090.640 . 8195.327 . 94 × 1033.11 × 104166 
 0.290 . 4690.580 . 8195.297 . 93 × 1033.10 × 104176 
 0.190 . 4890.600 . 8195.247 . 82 × 1032.03 × 10417 
 
 带 阴影 行 （ β = 0.4 ） 为 最佳 阈值 
 　 　 从表 1 中 可以 看出 , 随着 阈值 β 的 不断 降低 （ 从 0.9 到 0.1 ） , 优化 算法 的 分析 效率 的 变化趋势 基本上 是 与 我们 的 预期 估计 相一致 的 ： 即 随着 对 SPR 项 的 限制 条件 的 不断 放宽 , 可以 对 越来越 多 的 局部 语境 下 的 匹配 操作 进行 优化 , 从而 使 分析器 产生 的 匹配 成分 总数 和 分析器 总数 不断 下降 . 尽管 由于 统计 排歧 过程 的 影响 , 使得 CPU 时间 的 变化趋势 显得 不是 很 明显 . 但 从总体上 看 , 分析 效率 还是 在 不断 提高 的 . 
 　 　 值得注意 的 是 分析 结果 准确度 的 变化趋势 。 它 经历 了 一个 逐步提高 ， 直至 达到 最高点 （ β = 0.4 ） , 然后 又 逐步 下降 的 变化 过程 . 这 是因为 当 β 值 较大 时 , SPR 项所 反映 的 局部 优先 知识 比较 可靠 , 因此 利用 它们 来 对 匹配 算法 进行 优化 , 不但 不会 对 整体 的 排歧 机制 产生 危害 , 反而 是 有利 的 , 因为 它们 可以 尽早 排除 在 局部 语境 下 极少 可能 出现 的 句法 成分 组合 , 并且 这些 被 排除 成分 的 数目 将 随着 β 的 减少 而 不断 增加 , 从而 使 统计 排歧 算法 可以 从 可能性 较 高 的 成分 组合 中 更 快 、 更好 地 选择 出 一棵 概率 意义 上 最佳 的 分析树 . 但 当 阈值 β 下降 到 一定 程度 时 , SPR 信息 的 可靠性 将 大幅度降低 , 此时 再 利用 它们 来 进行 匹配 优化 , 就 可能 把 大量 正确 的 成分 组合 在 局部 语境 检查 时 就 排除 掉 了 , 从而 使 分析 结果 的 准确度 逐步 下降 . 
 　 　 综合 以上 分析 , 我们 认为 , 针对 目前 所用 的 局部 优先 数据 SPR , 选择 β = 0.4 作为 阈值 是 比较 合适 的 . 在 此 条件 下 对 原有 的 匹配 分析 算法 进行 优化 , 得到 了 这样 的 结果 : 汉语 概率分析 器 的 CPU 时间 、 匹配 成分 总数 和 分析树 总数 分别 下降 了 30.7% , 32.5% 和 99.5% , 并且 最终 分析 结果 的 准确度 也 有所提高 , 显示 出 很 好 的 优化 效果 . 
 　 　 图 2 和 图 3 进一步 显示 了 在 优化 前 和 β = 0.4 的 优化 条件 下 , 测试 语料 中 具有 不同 长度 的 句子 集上 的 平均 匹配 成分 总数 和 平均 分析树 总数 的 分布 特点 . 从中 可以 看出 , 对于 简单 的 句子 （ 其中 的 词项 ( 包括 句子 中 的 词语 和 标点符号 数 ) < 20 ） , 局部优化 效果 并 不是 很 明显 ； 而 对于 复杂 的 句子 （ 其中 的 词 项数 ≥ 20 ） , 新 算法 则 显示 了 很 强 的 优化 能力 . 这 主要 是因为 , 在 复杂 句子 中 , 各种 可 进行 优化 的 局部 语境 出现 的 频度 很 高 , 同时 , 早期 对 局部 语境 下 的 某个 句法 成分 组合 的 排除 , 往往 会 导致 对 整个 分析 森林 中 包含 这个 成分 的 成千上万 棵 分析 子树 的 排除 , 这 可以 从 测试 语料 中 最长 的 句子 （ 词 项数 = 61 ） 在 优化 前后 的 分析 性能 的 变化 中 清楚 地看 出来 , 见表 2 . 
 
 
 图 2 　 语料 句子 长度 与 平均 匹配 成分 总数 关系 
 
 图 3 　 语料 句子 长度 与 平均 分析树 总数 关系 
 表 2 　 一个 复杂 句子 （ 词 项数 = 61 ） 的 优化 分析 结果 
 
 β MR ( % ) MP ( % ) CBsLP ( % ) MCSumPTSumCPU 时间 ( s ) 
 优化 前 80.0076 . 60994.442 . 09 × 1025.22 × 1064 
 优化 后 82.2278 . 72894.591 . 66 × 1021.61 × 1044 
 
 5 　 结束语 
 　 　 本文 提出 了 一种 基于 局部 优先 信息 的 优化 句法分析 方法 . 初步 的 实验 结果显示 , 即使 只 利用 基于 词类 标记 和 句法 标记 描述 的 比较简单 的 结构 优先 关系数据 进行 优化 处理 , 在 适当 的 SPR 阈值 作用 下 , 也 可以 使 分析器 的 整体 效率 提高 约 30% , 并且 仍 保持 很 高 的 分析 精度 . 其 主要 缺陷 是 , 对于 交段 左 向 和 右 向 组合概率 相差 较 小 （ 即 小于 SPR 阈值 ） 的 局部 组合 , 优化 机制 将 不起作用 . 为此 我们 设想 , 在 今后 的 研究 中 , 可以 进一步 利用 词汇 优先 信息 补充 SPR 数据 描述 的 不足之处 , 从而 更好 地 发挥 不同 层次 的 局部 优先 信息 的 综合 优化 效能 。 作为 基础性 的 分析方法 的 探索 研究 , 本文 的 成果 将 为 汉外 机器翻译 、 汉语 信息检索 和 信息 抽取 等 应用领域 的 研究 提供 有力 的 支持 。 
 本文 研究 得到 国家自然科学基金 和 中国 博士后 科学基金 资助 。 
 作者 介绍 ： 周强 , 1967 年生 , 博士 , 助理 研究员 , 主要 研究 领域 为 语料库 语言学 , 机器翻译 , 机器 学习 。 
 　 　 　 　 　 黄 昌宁 , 1937 年生 , 教授 , 博士生 导师 , 主要 研究 领域 为 计算 语言学 。 
 本文 通讯联系 人 ： 周强 , 北京   100084 , 清华大学 智能 技术 与 系统 国家 重点 实验室 
 注释 ： * 包括 : ( 1 ) 具有 右 边界 预测 标记 的 词语 ( bi = 2 ) ； ( 2 ) 匹配 产生 的 新 的 句法 成分 ( 形 如 [ ... ] ) 
 　 　 　 * * 包括 : ( 1 ) 具有 左 边界 预测 标记 的 词语 ( bi = 1 ) ； ( 2 ) 匹配 产生 的 新 的 句法 成分 ( 形 如 [ ... ] ) 
 　 　 　 * 此 语料 的 电子 版本 由 国立 新加坡 大学 赖 金定 博士 提供 ， 在 此 表示感谢 。 
 　 　 　 * * 一棵 完整 的 分析树 是 指 覆盖 输入 句子 的 所有 词语 的 分析树 。 
 作者 单位 ： 周 　 强 　 清华大学 计算机科学 与 技术 系 　 北京 　 100084 
 　 　 　 　 　 黄 昌宁 　 清华大学 智能 技术 与 系统 国家 重点 实验室 　 北京 　 100084 
 E - mail :   zhouq @ s1000e . cs . tsinghua . edu . cn 
 参考文献 
 　 ［ 1 ］ Magerman   D   M ,   Weir   C .   Efficiency ,   robustness   and   accuracy   in   Picky   chart   parsing .   In :   Church   K   ed .   Proceedings   of   the   30th   Conference   of   ACL   ( Association   of   Computational   Linguistics ) .   Newark ,   Delaware ,   1992 .   40 ～ 47 
 　 ［ 2 ］ Caraballo   S   A ,   Charniak   E .   New   figures   of   merit   for   best - first   probabilistic   chart   parsing .   Technical   Report ,   Brown   University ,   Nov .   26 ,   1996 
 　 ［ 3 ］ Church   K   W ,   Mercer   R   L .   Introduction   to   the   special   issues   on   computational   linguistics   using   large   corpora .   Computational   Linguistics ,   1993 , 19 ( 1 ) : 1 ～ 24 
 　 ［ 4 ］ Hindle   D ,   Rooth   M .   Structural   ambiguity   and   lexical   relations .   Computational   Linguistics ,   1993 , 19 ( 1 ) : 103 ～ 120 
 　 ［ 5 ］ Basili   R ,   Pazienza   M   T ,   Velardi   P .   Semi - automatic   extraction   of   linguistic   information   for   syntactic   disambiguation .   Applied   Artificial   Intelligence ,   1993 , ( 7 ) : 339 ～ 364 
 　 ［ 6 ］ Collins   M ,   Brooks   J .   Prepositional   phrase   attachment   through   a   backed - off   model .   In :   Yarowsky   D ,   Church   K   eds .   Proceedings   of   the   3rd   Workshop   on   Very   Large   Corpora .   Cambridge ,   Massachusetts :   Massachusetts   Institute   of   Technology ,   1995 .   27 ～ 38 
 　 ［ 7 ］ Zhou   Qiang .   A   statistics - based   Chinese   parser .   In :   Zhou   Joe ,   Church   K   eds .   Proceedings   of   the   5th   Workshop   on   Very   Large   Corpora .   Beijing :   Tsinghua   University   Press ,   1997 .   4 ～ 15 
 　 ［ 8 ］ 周强 ， 汉语 匹配 算法 的 实现 。 见 : 陈力 为 , 袁琦编 . 语言 工程 . 北京 : 清华大学出版社 , 1997.194 ～ 200 ( Zhou   Qiang .   Implementation   of   Chinese   parsing   algorithm   based   on   bracket   matching   principle .   In :   Chen   Li - wei ,   Yuan   Qi   eds .   Language   Engineer .   Beijing :   Tsinghua   University   Press ,   1997 .   194 ～ 200 ) 
 　 ［ 9 ］ 周强 ， 一个 汉语 短语 自动 界定 模型 . 软件 学报 , 1996 , 7 ( 增刊 ) : 315 ～ 322 ( Zhou   Qiang .   A   model   for   automatic   prediction   of   Chinese   phrase   boundary   location .   Journal   of   Software ,   1996 , 7 ( supplement ) : 315 ～ 322 ) 
 　 ［ 10 ］ 周强 ， 汉语 语料库 的 短语 自动 划分 和 标准 研究 ［ 博士学位 论文 ］ . 北京大学 , 1996 ( Zhou   Qiang .   Phrase   bracketing   and   annotating   on   Chinese   language   corpus   ［ Ph . D .   Dissertation ］ .   Beijing   University ,   1996 ) 
 　 ［ 11 ］ Tomita   M .   Efficient   Parsing   for   Natural   Language — — a   Fast   Algorithm   for   Practical   System .   Boston :   Kluwer   Academic   Publishers ,   1986 
 　 ［ 12 ］ Winograd   T .   Language   as   a   Cognitive   Process .   Vol.1 ,   Syntax .   Reading ,   MA :   Addison - Wesley ,   1983 .   116 ～ 129 
 本文 1997 - 11 - 20 收到 原稿 , 1998 - 01 - 23 收到 修改稿 
