微型机 与 应用 
 MICROCOMPUTER   &   ITS   APPLICATIONS 
 2000 　 Vol.19 　 No.4 　 P.14 - 16 
 
 
 
 MATLAB 下 神经网络 工具箱 的 开发 和 应用 
 刘晔 　 夏建生 
 摘   要 ：   Ｍ Ａ Ｔ Ｌ Ａ Ｂ 环境 下 神经网络 工具箱 的 使用 方法 和 技巧 ， 以 Ｂ Ｐ 网络 为例 介绍 了 网络 的 初始化 、 训练 和 仿真 函数 ， 给出 了 网络结构 的 设计 和 图形 结果 的 输出 方法 。 
 关键词 ：   Ｍ Ａ Ｔ Ｌ Ａ Ｂ 软件   神经网络   图形 结果 
 　 　 人工神经网络 （ ANN ） 技术 ， 是 一种 不 需要 选取 基 函数 系 的 非线性 函数 逼近 方法 ， 具有 自 学习 、 自 组织 和 自 适应 、 固有 的 并行 结构 和 并行处理 、 知识 的 分布 存储 、 容错性 等 功能 和 特点 ， 在 复杂 系统 的 建模 问题 上 表现 出 了 它 的 优越性 。 在 生物 、 商业 、 环境 、 金融 、 制造业 、 医学 、 军事 、 通信 等 方面 已经 获得 广泛应用 ， 因此 神经网络 的 实现 就 成为 当务之急 。 神经网络 的 实现 方案 可 分为 基于 传统 计算机技术 （ 包括 ： 软件 模拟 、 并行 处理器 阵列 、 传统 计算机 的 加强 等 ） 和 基于 直接 硬件 实现 （ 包括 ： VLSI 技术 、 光学 等 ） ， 但 目前 最 常用 的 方法 还是 软件 模拟 。 由于 这 需要 掌握 计算机 编程语言 和 较 高 的 编程 技巧 ， 因此 不利于 神经网络 技术 的 推广 和 应用 ， 所以 国际 上 许多 公司 和 研究 单位 设计 了 通用 的 ANN 模型库 ， MATLAB 环境 下 的 神经网络 工具箱 就是 其 重要 代表 。 
 　 　 MATLAB 是 MathWorks 公司 推出 的 一套 高性能 的 数值 计算 和 可视化 软件 ， 它集 数值 分析 、 矩阵 运算 、 信号处理 和 图形 显示 于 一体 ， 构成 了 1 个 方便 的 、 界面 友好 的 用户 环境 。 在 这个 环境 下 ， 对 所 要求 解 的 问题 ， 用户 只 需要 简单 地 列出 数学 表达式 ， 其 结果 便 以 数值 或 图形 方式 显示 出来 ， 特别 是 包括 了 被称作 Toolbox （ 工具箱 ） 的 各类 应用 问题 的 求解 工具 。 本文 论述 其中 神经网络 工具箱 的 使用 方法 和 要点 。 
 1 　 调试 方法 
 　 　 设 需要 训练 和 仿真 的 前馈 网络 如图 1 所示 。 网络 采用 误差 反传 训练 算法 （ BP 算法 ） 。 
 
 图 1 　 网络结构 
 1 ． 1   提供 训练样本 和 权值 、 阈值 的 初始值 
 　 　 BP 算法 是 有 指导 的 训练 ， 是 靠 调节 各层 的 权值 使 网络 学会 训练样本 所 表达 的 规律 。 训练样本 由 输入输出 对 ｛  Pki ： tkj ｝ 组成 ， 而 i （ i ＝ 1 ， 2 ， … ， n ， ） 是 输入 层 神经元 的 序号 ， n 是 输入 层 神经元 数 ； j （ j ＝ 1 ， 2 ， … ， m ， ） 是 输出 层 神经元 的 序号 ， m 是 输出 层 神经元 数 ； k （ k ＝ 1 ， 2 ， … ， q ， ） 是 训练 对 的 序号 ， 显然 ， q 的 大小 决定 了 训练样本 的 规模 ， Pki 的 输入 方法 是 ： 先 就 某 固定 的 k 值 ， 输入 i 的 所有 取值 下 的 输入 样本 ； 再 改变 k 值 ， 输入 i 的 所有 取值 下 的 输入 样本 ； 直到 k ＝ q ， 输入 i 的 所有 取值 下 的 输入 样本 为 至 tkj 的 输入 方法 与 Pki 相同 。 需要 注意 的 是 ： MATLAB 下 的 神经网络 工具箱 不必 专门 指出 输入 层 神经元 和 输出 层 神经元 的 多少 ， 而是 自动 地 从 Pki 和 tkj 中 辨认 ， 即会 默认 输入 层 神经元 数为 n ， 输出 层 神经元 数为 m 。 所以 Pki 和 tkj 的 给定 就 显得 特别 重要 。 
 　 　 Wih 是 输入 层至 隐层 的 权值 ， h （ h ＝ 1 ， 2 ， … ， s1 ， ） 是 隐层 神经元 的 序号 ， s1 是 隐层 神经元 数 ， 它 需要 在 程序 中 给出 确定 的 初始值 ， 其 输入 方法 是 ： 就 某 固定 的 i 值 ， 输入 h 的 所有 取值 下 的 权值 ； Whj 是 隐层 至 输出 层 的 权值 ， 其 输入 方法 是 ： 就 某 固定 的 h 值 ， 输入 j 的 所有 取值 下 的 权值 ， bh 和 bj 分别 是 隐层 、 输出 层 神经元 的 阈值 ， 它们 需要 在 程序 中 给出 确定 的 初始值 。 
 1 ． 2 　 有关 函数 说明 
 　 　 用 软件 模拟 BP 网络 时 ， 需要 用到 的 函数 有 ： initff 、 trainbp 、 simuff 、 ploterr 等 ， 下面 分别 说明 。 
 　 　 在 设计 BP 网络 时 ， 只要 已知 输入 向量 p 、 各层 的 神经元 数 、 各层 神经元 的 传递函数 ， 就 可以 利用 函数 initff 对 BP 网络 进行 初始化 。 例如 ， 1 个 2 层 （ 不 包括 输入 层 ） 的 BP 网络 ， 隐层 有 8 个 神经元 ， 传递函数 为 tansig （ 正切 S 型函数 ） ， 输出 层 神经元 数由 目标 向量 t 决定 ， 传递函数 为 purelin （ 纯 线性 函数 ） ， 该 BP 网络 的 初始化 语句 为 ： 
 ［ w1 ， b1 ， w2 ， b2 ］ ＝ initff （ p ， 8 ， ′ tansig ′ ， t ， ′ purelin ′ ） ； 
 　 　 用户 在 准备 数据 样本 时 ， 向量 p 应该 包含 所有 输入 值中 的 最大值 和 最小值 ， 这样 才能 保证 得到 最佳 的 初始值 。 
 　 　 神经网络 工具箱 函数 trainbp 、 trainbpx 、 trainlm ， 用来 对 BP 网络 进行 训练 ， 它们 的 用法 是 类似 的 ， 只是 采用 的 学习 规则 有所不同 。 函数 trainbp 利用 标准 BP 学习 规则 训练 前馈 网络 ， 使 网络 完成 函数 逼近 、 矢量 分类 和 模式识别 ； trainbpx 采用 了 动量 法 和 学习 率自 适应 调整 的 策略 ， 从而 提高 了 学习 速度 并 增加 了 算法 的 可靠性 ； trainlm 使用 了 Levenberg － Marquardt 优化 方法 ， 学习 时间 更 短 ， 但 对于 复杂 的 问题 ， 这种 方法 需要 很大 的 存储空间 。 下面 程序 表明 了 trainlm 的 调用 方法 ： 
 　 　 df ＝ 5 ； 　 　 　 　 　 　 　 　 ％ 　 训练 过程 显示 频率 
 　 　 me ＝ 1000 ； 　 　 　 　 　 　 ％ 　 　 最大 训练 步数 
 　 　 eg ＝ 0 ． 01 ； 　 　 　 　 　 　 ％ 　 误差 指标 
 　 　 tp ＝ ［ df   me   eg ］ ； 
 　 　 ［ w1 ， b1 ， w2 ， b2 ， ep ， tr ］ ＝ trainlm （ w1 ， b1 ， ′ tansig ′ ， w2 ， b2 ， ′ purelin ′ ， p ， t ， tp ） ； 
 　 　 经过训练 得到 了 新 的 权值 矩阵 w1 、 w2 ， 阈值 矢量 b1 、 b2 ， 网络 的 实际 训练 次数 ep 及 网络 训练 误差 平方和 行 矢量 tr 。 
 　 　 前馈 网络 由 一系列 网络层 组成 ， 每 一层 都 从前 一层 得到 输入 数据 ， simuff 函数 可 用于 仿真 最多 3 层 的 前馈 网络 ： 
 　 　 a ＝ simuff （ q ， w1 ， b1 ， ′ tansig ′ ， w2 ， b2 ， ′ purelin ′ ） 
 　 　 上式 q 为 输入 数据 ， a 为 预测 结果 。 
 　 　 Ploterr （ e ， eg ） 用于 绘制 误差 行 矢量 e 随 训练 次数 的 变化 图 ， 同时 以点线 绘出 误差 指标 eg ， 其 纵轴 为 对数 刻度 ， 总 的 训练 次数 小于 e 的 长度 ， e 的 第一个 元素 为 网络 训练 前 的 误差 。 
 1 ． 3   网络结构 的 确定 
 　 　 神经网络 的 结构设计 是 一个 非常 重要 但 却 十分复杂 的 问题 。 网络 的 结构设计 主要 指 对于 给定 的 任务 ： ① 如何 选择 网络层 数 ？ 因为 网络 的 输入 和 输出 层 易于 确定 ， 所以 这一 问题 实际上 就是 隐层 应该 为 几层 ； ② 每层 应选 多少 神经元 ； ③ 神经元 的 传递函数 应 如何 选定 。 所有 这些 都 是 使用 神经网络 时 必须 加以解决 的 问题 。 但 目前 对此 并 没有 一个 确切 的 答案 ， MATLAB 下 的 神经网络 工具箱 也 不 例外 。 
 　 　 综合 以往 的 研究成果 ， 可以 得到 BP 网络结构 的 一些 结论 ： ① 对于 3 层 （ 1 个 输入 层 、 1 个 隐层 和 1 个 输出 层 ） 的 BP 网络 ， 只要 其隐层 的 神经元 数可选 ， 就 可以 任意 精度 逼近 任何 连续函数 （ Kolmogorov 定理 ） ； ② 随着 所 逼近 函数 的 波动性 增加 ， 隐层 的 神经元 数 也 应适当 增加 ； ③ 随着 学习 样本数 的 增加 ， 隐层 神经元 数 也 应 增加 ； ④ 增加 隐层 数目 可以 减少 各隐层 的 神经元 数 ， 减少 陷入 局部 极小 的 机会 ； ⑤ 随着 网络 复杂程度 和 学习 样本数 的 增加 ， 其 收敛 速度 变慢 ， 所以 网络 的 规模 不 应 随意 增大 。 另外 ， 作者 的 实践经验 是 ： 对于 给定 的 问题 ， 如果 不得不 增大 网络 规模 时 ， 宁愿 采用 较 多 隐层 和 较 少 神经元 数 的 神经网络 ， 而 不应 采用 较少 隐层 和 较 多 神经元 数 的 神经网络 。 因为 这样 可以 相对 减少 网络 的 训练 时间 。 
 2 　 图形 结果 的 输出 
 　 　 图形 结果 的 输出 是 软件 模拟 神经网络 的 重要 步骤 。 根据 作者 使用 MATLAB 下 神经网络 工具箱 的 情况 ， 除了 将 图形 显示 在 计算机屏幕 上 ， 图形 结果 的 输出 还有 其它 几种 方式 。 
 　 　 （ 1 ） 打印输出 
 　 　 工具箱 在 生成 图形 结果 时 （ 例如 利用 上述 Ploterr （ e ， eg ） 函数 ） ， 也 同时 生成 该 图形 对应 的 窗口 。 这时 可以 利用 窗口 中 的 file 菜单 下 的 Page   Position 功能 调整 图形 的 大小 和 在 打印纸 上 的 位置 ： Paper   Position ： ［ Left   Bottom   Width   Height ］ ， 如图 2 所示 。 再 利用 Print 功能 将 图形 从 指定 的 打印机 上 输出 。 
 
 图 2 　 设置 被 打印 图形 
 　 　 （ 2 ） 建立 图形文件 输出 
 　 　 利用 窗口 中 的 file 菜单 下 的 Save   As 命令 可以 建立 图形文件 。 该 文件 与 一般 的 MATLAB 文件 等价 ， 可以 实现 编辑 、 调试 和 运行 重显 图形 ， 当然 也 可以 打印输出 。 另外 ， 有时 可能 在 1 个 MATLAB 程序 中 需要 输出 不止 1 个 图形 ， 这时 可以 利用 MATLAB 的 pause 命令 实现 运行 程序 的 暂停 ， 再 利用 Save   As 命令 建立 不同 文件名 的 图形文件 即可 。 
 　 　 （ 3 ） 带 窗口 输出 
 　 　 为了 满足 某种 目的 （ 例如 演示 和 教学 ） ， 有时 需要 输出 图形 的 同时 ， 输出 窗口 。 利用 Windows 的 剪切板 可 在 MATLAB 与 其它 应用程序 之间 交换 信息 。 要 将 MATLAB 的 图形 （ 带 窗口 ） 移 到 其它 应用程序 ， 首先 按 Alt － PrintScreen 键 ， 将 图形 （ 带 窗口 ） 复制到 剪切板 ， 然后 激活 其它 应用程序 ， 选择 Edit 中 的 Paste ， 就 可 在 应用程序 中 得到 MATLAB 的 图形 （ 带 窗口 ） 。 
 　 　 （ 4 ） 输出 到 WORD 等 应用程序 
 　 　 这是 较为 常见 的 输出 方式 。 同样 也 是 利用 Windows 的 剪切板 功能 ， 但 它 不是 按 Alt － PrintScreen 键 ， 而是 用 图形 窗口 中 Window 菜单 下 的 Copy   Figure 功能 。 首先 单击 图形 窗口 中 Window 菜单 下 的 Copy   Figure ， 然后 激活 其它 应用程序 ， 选择 Edit 中 的 Paste ， 就 可 在 应用程序 中 得到 MATLAB 的 图形 （ 不带 窗口 ） 。 
 3 　 结论 
 　 　 人工神经网络 理论 和 技术 已经 渗透到 各个领域 ， 取得 了 令人鼓舞 的 成果 。 本文 讨论 了 MATLAB 环境 下 神经网络 工具箱 的 使用 方法 ， 重点 分析 了 工具箱 的 调试 技巧 ， 给出 了 网络结构 设计 和 图形 结果 输出 方法 ， 这些 对 工程 实际 而言 具有 指导作用 和 实用价值 。 
 刘晔 ( 西安交通大学 电气 工程学院  710049 ) 
 夏建生 ( 西安交通大学 电气 工程学院  710049 ) 
 参考文献 
 １ ， 周 继成 ， 周 青山 ， 韩 飘扬 ． 人工神经网络 — 第六代 计算机 的 实现 ． 北京 ： 科学普及 出版社 ， １ ９ ９ ３ 
 ２ ， Ｈ ａ ｎ ｓ ｅ ｌ ｍ ａ ｎ   Ｄ ， Ｌ ｉ ｔ ｔ ｌ ｅ ｆ ｉ ｅ ｌ ｄ   Ｂ 著 ， 李人厚 ， 张 平安 译 ． 精通 Ｍ Ａ Ｔ － Ｌ Ａ Ｂ － 综合 辅导 与 指南 ． 西安 ： 西安交通大学 出版社 ， １ ９ ９ ８ 
 ３ ， 楼 顺天 ， 施阳 ． 基于 Ｍ Ａ Ｔ Ｌ Ａ Ｂ 的 系统分析 与 设计 — 神经网络 ． 西安 ： 西安电子科技大学 出版社 ， １ ９ ９ ８ 
 ４ ， 李耀勇 ， 郑 南宁 ． 前馈 神经网络 的 隐 结点 个数 与 网络 推广 能力 的 关系 ． 西安交通大学 学报 ， １ ９ ９ ６ ； ３ ０ （ ９ ） 
 ５ ， 廖宁放 ， 高稚 允 ． Ｂ Ｐ 神经网络 用于 函数 逼近 的 最佳 隐层 结构 ． 北京理工大学 学报 ， １ ９ ９ ８ ； １ ８ （ ４ ） 
  收稿 日期 ： １ ９ ９ ９ － １ ０ － １ ０ 
